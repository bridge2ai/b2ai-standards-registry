{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About the Bridge2AI Standards Explorer","text":"<p>The Standards Explorer is part of Bridge2AI, a consortium supported by the National Institute of Health Common Fund. Bridge2AI aims to propel biomedical research forward by setting the stage for widespread adoption of artificial intelligence (AI) that tackles complex biomedical challenges beyond human intuition. See the official site or this NIH page for more details on Bridge2AI.</p> <p>The Explorer is built and maintained by the Bridge2AI Standards Working Group. The Standards Working Group is focused on developing strategies to support generation of standardized, interoperable, and machine-readable data from biomedical research.</p>"},{"location":"#what-is-the-explorer-for","title":"What is the Explorer for?","text":"<p>The Explorer serves as an integrated knowledge base about data standards and the process of preparing data to be AI ready.</p> <p>Rather than simply listing standards, however, the Explorer displays relevance of each standard to:</p> <ul> <li> <p>The groups using it within the Bridge2AI Consortium</p> </li> <li> <p>Its relevant topics and data structures</p> </li> <li> <p>The organization(s) responsible for its creation and continued development</p> </li> </ul> <p>and other features pertinent to using the standard in practice.</p> <p>Biomedical researchers may use the Explorer to rapidly determine relevance of a set of standards to their own needs while also seeing examples of how those standards have already been used in Bridge2AI projects.</p> <p>Computational scientists and AI engineers may use the Explorer to learn about standards and practices used within specific domains of biomedicine, allowing them to better understand the structure and content of biomedical data.</p> <p>Organizations and individuals planning to develop new methods for ensuring AI data readiness will also find the Explorer useful for characterizing the current standards ecosystem.</p>"},{"location":"#what-is-in-the-explorer","title":"What is in the Explorer?","text":"<p>The Explorer includes six primary types of objects, as described in the table below. Each object has a numerical identifier with a prefix defining its type (e.g., <code>B2AI_STANDARD:221</code> refers to a single standard).</p> Type Prefix Description Data Standards and Tools <code>B2AI_STANDARD</code> Defined broadly, to include any formal or informal guidelines used to standardize, integrate, or otherwise make data more consistent in structure and content. It covers data standards, ontologies, controlled vocabularies, repositories, other registries, reference implementations, example datasets, software, and relevant training programs. See the page on categories for more details about specific types of data standards and tools as used in the Explorer. Data Sets <code>B2AI_DATA</code> Data sets produced by Bridge2AI Grand Challenges. Data Substrates <code>B2AI_SUBSTRATE</code> A conceptual category of the structure and content of data itself. This may be interpreted as \"data, in this form or format\", as compared to a data standard, which refers to the set of rules defining how data is to be organized. For example, <code>B2AI_SUBSTRATE:9</code>, or Database, refers to any \"organized collection of structured information, stored electronically and organized for rapid search and retrieval.\" Standards may define or implement specific types of Databases. Similarly, <code>B2AI_SUBSTRATE:11</code>, or DICOM, refers to images and metadata stored according to DICOM standards (<code>B2AI_STANDARD:98</code>). Data Topics <code>B2AI_TOPIC</code> An area of study or research focus, from the very broad (<code>B2AI_TOPIC:5</code> or Data; all Topics in the Explorer are a subclass of this) to the more specific (<code>B2AI_TOPIC:47</code> or Respiratory Disorders). These topics also include general methodologies and data collection mechanisms (e.g., <code>B2AI_TOPIC:38</code> or Glucose Monitoring). Organizations <code>B2AI_ORG</code> An organization related to or responsible for one or more standards. This includes all Bridge2AI Grand Challenge research groups. Use Cases <code>B2AI_USECASE</code> Specific use cases for standards, including standards for their expected input and outputs."},{"location":"#how-are-standards-selected","title":"How are standards selected?","text":"<p>Standards in the Explorer are curated by Bridge2AI standards members. All standards, tools, and related resources (see the description of Data Standards and Tools above) meeting any of the following criteria are within the scope of curation:</p> <ol> <li>Those used or developed by Bridge2AI Grand Challenges.</li> <li>Those used more generally in biomedical data science and biological research, to characterize the broader environment of data standards.</li> <li>Those used in specific domains of biomedicine and biology shared by Bridge2AI Grand Challenges (e.g., ophthalmic imaging).</li> <li>Those used with data for testing, training, and validating artificial intelligence models.</li> </ol>"},{"location":"#why-does-the-explorer-list-other-resources-like-data-sets-and-tools","title":"Why does the Explorer list other resources, like data sets and tools?","text":"<p>Data sets, including both those produced by Bridge2AI Grand Challenges and those categorized as Reference Data or Dataset in the Explorer, serve numerous roles in the production of AI ready data. They:</p> <ul> <li> <p>Provide examples of how data has been and is currently released</p> </li> <li> <p>Serve as validation sets for new methods</p> </li> <li> <p>Offer opportunities for comparing new data with previous observations</p> </li> </ul> <p>In addition to the criteria used for curating standards (see above), reference data, software, and other resources are included in the Explorer if they meet one of the following criteria:</p> <ul> <li> <p>They are accompanied by standardized metadata and serve as a real-world example of that standard (e.g., B2AI_STANDARD:690 is a Datasheet for a text data set; the corresponding standard is B2AI_STANDARD:326, or Datasheets)</p> </li> <li> <p>They are very similar to data produced by Bridge2AI Grand Challenges and serve as examples of how data may have been standardized in the past.</p> </li> <li> <p>They are the origin of a standard (e.g., B2AI_STANDARD:202 refers to the WFDB Format, while B2AI_STANDARD:643 refers to the WFDB database).</p> </li> <li> <p>They are in broad use within biomedical research, to the point of acting as a standard or a source of standardization.</p> </li> </ul>"},{"location":"#is-the-explorer-intended-to-be-fully-comprehensive","title":"Is the Explorer intended to be fully comprehensive?","text":"<p>No. Assembling a complete collection of all standards used for all types of data may not be feasible or even possible. Instead, we have focused on resources relevant to preparing AI ready biomedical and biological data, while also capturing a broader context of the data standards landscape.</p>"},{"location":"#does-the-explorer-include-only-formal-mature-standards","title":"Does the Explorer include only formal, mature standards?","text":"<p>No. Standards development organizations such as the International Organization for Standardization (ISO) play crucial roles in the refinement of expert-designed, formal rules for representing data (e.g., the ISO 8601 standard defines a standardized format for representing date and time). Biomedical research, however, is built upon an assortment of standards varying in formality, maturity, and domain-specificity. Novel methods and approaches may require adaptation or extension of existing standards. </p> <p>The Explorer categorizes the maturity of each standard according an evaluation of how complete its review process is and how ready it is to be used (i.e., if there is an implementation of the standard). The categories for these are:</p> Category Description Process Maturity Final This standard has undergone a review process by one or more SDOs and has been determined to be in a mature state. Future revisions may still be possible. Draft This standard is undergoing a review process by one or more SDOs to determine its maturity. Development This standard is in its initial development stages and has not yet entered a review process, or is early in the process and still likely to be extensively revised. Implementation Maturity Production This standard has one or more implementations appropriate for production use, i.e., in use cases and environments where adherence to the standard is expected to be fully consistent. Pilot This standard has one or more implementations intended for testing or evaluation purposes but may not be appropriate for production applications. <p>A standard is determined to be mature if its Process Maturity is Final and/or its Implementation Maturity is Production.</p> <p>Mature standards are labeled with a badge in the Maturity column in the Standards Explorer.</p>"},{"location":"#do-bridge2ai-researchers-only-use-formal-mature-standards","title":"Do Bridge2AI researchers only use formal, mature standards?","text":"<p>No. Researchers are actively pursing approaches with community-tested standards, as evidenced by our Bridge2AI Grand Challenges:</p> <ul> <li>The Salutogenesis Grand Challenge (also known as AI-READI) performed vision assessments with several diagnostic methods. For one method, autorefraction, no single standard existed to capture all metadata they wished to record, so AI-READI researchers defined and documented an appropriate metadata format. They also found that, in the collection of Optical Coherence Tomography (OCT) images, several metadata fields defined by the DICOM standard could be safely removed as they either contained patient information or were inconsistent across imaging devices (see dataset documentation on retinal OCT).</li> <li>The Precision Public Health Grand Challenge (also known as Voice as a Biomarker of Health) found that existing protocols for collecting and representing human voice recordings were highly variable and non-standard. No mature standard existed for representing voice recordings along with their relevant features and health information, nor did one for sharing recordings while preserving patient privacy (see more details in this paper by Bensoussan et al.).</li> </ul>"},{"location":"#where-is-explorer-data-stored","title":"Where is Explorer data stored?","text":"<p>All data in the Explorer is stored in the Standards Registry GitHub repository.</p> <p>The \"source of truth\" for each table is stored in YAML format in the directory src/data/.</p> <p>Corresponding versions of the tables are provided in JSON and TSV format in the directory project/data/.</p>"},{"location":"#how-may-a-standard-be-added-or-updated","title":"How may a standard be added or updated?","text":"<p>To submit a new data standard or other entry to the Explorer (including data topics, organizations, or others), please open an issue on the Standards Registry GitHub repository using this form.</p> <p>Updates may also be requested through an issue on the same repository.</p>"},{"location":"#is-there-a-schema-or-data-model-for-the-explorer","title":"Is there a schema or data model for the Explorer?","text":"<p>Data objects are defined according to the standards-schemas.</p> <p>This data model is defined in the LinkML modeling language.</p> <p>In this repository, schema modules are stored in the src/standards_schemas/schema/ directory.</p> <p>The schemas are also provided in JSON-LD, JSONSchema, and OWL formats within the project/ directory.</p>"},{"location":"#what-do-the-categories-mean","title":"What do the categories mean?","text":"<p>See the page on categories.</p>"},{"location":"#what-do-the-topics-mean","title":"What do the topics mean?","text":"<p>See the page on topics.</p>"},{"location":"DataSubstrate/","title":"Data Substrates","text":"<pre><code>flowchart LR\n    B2AI_SUBSTRATE_1[Array]\n    B2AI_SUBSTRATE_2[Associative Array]\n    B2AI_SUBSTRATE_3[BIDS]\n    B2AI_SUBSTRATE_4[BigQuery]\n    B2AI_SUBSTRATE_5[Column Store]\n    B2AI_SUBSTRATE_6[Comma-separated values]\n    B2AI_SUBSTRATE_7[Data]\n    B2AI_SUBSTRATE_8[Data Frame]\n    B2AI_SUBSTRATE_9[Database]\n    B2AI_SUBSTRATE_10[Delimited Text]\n    B2AI_SUBSTRATE_11[DICOM]\n    B2AI_SUBSTRATE_12[Directed acyclic graph]\n    B2AI_SUBSTRATE_13[Document Database]\n    B2AI_SUBSTRATE_14[Graph]\n    B2AI_SUBSTRATE_15[Graph Database]\n    B2AI_SUBSTRATE_16[HDF5]\n    B2AI_SUBSTRATE_17[Heap]\n    B2AI_SUBSTRATE_18[Hierarchical Array]\n    B2AI_SUBSTRATE_19[Image]\n    B2AI_SUBSTRATE_20[JSON]\n    B2AI_SUBSTRATE_21[KGX TSV]\n    B2AI_SUBSTRATE_22[MongoDB]\n    B2AI_SUBSTRATE_23[MySQL]\n    B2AI_SUBSTRATE_24[N-Dimensional Array]\n    B2AI_SUBSTRATE_25[Neo4j]\n    B2AI_SUBSTRATE_26[Neural Network Model]\n    B2AI_SUBSTRATE_27[NNEF]\n    B2AI_SUBSTRATE_28[ONNX]\n    B2AI_SUBSTRATE_29[Pandas DataFrame]\n    B2AI_SUBSTRATE_30[Parquet]\n    B2AI_SUBSTRATE_31[PostgreSQL]\n    B2AI_SUBSTRATE_32[Property graph]\n    B2AI_SUBSTRATE_33[PyTorch Tensor]\n    B2AI_SUBSTRATE_34[R data.frame]\n    B2AI_SUBSTRATE_35[R tibble]\n    B2AI_SUBSTRATE_36[Raster Image]\n    B2AI_SUBSTRATE_37[Relational Database]\n    B2AI_SUBSTRATE_38[Set]\n    B2AI_SUBSTRATE_39[String]\n    B2AI_SUBSTRATE_40[SummarizedExperiment]\n    B2AI_SUBSTRATE_41[Tab-separated values]\n    B2AI_SUBSTRATE_42[Tensor]\n    B2AI_SUBSTRATE_43[Text]\n    B2AI_SUBSTRATE_44[Tree]\n    B2AI_SUBSTRATE_45[Trie]\n    B2AI_SUBSTRATE_46[Vector]\n    B2AI_SUBSTRATE_47[Vector Image]\n    B2AI_SUBSTRATE_48[Waveform Audio File Format]\n    B2AI_SUBSTRATE_49[Waveform Data]\n    B2AI_SUBSTRATE_50[xarray]\n    B2AI_SUBSTRATE_51[Zarr]\n    B2AI_SUBSTRATE_52[Compressed Data]\n    B2AI_SUBSTRATE_53[BED]\n    B2AI_SUBSTRATE_54[Vector Database]\n    B2AI_SUBSTRATE_55[Pinecone]\n    B2AI_SUBSTRATE_56[Immunofluorescence Image]\n    B2AI_SUBSTRATE_57[Spectral Data]\n    B2AI_SUBSTRATE_58[Mass Spectrometry Data]\n    B2AI_SUBSTRATE_59[Size Exclusion Chromatography-Mass Spectrometry Data]\n    B2AI_SUBSTRATE_60[Sequence]\n    B2AI_SUBSTRATE_61[DNA Sequence Data]\n    B2AI_SUBSTRATE_62[RNA Sequence Data]\n    B2AI_SUBSTRATE_63[Single-cell RNA Sequence Data]\n    B2AI_SUBSTRATE_64[Perturb-seq Data]\n    B2AI_SUBSTRATE_65[Retinal Image]\n    B2AI_SUBSTRATE_66[Fluorescence Lifetime Imaging Ophthalmoscopy data]\n    B2AI_SUBSTRATE_67[Optical coherence tomography data]\n    B2AI_SUBSTRATE_68[Optical coherence tomography angiography data]\n    B2AI_SUBSTRATE_69[Time-series data]\n    B2AI_SUBSTRATE_70[Physiological data]\n    B2AI_SUBSTRATE_71[Heart rate]\n    B2AI_SUBSTRATE_72[Oxygen saturation]\n    B2AI_SUBSTRATE_73[Physical activity data]\n    B2AI_SUBSTRATE_74[Caloric burn data]\n    B2AI_SUBSTRATE_75[Respiratory rate]\n    B2AI_SUBSTRATE_76[Sleep tracking data]\n    B2AI_SUBSTRATE_77[Stress tracking data]\n    B2AI_SUBSTRATE_78[Glucose monitoring data]\n    B2AI_SUBSTRATE_79[Participant response data]\n    B2AI_SUBSTRATE_80[Questionnaire response data]\n    B2AI_SUBSTRATE_81[File headers]\n    B2AI_SUBSTRATE_1 --&gt; B2AI_SUBSTRATE_2\n    B2AI_SUBSTRATE_1 --&gt; B2AI_SUBSTRATE_18\n    B2AI_SUBSTRATE_1 --&gt; B2AI_SUBSTRATE_24\n    B2AI_SUBSTRATE_2 --&gt; B2AI_SUBSTRATE_20\n    B2AI_SUBSTRATE_5 --&gt; B2AI_SUBSTRATE_4\n    B2AI_SUBSTRATE_5 --&gt; B2AI_SUBSTRATE_30\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_1\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_8\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_9\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_14\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_19\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_26\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_38\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_39\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_42\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_46\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_49\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_52\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_57\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_69\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_79\n    B2AI_SUBSTRATE_8 --&gt; B2AI_SUBSTRATE_29\n    B2AI_SUBSTRATE_8 --&gt; B2AI_SUBSTRATE_34\n    B2AI_SUBSTRATE_8 --&gt; B2AI_SUBSTRATE_35\n    B2AI_SUBSTRATE_9 --&gt; B2AI_SUBSTRATE_5\n    B2AI_SUBSTRATE_9 --&gt; B2AI_SUBSTRATE_13\n    B2AI_SUBSTRATE_9 --&gt; B2AI_SUBSTRATE_15\n    B2AI_SUBSTRATE_9 --&gt; B2AI_SUBSTRATE_37\n    B2AI_SUBSTRATE_9 --&gt; B2AI_SUBSTRATE_54\n    B2AI_SUBSTRATE_10 --&gt; B2AI_SUBSTRATE_6\n    B2AI_SUBSTRATE_10 --&gt; B2AI_SUBSTRATE_41\n    B2AI_SUBSTRATE_10 --&gt; B2AI_SUBSTRATE_53\n    B2AI_SUBSTRATE_13 --&gt; B2AI_SUBSTRATE_22\n    B2AI_SUBSTRATE_14 --&gt; B2AI_SUBSTRATE_12\n    B2AI_SUBSTRATE_14 --&gt; B2AI_SUBSTRATE_15\n    B2AI_SUBSTRATE_14 --&gt; B2AI_SUBSTRATE_32\n    B2AI_SUBSTRATE_14 --&gt; B2AI_SUBSTRATE_44\n    B2AI_SUBSTRATE_15 --&gt; B2AI_SUBSTRATE_25\n    B2AI_SUBSTRATE_18 --&gt; B2AI_SUBSTRATE_16\n    B2AI_SUBSTRATE_18 --&gt; B2AI_SUBSTRATE_20\n    B2AI_SUBSTRATE_18 --&gt; B2AI_SUBSTRATE_40\n    B2AI_SUBSTRATE_19 --&gt; B2AI_SUBSTRATE_3\n    B2AI_SUBSTRATE_19 --&gt; B2AI_SUBSTRATE_36\n    B2AI_SUBSTRATE_19 --&gt; B2AI_SUBSTRATE_47\n    B2AI_SUBSTRATE_24 --&gt; B2AI_SUBSTRATE_50\n    B2AI_SUBSTRATE_24 --&gt; B2AI_SUBSTRATE_51\n    B2AI_SUBSTRATE_26 --&gt; B2AI_SUBSTRATE_27\n    B2AI_SUBSTRATE_26 --&gt; B2AI_SUBSTRATE_28\n    B2AI_SUBSTRATE_32 --&gt; B2AI_SUBSTRATE_21\n    B2AI_SUBSTRATE_36 --&gt; B2AI_SUBSTRATE_11\n    B2AI_SUBSTRATE_36 --&gt; B2AI_SUBSTRATE_56\n    B2AI_SUBSTRATE_36 --&gt; B2AI_SUBSTRATE_65\n    B2AI_SUBSTRATE_37 --&gt; B2AI_SUBSTRATE_23\n    B2AI_SUBSTRATE_37 --&gt; B2AI_SUBSTRATE_31\n    B2AI_SUBSTRATE_39 --&gt; B2AI_SUBSTRATE_43\n    B2AI_SUBSTRATE_39 --&gt; B2AI_SUBSTRATE_60\n    B2AI_SUBSTRATE_41 --&gt; B2AI_SUBSTRATE_21\n    B2AI_SUBSTRATE_42 --&gt; B2AI_SUBSTRATE_33\n    B2AI_SUBSTRATE_43 --&gt; B2AI_SUBSTRATE_10\n    B2AI_SUBSTRATE_44 --&gt; B2AI_SUBSTRATE_45\n    B2AI_SUBSTRATE_49 --&gt; B2AI_SUBSTRATE_3\n    B2AI_SUBSTRATE_49 --&gt; B2AI_SUBSTRATE_48\n    B2AI_SUBSTRATE_54 --&gt; B2AI_SUBSTRATE_55\n    B2AI_SUBSTRATE_57 --&gt; B2AI_SUBSTRATE_58\n    B2AI_SUBSTRATE_58 --&gt; B2AI_SUBSTRATE_59\n    B2AI_SUBSTRATE_60 --&gt; B2AI_SUBSTRATE_61\n    B2AI_SUBSTRATE_60 --&gt; B2AI_SUBSTRATE_62\n    B2AI_SUBSTRATE_62 --&gt; B2AI_SUBSTRATE_63\n    B2AI_SUBSTRATE_63 --&gt; B2AI_SUBSTRATE_64\n    B2AI_SUBSTRATE_65 --&gt; B2AI_SUBSTRATE_66\n    B2AI_SUBSTRATE_65 --&gt; B2AI_SUBSTRATE_67\n    B2AI_SUBSTRATE_67 --&gt; B2AI_SUBSTRATE_68\n    B2AI_SUBSTRATE_69 --&gt; B2AI_SUBSTRATE_70\n    B2AI_SUBSTRATE_70 --&gt; B2AI_SUBSTRATE_71\n    B2AI_SUBSTRATE_70 --&gt; B2AI_SUBSTRATE_72\n    B2AI_SUBSTRATE_70 --&gt; B2AI_SUBSTRATE_73\n    B2AI_SUBSTRATE_70 --&gt; B2AI_SUBSTRATE_75\n    B2AI_SUBSTRATE_70 --&gt; B2AI_SUBSTRATE_76\n    B2AI_SUBSTRATE_70 --&gt; B2AI_SUBSTRATE_77\n    B2AI_SUBSTRATE_70 --&gt; B2AI_SUBSTRATE_78\n    B2AI_SUBSTRATE_73 --&gt; B2AI_SUBSTRATE_74\n    B2AI_SUBSTRATE_79 --&gt; B2AI_SUBSTRATE_80\n\n    click B2AI_SUBSTRATE_1 \"substrates/array/\" \"Array\"\n    click B2AI_SUBSTRATE_2 \"substrates/associative-array/\" \"Associative Array\"\n    click B2AI_SUBSTRATE_3 \"substrates/bids/\" \"BIDS\"\n    click B2AI_SUBSTRATE_4 \"substrates/bigquery/\" \"BigQuery\"\n    click B2AI_SUBSTRATE_5 \"substrates/column-store/\" \"Column Store\"\n    click B2AI_SUBSTRATE_6 \"substrates/comma-separated-values/\" \"Comma-separated values\"\n    click B2AI_SUBSTRATE_7 \"substrates/data/\" \"Data\"\n    click B2AI_SUBSTRATE_8 \"substrates/data-frame/\" \"Data Frame\"\n    click B2AI_SUBSTRATE_9 \"substrates/database/\" \"Database\"\n    click B2AI_SUBSTRATE_10 \"substrates/delimited-text/\" \"Delimited Text\"\n    click B2AI_SUBSTRATE_11 \"substrates/dicom/\" \"DICOM\"\n    click B2AI_SUBSTRATE_12 \"substrates/directed-acyclic-graph/\" \"Directed acyclic graph\"\n    click B2AI_SUBSTRATE_13 \"substrates/document-database/\" \"Document Database\"\n    click B2AI_SUBSTRATE_14 \"substrates/graph/\" \"Graph\"\n    click B2AI_SUBSTRATE_15 \"substrates/graph-database/\" \"Graph Database\"\n    click B2AI_SUBSTRATE_16 \"substrates/hdf5/\" \"HDF5\"\n    click B2AI_SUBSTRATE_17 \"substrates/heap/\" \"Heap\"\n    click B2AI_SUBSTRATE_18 \"substrates/hierarchical-array/\" \"Hierarchical Array\"\n    click B2AI_SUBSTRATE_19 \"substrates/image/\" \"Image\"\n    click B2AI_SUBSTRATE_20 \"substrates/json/\" \"JSON\"\n    click B2AI_SUBSTRATE_21 \"substrates/kgx-tsv/\" \"KGX TSV\"\n    click B2AI_SUBSTRATE_22 \"substrates/mongodb/\" \"MongoDB\"\n    click B2AI_SUBSTRATE_23 \"substrates/mysql/\" \"MySQL\"\n    click B2AI_SUBSTRATE_24 \"substrates/n-dimensional-array/\" \"N-Dimensional Array\"\n    click B2AI_SUBSTRATE_25 \"substrates/neo4j/\" \"Neo4j\"\n    click B2AI_SUBSTRATE_26 \"substrates/neural-network-model/\" \"Neural Network Model\"\n    click B2AI_SUBSTRATE_27 \"substrates/nnef/\" \"NNEF\"\n    click B2AI_SUBSTRATE_28 \"substrates/onnx/\" \"ONNX\"\n    click B2AI_SUBSTRATE_29 \"substrates/pandas-dataframe/\" \"Pandas DataFrame\"\n    click B2AI_SUBSTRATE_30 \"substrates/parquet/\" \"Parquet\"\n    click B2AI_SUBSTRATE_31 \"substrates/postgresql/\" \"PostgreSQL\"\n    click B2AI_SUBSTRATE_32 \"substrates/property-graph/\" \"Property graph\"\n    click B2AI_SUBSTRATE_33 \"substrates/pytorch-tensor/\" \"PyTorch Tensor\"\n    click B2AI_SUBSTRATE_34 \"substrates/r-data-frame/\" \"R data.frame\"\n    click B2AI_SUBSTRATE_35 \"substrates/r-tibble/\" \"R tibble\"\n    click B2AI_SUBSTRATE_36 \"substrates/raster-image/\" \"Raster Image\"\n    click B2AI_SUBSTRATE_37 \"substrates/relational-database/\" \"Relational Database\"\n    click B2AI_SUBSTRATE_38 \"substrates/set/\" \"Set\"\n    click B2AI_SUBSTRATE_39 \"substrates/string/\" \"String\"\n    click B2AI_SUBSTRATE_40 \"substrates/summarizedexperiment/\" \"SummarizedExperiment\"\n    click B2AI_SUBSTRATE_41 \"substrates/tab-separated-values/\" \"Tab-separated values\"\n    click B2AI_SUBSTRATE_42 \"substrates/tensor/\" \"Tensor\"\n    click B2AI_SUBSTRATE_43 \"substrates/text/\" \"Text\"\n    click B2AI_SUBSTRATE_44 \"substrates/tree/\" \"Tree\"\n    click B2AI_SUBSTRATE_45 \"substrates/trie/\" \"Trie\"\n    click B2AI_SUBSTRATE_46 \"substrates/vector/\" \"Vector\"\n    click B2AI_SUBSTRATE_47 \"substrates/vector-image/\" \"Vector Image\"\n    click B2AI_SUBSTRATE_48 \"substrates/waveform-audio-file-format/\" \"Waveform Audio File Format\"\n    click B2AI_SUBSTRATE_49 \"substrates/waveform-data/\" \"Waveform Data\"\n    click B2AI_SUBSTRATE_50 \"substrates/xarray/\" \"xarray\"\n    click B2AI_SUBSTRATE_51 \"substrates/zarr/\" \"Zarr\"\n    click B2AI_SUBSTRATE_52 \"substrates/compressed-data/\" \"Compressed Data\"\n    click B2AI_SUBSTRATE_53 \"substrates/bed/\" \"BED\"\n    click B2AI_SUBSTRATE_54 \"substrates/vector-database/\" \"Vector Database\"\n    click B2AI_SUBSTRATE_55 \"substrates/pinecone/\" \"Pinecone\"\n    click B2AI_SUBSTRATE_56 \"substrates/immunofluorescence-image/\" \"Immunofluorescence Image\"\n    click B2AI_SUBSTRATE_57 \"substrates/spectral-data/\" \"Spectral Data\"\n    click B2AI_SUBSTRATE_58 \"substrates/mass-spectrometry-data/\" \"Mass Spectrometry Data\"\n    click B2AI_SUBSTRATE_59 \"substrates/size-exclusion-chromatography-mass-spectrometry-data/\" \"Size Exclusion Chromatography-Mass Spectrometry Data\"\n    click B2AI_SUBSTRATE_60 \"substrates/sequence/\" \"Sequence\"\n    click B2AI_SUBSTRATE_61 \"substrates/dna-sequence-data/\" \"DNA Sequence Data\"\n    click B2AI_SUBSTRATE_62 \"substrates/rna-sequence-data/\" \"RNA Sequence Data\"\n    click B2AI_SUBSTRATE_63 \"substrates/single-cell-rna-sequence-data/\" \"Single-cell RNA Sequence Data\"\n    click B2AI_SUBSTRATE_64 \"substrates/perturb-seq-data/\" \"Perturb-seq Data\"\n    click B2AI_SUBSTRATE_65 \"substrates/retinal-image/\" \"Retinal Image\"\n    click B2AI_SUBSTRATE_66 \"substrates/fluorescence-lifetime-imaging-ophthalmoscopy-data/\" \"Fluorescence Lifetime Imaging Ophthalmoscopy data\"\n    click B2AI_SUBSTRATE_67 \"substrates/optical-coherence-tomography-data/\" \"Optical coherence tomography data\"\n    click B2AI_SUBSTRATE_68 \"substrates/optical-coherence-tomography-angiography-data/\" \"Optical coherence tomography angiography data\"\n    click B2AI_SUBSTRATE_69 \"substrates/time-series-data/\" \"Time-series data\"\n    click B2AI_SUBSTRATE_70 \"substrates/physiological-data/\" \"Physiological data\"\n    click B2AI_SUBSTRATE_71 \"substrates/heart-rate/\" \"Heart rate\"\n    click B2AI_SUBSTRATE_72 \"substrates/oxygen-saturation/\" \"Oxygen saturation\"\n    click B2AI_SUBSTRATE_73 \"substrates/physical-activity-data/\" \"Physical activity data\"\n    click B2AI_SUBSTRATE_74 \"substrates/caloric-burn-data/\" \"Caloric burn data\"\n    click B2AI_SUBSTRATE_75 \"substrates/respiratory-rate/\" \"Respiratory rate\"\n    click B2AI_SUBSTRATE_76 \"substrates/sleep-tracking-data/\" \"Sleep tracking data\"\n    click B2AI_SUBSTRATE_77 \"substrates/stress-tracking-data/\" \"Stress tracking data\"\n    click B2AI_SUBSTRATE_78 \"substrates/glucose-monitoring-data/\" \"Glucose monitoring data\"\n    click B2AI_SUBSTRATE_79 \"substrates/participant-response-data/\" \"Participant response data\"\n    click B2AI_SUBSTRATE_80 \"substrates/questionnaire-response-data/\" \"Questionnaire response data\"\n    click B2AI_SUBSTRATE_81 \"substrates/file-headers/\" \"File headers\"\n</code></pre>"},{"location":"DataTopic/","title":"Data Topics","text":"<pre><code>flowchart LR\n    B2AI_TOPIC_1[Biology]\n    B2AI_TOPIC_2[Cell]\n    B2AI_TOPIC_3[Cheminformatics]\n    B2AI_TOPIC_4[Clinical Observations]\n    B2AI_TOPIC_5[Data]\n    B2AI_TOPIC_6[Demographics]\n    B2AI_TOPIC_7[Disease]\n    B2AI_TOPIC_8[Drug]\n    B2AI_TOPIC_9[EHR]\n    B2AI_TOPIC_10[EKG]\n    B2AI_TOPIC_11[Environment]\n    B2AI_TOPIC_12[Gene]\n    B2AI_TOPIC_13[Genome]\n    B2AI_TOPIC_14[Geolocation]\n    B2AI_TOPIC_15[Image]\n    B2AI_TOPIC_16[Literature]\n    B2AI_TOPIC_17[Metabolome]\n    B2AI_TOPIC_18[mHealth]\n    B2AI_TOPIC_19[Microscale Imaging]\n    B2AI_TOPIC_20[Molecular Biology]\n    B2AI_TOPIC_21[Networks And Pathways]\n    B2AI_TOPIC_22[Neurologic Imaging]\n    B2AI_TOPIC_23[Omics]\n    B2AI_TOPIC_24[Ophthalmic Imaging]\n    B2AI_TOPIC_25[Phenotype]\n    B2AI_TOPIC_26[Protein]\n    B2AI_TOPIC_27[Protein Structure Model]\n    B2AI_TOPIC_28[Proteome]\n    B2AI_TOPIC_29[SDoH]\n    B2AI_TOPIC_30[Social Media]\n    B2AI_TOPIC_31[Survey]\n    B2AI_TOPIC_32[Text]\n    B2AI_TOPIC_33[Transcript]\n    B2AI_TOPIC_34[Transcriptome]\n    B2AI_TOPIC_35[Variant]\n    B2AI_TOPIC_36[Voice]\n    B2AI_TOPIC_37[Waveform]\n    B2AI_TOPIC_38[Glucose Monitoring]\n    B2AI_TOPIC_39[Activity Monitoring]\n    B2AI_TOPIC_40[Governance]\n    B2AI_TOPIC_41[Neuron]\n    B2AI_TOPIC_42[Cardiomyocyte]\n    B2AI_TOPIC_43[Diabetes]\n    B2AI_TOPIC_44[Eye Diseases]\n    B2AI_TOPIC_45[Voice Disorders]\n    B2AI_TOPIC_46[Respiration]\n    B2AI_TOPIC_47[Respiratory Disorders]\n    B2AI_TOPIC_48[Neurology]\n    B2AI_TOPIC_49[Neurological Disorders]\n    B2AI_TOPIC_50[Psychiatry]\n    B2AI_TOPIC_51[Psychiatric Disorders]\n    B2AI_TOPIC_52[Training]\n    B2AI_TOPIC_1 --&gt; B2AI_TOPIC_11\n    B2AI_TOPIC_1 --&gt; B2AI_TOPIC_20\n    B2AI_TOPIC_1 --&gt; B2AI_TOPIC_46\n    B2AI_TOPIC_2 --&gt; B2AI_TOPIC_41\n    B2AI_TOPIC_2 --&gt; B2AI_TOPIC_42\n    B2AI_TOPIC_3 --&gt; B2AI_TOPIC_8\n    B2AI_TOPIC_4 --&gt; B2AI_TOPIC_9\n    B2AI_TOPIC_4 --&gt; B2AI_TOPIC_48\n    B2AI_TOPIC_4 --&gt; B2AI_TOPIC_50\n    B2AI_TOPIC_5 --&gt; B2AI_TOPIC_1\n    B2AI_TOPIC_5 --&gt; B2AI_TOPIC_3\n    B2AI_TOPIC_5 --&gt; B2AI_TOPIC_4\n    B2AI_TOPIC_5 --&gt; B2AI_TOPIC_6\n    B2AI_TOPIC_5 --&gt; B2AI_TOPIC_7\n    B2AI_TOPIC_5 --&gt; B2AI_TOPIC_14\n    B2AI_TOPIC_5 --&gt; B2AI_TOPIC_15\n    B2AI_TOPIC_5 --&gt; B2AI_TOPIC_18\n    B2AI_TOPIC_5 --&gt; B2AI_TOPIC_21\n    B2AI_TOPIC_5 --&gt; B2AI_TOPIC_25\n    B2AI_TOPIC_5 --&gt; B2AI_TOPIC_31\n    B2AI_TOPIC_5 --&gt; B2AI_TOPIC_32\n    B2AI_TOPIC_5 --&gt; B2AI_TOPIC_37\n    B2AI_TOPIC_5 --&gt; B2AI_TOPIC_40\n    B2AI_TOPIC_6 --&gt; B2AI_TOPIC_29\n    B2AI_TOPIC_7 --&gt; B2AI_TOPIC_43\n    B2AI_TOPIC_7 --&gt; B2AI_TOPIC_44\n    B2AI_TOPIC_7 --&gt; B2AI_TOPIC_45\n    B2AI_TOPIC_7 --&gt; B2AI_TOPIC_47\n    B2AI_TOPIC_12 --&gt; B2AI_TOPIC_35\n    B2AI_TOPIC_13 --&gt; B2AI_TOPIC_12\n    B2AI_TOPIC_15 --&gt; B2AI_TOPIC_19\n    B2AI_TOPIC_15 --&gt; B2AI_TOPIC_22\n    B2AI_TOPIC_15 --&gt; B2AI_TOPIC_24\n    B2AI_TOPIC_16 --&gt; B2AI_TOPIC_52\n    B2AI_TOPIC_18 --&gt; B2AI_TOPIC_38\n    B2AI_TOPIC_18 --&gt; B2AI_TOPIC_39\n    B2AI_TOPIC_20 --&gt; B2AI_TOPIC_2\n    B2AI_TOPIC_20 --&gt; B2AI_TOPIC_23\n    B2AI_TOPIC_23 --&gt; B2AI_TOPIC_13\n    B2AI_TOPIC_23 --&gt; B2AI_TOPIC_17\n    B2AI_TOPIC_23 --&gt; B2AI_TOPIC_28\n    B2AI_TOPIC_23 --&gt; B2AI_TOPIC_34\n    B2AI_TOPIC_26 --&gt; B2AI_TOPIC_27\n    B2AI_TOPIC_28 --&gt; B2AI_TOPIC_26\n    B2AI_TOPIC_32 --&gt; B2AI_TOPIC_16\n    B2AI_TOPIC_32 --&gt; B2AI_TOPIC_30\n    B2AI_TOPIC_34 --&gt; B2AI_TOPIC_33\n    B2AI_TOPIC_36 --&gt; B2AI_TOPIC_45\n    B2AI_TOPIC_37 --&gt; B2AI_TOPIC_10\n    B2AI_TOPIC_37 --&gt; B2AI_TOPIC_36\n    B2AI_TOPIC_46 --&gt; B2AI_TOPIC_47\n    B2AI_TOPIC_48 --&gt; B2AI_TOPIC_22\n    B2AI_TOPIC_48 --&gt; B2AI_TOPIC_49\n    B2AI_TOPIC_50 --&gt; B2AI_TOPIC_51\n\n    click B2AI_TOPIC_1 \"topics/Biology/\" \"Biology\"\n    click B2AI_TOPIC_2 \"topics/Cell/\" \"Cell\"\n    click B2AI_TOPIC_3 \"topics/Cheminformatics/\" \"Cheminformatics\"\n    click B2AI_TOPIC_4 \"topics/ClinicalObservations/\" \"Clinical Observations\"\n    click B2AI_TOPIC_5 \"topics/Data/\" \"Data\"\n    click B2AI_TOPIC_6 \"topics/Demographics/\" \"Demographics\"\n    click B2AI_TOPIC_7 \"topics/Disease/\" \"Disease\"\n    click B2AI_TOPIC_8 \"topics/Drug/\" \"Drug\"\n    click B2AI_TOPIC_9 \"topics/EHR/\" \"EHR\"\n    click B2AI_TOPIC_10 \"topics/EKG/\" \"EKG\"\n    click B2AI_TOPIC_11 \"topics/Environment/\" \"Environment\"\n    click B2AI_TOPIC_12 \"topics/Gene/\" \"Gene\"\n    click B2AI_TOPIC_13 \"topics/Genome/\" \"Genome\"\n    click B2AI_TOPIC_14 \"topics/Geolocation/\" \"Geolocation\"\n    click B2AI_TOPIC_15 \"topics/Image/\" \"Image\"\n    click B2AI_TOPIC_16 \"topics/Literature/\" \"Literature\"\n    click B2AI_TOPIC_17 \"topics/Metabolome/\" \"Metabolome\"\n    click B2AI_TOPIC_18 \"topics/mHealth/\" \"mHealth\"\n    click B2AI_TOPIC_19 \"topics/MicroscaleImaging/\" \"Microscale Imaging\"\n    click B2AI_TOPIC_20 \"topics/MolecularBiology/\" \"Molecular Biology\"\n    click B2AI_TOPIC_21 \"topics/NetworksAndPathways/\" \"Networks And Pathways\"\n    click B2AI_TOPIC_22 \"topics/NeurologicImaging/\" \"Neurologic Imaging\"\n    click B2AI_TOPIC_23 \"topics/Omics/\" \"Omics\"\n    click B2AI_TOPIC_24 \"topics/OphthalmicImaging/\" \"Ophthalmic Imaging\"\n    click B2AI_TOPIC_25 \"topics/Phenotype/\" \"Phenotype\"\n    click B2AI_TOPIC_26 \"topics/Protein/\" \"Protein\"\n    click B2AI_TOPIC_27 \"topics/ProteinStructureModel/\" \"Protein Structure Model\"\n    click B2AI_TOPIC_28 \"topics/Proteome/\" \"Proteome\"\n    click B2AI_TOPIC_29 \"topics/SDoH/\" \"SDoH\"\n    click B2AI_TOPIC_30 \"topics/SocialMedia/\" \"Social Media\"\n    click B2AI_TOPIC_31 \"topics/Survey/\" \"Survey\"\n    click B2AI_TOPIC_32 \"topics/Text/\" \"Text\"\n    click B2AI_TOPIC_33 \"topics/Transcript/\" \"Transcript\"\n    click B2AI_TOPIC_34 \"topics/Transcriptome/\" \"Transcriptome\"\n    click B2AI_TOPIC_35 \"topics/Variant/\" \"Variant\"\n    click B2AI_TOPIC_36 \"topics/Voice/\" \"Voice\"\n    click B2AI_TOPIC_37 \"topics/Waveform/\" \"Waveform\"\n    click B2AI_TOPIC_38 \"topics/GlucoseMonitoring/\" \"Glucose Monitoring\"\n    click B2AI_TOPIC_39 \"topics/ActivityMonitoring/\" \"Activity Monitoring\"\n    click B2AI_TOPIC_40 \"topics/Governance/\" \"Governance\"\n    click B2AI_TOPIC_41 \"topics/Neuron/\" \"Neuron\"\n    click B2AI_TOPIC_42 \"topics/Cardiomyocyte/\" \"Cardiomyocyte\"\n    click B2AI_TOPIC_43 \"topics/Diabetes/\" \"Diabetes\"\n    click B2AI_TOPIC_44 \"topics/EyeDiseases/\" \"Eye Diseases\"\n    click B2AI_TOPIC_45 \"topics/VoiceDisorders/\" \"Voice Disorders\"\n    click B2AI_TOPIC_46 \"topics/Respiration/\" \"Respiration\"\n    click B2AI_TOPIC_47 \"topics/RespiratoryDisorders/\" \"Respiratory Disorders\"\n    click B2AI_TOPIC_48 \"topics/Neurology/\" \"Neurology\"\n    click B2AI_TOPIC_49 \"topics/NeurologicalDisorders/\" \"Neurological Disorders\"\n    click B2AI_TOPIC_50 \"topics/Psychiatry/\" \"Psychiatry\"\n    click B2AI_TOPIC_51 \"topics/PsychiatricDisorders/\" \"Psychiatric Disorders\"\n    click B2AI_TOPIC_52 \"topics/Training/\" \"Training\"\n</code></pre>"},{"location":"Organization/","title":"Organizations in the Bridge2AI Standards Explorer","text":"<p>Organizations represented with entries in the Explorer are those using, managing, creating, and/or governing one or more data standards.</p> <p>All Organization identifiers have the prefix <code>B2AI_ORG</code>.</p> <p>These include the Bridge2AI Grand Challenges described below:</p> Full Name Short Name ID Data Documentation AI/ML for Clinical Care CHoRUS B2AI_ORG:115 CHoRUS for Equitable AI Functional Genomics CM4AI B2AI_ORG:116 CM4AI Product Documentation Precision Public Health Voice B2AI_ORG:117 Flagship Dataset of Voice as a Biomarker of Health Salutogenesis AI-READI B2AI_ORG:114 Flagship Dataset of Type 2 Diabetes from the AI-READI Project <p>Where possible, organizations are accompanied by the following identifiers:</p> <ul> <li> <p>A URL to a page providing more details about the organization.</p> </li> <li> <p>An identifier from the Research Organization Registry (ROR). These begin with the prefix <code>ror</code>. They may be resolved as a URL by appending the identifier to <code>https://ror.org</code>. For example, https://ror.org/02z468g17 leads to the ROR page for the Internet Archive.</p> </li> <li> <p>An identifier from Wikidata. These begin with the prefix <code>wikidata</code>. They may be resolved as a URL by appending the identifier to <code>https://www.wikidata.org/wiki/</code>. For example, https://www.wikidata.org/wiki/Q15028 leads to the Wikidata page for the International Organization for Standardization.</p> </li> </ul>"},{"location":"UseCase/","title":"Use Cases in the Bridge2AI Standards Explorer","text":"<p>The Bridge2AI project defines various use cases that represent different stages and activities in biomedical data workflows. These use cases are organized into categories and show relationships through enabling dependencies.</p>"},{"location":"UseCase/#use-case-categories","title":"Use Case Categories","text":"<p>The colors in the diagrams below represent different categories of use cases:</p> Acquisition: Use cases focused on obtaining and collecting data from various sources    Integration: Use cases that combine or link data from multiple sources    Standardization: Use cases that establish consistent formats and quality standards    Modeling: Use cases that develop analytical or predictive models from data"},{"location":"UseCase/#main-use-case-workflow","title":"Main Use Case Workflow","text":"<p>The following diagram shows the primary use case workflow with dependencies and relationships:</p> <pre><code>flowchart LR\n    B2AI_USECASE_1[\"Obtain patient data from records of clinical vi...\"]\n    B2AI_USECASE_2[\"Obtain image data from brain magnetic resonance...\"]\n    B2AI_USECASE_3[\"Obtain clinical waveform data from patients.\"]\n    B2AI_USECASE_4[\"Obtain image data from retinal and other ophtha...\"]\n    B2AI_USECASE_5[\"Obtain patient data from laboratory analysis, i...\"]\n    B2AI_USECASE_6[\"Obtain patient data from wearable devices.\"]\n    B2AI_USECASE_7[\"Obtain genomics data from patients.\"]\n    B2AI_USECASE_8[\"Obtain voice data from patients.\"]\n    B2AI_USECASE_9[\"Obtain social determinants of health data from ...\"]\n    B2AI_USECASE_10[\"Obtain molecular proximity observations from mi...\"]\n    B2AI_USECASE_11[\"Obtain proteome data from human cell samples.\"]\n    B2AI_USECASE_12[\"Obtain transcriptome data from human cell popul...\"]\n    B2AI_USECASE_13[\"Integrate clinical record data with voice data.\"]\n    B2AI_USECASE_16[\"Link cellular objects to functions through asso...\"]\n    B2AI_USECASE_17[\"Standardize clinical record data collected from...\"]\n    B2AI_USECASE_18[\"Standardize clinical waveform data collected fr...\"]\n    B2AI_USECASE_19[\"Standardize clinical image data collected from ...\"]\n    B2AI_USECASE_20[\"Standardize clinical omics data collected from ...\"]\n    B2AI_USECASE_22[\"Assemble standards for voice data.\"]\n    B2AI_USECASE_24[\"Develop multi-scale maps of human cell architec...\"]\n    B2AI_USECASE_25[\"Develop models of clinical image data.\"]\n    B2AI_USECASE_26[\"Develop pseudotime patient models of health and...\"]\n    B2AI_USECASE_27[\"Deploy a Federated Learning System for analysis...\"]\n    B2AI_USECASE_28[\"Develop cross-sectional AI models of relationsh...\"]\n    B2AI_USECASE_29[\"Develop predictive models of insulin dependence...\"]\n    B2AI_USECASE_30[\"Test and deploy analytical models of clinical i...\"]\n    B2AI_USECASE_31[\"Develop software and cloud infrastructure for a...\"]\n    B2AI_USECASE_32[\"Build a database of human voice samples and ass...\"]\n\n    %% Workflow relationships\n    B2AI_USECASE_1 --&gt; B2AI_USECASE_5\n    B2AI_USECASE_1 --&gt; B2AI_USECASE_13\n    B2AI_USECASE_1 --&gt; B2AI_USECASE_17\n    B2AI_USECASE_1 --&gt; B2AI_USECASE_19\n    B2AI_USECASE_2 --&gt; B2AI_USECASE_19\n    B2AI_USECASE_3 --&gt; B2AI_USECASE_18\n    B2AI_USECASE_4 --&gt; B2AI_USECASE_19\n    B2AI_USECASE_4 --&gt; B2AI_USECASE_26\n    B2AI_USECASE_5 --&gt; B2AI_USECASE_17\n    B2AI_USECASE_6 --&gt; B2AI_USECASE_17\n    B2AI_USECASE_6 --&gt; B2AI_USECASE_26\n    B2AI_USECASE_6 --&gt; B2AI_USECASE_28\n    B2AI_USECASE_7 --&gt; B2AI_USECASE_20\n    B2AI_USECASE_7 --&gt; B2AI_USECASE_26\n    B2AI_USECASE_7 --&gt; B2AI_USECASE_28\n    B2AI_USECASE_7 --&gt; B2AI_USECASE_29\n    B2AI_USECASE_8 --&gt; B2AI_USECASE_13\n    B2AI_USECASE_8 --&gt; B2AI_USECASE_22\n    B2AI_USECASE_8 --&gt; B2AI_USECASE_27\n    B2AI_USECASE_8 --&gt; B2AI_USECASE_31\n    B2AI_USECASE_9 --&gt; B2AI_USECASE_17\n    B2AI_USECASE_9 --&gt; B2AI_USECASE_26\n    B2AI_USECASE_9 --&gt; B2AI_USECASE_28\n    B2AI_USECASE_9 --&gt; B2AI_USECASE_29\n    B2AI_USECASE_10 --&gt; B2AI_USECASE_16\n    B2AI_USECASE_11 --&gt; B2AI_USECASE_16\n    B2AI_USECASE_12 --&gt; B2AI_USECASE_16\n    B2AI_USECASE_13 --&gt; B2AI_USECASE_17\n    B2AI_USECASE_16 --&gt; B2AI_USECASE_24\n    B2AI_USECASE_17 --&gt; B2AI_USECASE_26\n    B2AI_USECASE_17 --&gt; B2AI_USECASE_28\n    B2AI_USECASE_17 --&gt; B2AI_USECASE_29\n    B2AI_USECASE_19 --&gt; B2AI_USECASE_25\n    B2AI_USECASE_19 --&gt; B2AI_USECASE_30\n    B2AI_USECASE_22 --&gt; B2AI_USECASE_31\n    B2AI_USECASE_22 --&gt; B2AI_USECASE_32\n    B2AI_USECASE_25 --&gt; B2AI_USECASE_30\n\n    style B2AI_USECASE_1 fill:#e1f5fe\n    style B2AI_USECASE_2 fill:#e1f5fe\n    style B2AI_USECASE_3 fill:#e1f5fe\n    style B2AI_USECASE_4 fill:#e1f5fe\n    style B2AI_USECASE_5 fill:#e1f5fe\n    style B2AI_USECASE_6 fill:#e1f5fe\n    style B2AI_USECASE_7 fill:#e1f5fe\n    style B2AI_USECASE_8 fill:#e1f5fe\n    style B2AI_USECASE_9 fill:#e1f5fe\n    style B2AI_USECASE_10 fill:#e1f5fe\n    style B2AI_USECASE_11 fill:#e1f5fe\n    style B2AI_USECASE_12 fill:#e1f5fe\n    style B2AI_USECASE_13 fill:#f3e5f5\n    style B2AI_USECASE_16 fill:#f3e5f5\n    style B2AI_USECASE_17 fill:#e8f5e8\n    style B2AI_USECASE_18 fill:#e8f5e8\n    style B2AI_USECASE_19 fill:#e8f5e8\n    style B2AI_USECASE_20 fill:#e8f5e8\n    style B2AI_USECASE_22 fill:#e8f5e8\n    style B2AI_USECASE_24 fill:#fff3e0\n    style B2AI_USECASE_25 fill:#fff3e0\n    style B2AI_USECASE_26 fill:#fff3e0\n\n    click B2AI_USECASE_1 \"../usecases/obtain-patient-data-from-records-of-clinical-visits/\" \"Obtain patient data from records of clinical visits.\"\n    click B2AI_USECASE_2 \"../usecases/obtain-image-data-from-brain-magnetic-resonance-imaging/\" \"Obtain image data from brain magnetic resonance imaging.\"\n    click B2AI_USECASE_3 \"../usecases/obtain-clinical-waveform-data-from-patients/\" \"Obtain clinical waveform data from patients.\"\n    click B2AI_USECASE_4 \"../usecases/obtain-image-data-from-retinal-and-other-ophthalmic-imaging/\" \"Obtain image data from retinal and other ophthalmic imaging.\"\n    click B2AI_USECASE_5 \"../usecases/obtain-patient-data-from-laboratory-analysis-including-serological-testing-and-urinalysis/\" \"Obtain patient data from laboratory analysis, including serological testing and urinalysis.\"\n    click B2AI_USECASE_6 \"../usecases/obtain-patient-data-from-wearable-devices/\" \"Obtain patient data from wearable devices.\"\n    click B2AI_USECASE_7 \"../usecases/obtain-genomics-data-from-patients/\" \"Obtain genomics data from patients.\"\n    click B2AI_USECASE_8 \"../usecases/obtain-voice-data-from-patients/\" \"Obtain voice data from patients.\"\n    click B2AI_USECASE_9 \"../usecases/obtain-social-determinants-of-health-data-from-patients/\" \"Obtain social determinants of health data from patients.\"\n    click B2AI_USECASE_10 \"../usecases/obtain-molecular-proximity-observations-from-microscopy-images-of-human-cells/\" \"Obtain molecular proximity observations from microscopy images of human cells.\"\n    click B2AI_USECASE_11 \"../usecases/obtain-proteome-data-from-human-cell-samples/\" \"Obtain proteome data from human cell samples.\"\n    click B2AI_USECASE_12 \"../usecases/obtain-transcriptome-data-from-human-cell-populations-perturbed-through-crispr-driven-mutagenesis/\" \"Obtain transcriptome data from human cell populations perturbed through CRISPR-driven mutagenesis.\"\n    click B2AI_USECASE_13 \"../usecases/integrate-clinical-record-data-with-voice-data/\" \"Integrate clinical record data with voice data.\"\n    click B2AI_USECASE_16 \"../usecases/link-cellular-objects-to-functions-through-associations-between-proteins-cell-structure-proximity-and-transcriptomics/\" \"Link cellular objects to functions through associations between proteins, cell structure proximity, and transcriptomics.\"\n    click B2AI_USECASE_17 \"../usecases/standardize-clinical-record-data-collected-from-multiple-sites-and-sources/\" \"Standardize clinical record data collected from multiple sites and sources.\"\n    click B2AI_USECASE_18 \"../usecases/standardize-clinical-waveform-data-collected-from-multiple-sites-and-sources/\" \"Standardize clinical waveform data collected from multiple sites and sources.\"\n    click B2AI_USECASE_19 \"../usecases/standardize-clinical-image-data-collected-from-multiple-sites-and-sources/\" \"Standardize clinical image data collected from multiple sites and sources.\"\n    click B2AI_USECASE_20 \"../usecases/standardize-clinical-omics-data-collected-from-multiple-sites-and-sources/\" \"Standardize clinical omics data collected from multiple sites and sources.\"\n    click B2AI_USECASE_22 \"../usecases/assemble-standards-for-voice-data/\" \"Assemble standards for voice data.\"\n    click B2AI_USECASE_24 \"../usecases/develop-multi-scale-maps-of-human-cell-architecture/\" \"Develop multi-scale maps of human cell architecture.\"\n    click B2AI_USECASE_25 \"../usecases/develop-models-of-clinical-image-data/\" \"Develop models of clinical image data.\"\n    click B2AI_USECASE_26 \"../usecases/develop-pseudotime-patient-models-of-health-and-salutogenesis/\" \"Develop pseudotime patient models of health and salutogenesis.\"\n    click B2AI_USECASE_27 \"../usecases/deploy-a-federated-learning-system-for-analysis-of-voice-data/\" \"Deploy a Federated Learning System for analysis of voice data.\"\n    click B2AI_USECASE_28 \"../usecases/develop-cross-sectional-ai-models-of-relationships-between-diabetes-severity-cognitive-function-and-presence-of-biomarkers/\" \"Develop cross-sectional AI models of relationships between diabetes severity, cognitive function, and presence of biomarkers.\"\n    click B2AI_USECASE_29 \"../usecases/develop-predictive-models-of-insulin-dependence-and-salutogenesis/\" \"Develop predictive models of insulin dependence and salutogenesis.\"\n    click B2AI_USECASE_30 \"../usecases/test-and-deploy-analytical-models-of-clinical-image-data/\" \"Test and deploy analytical models of clinical image data.\"\n    click B2AI_USECASE_31 \"../usecases/develop-software-and-cloud-infrastructure-for-automated-voice-data-collection-through-a-smartphone-application/\" \"Develop software and cloud infrastructure for automated voice data collection through a smartphone application.\"\n    click B2AI_USECASE_32 \"../usecases/build-a-database-of-human-voice-samples-and-associations-with-biomarkers-of-health/\" \"Build a database of human voice samples and associations with biomarkers of health.\"\n</code></pre>"},{"location":"UseCase/#standalone-use-cases","title":"Standalone Use Cases","text":"<p>The following use cases operate independently without direct dependencies on other use cases:</p> <pre><code>flowchart LR\n    subgraph integration_standalone [\"Integration\"]\n        direction LR\n        B2AI_USECASE_14[\"Transform data from OMOP to the i2b2 standard.\"]\n        B2AI_USECASE_15[\"Produce artifacts that map identifiers between ...\"]\n        B2AI_USECASE_40[\"Transform FHIR data to TSV.\"]\n    end\n    subgraph standardization_standalone [\"Standardization\"]\n        direction LR\n        B2AI_USECASE_21[\"Assemble standards for integrated maps of human...\"]\n        B2AI_USECASE_23[\"Construct standards for computational provenance.\"]\n    end\n    subgraph application_standalone [\"Application\"]\n        direction LR\n        B2AI_USECASE_33[\"Build a relational database of arbitrary data t...\"]\n        B2AI_USECASE_34[\"Query a relational database of arbitrary data t...\"]\n        B2AI_USECASE_35[\"Build a graph database of arbitrary data types.\"]\n        B2AI_USECASE_36[\"Query a graph database of arbitrary data types.\"]\n    end\n    subgraph modeling_standalone [\"Modeling\"]\n        direction LR\n        B2AI_USECASE_37[\"Train a linear regression model on data in an R...\"]\n        B2AI_USECASE_38[\"Train a binary classification model on data in ...\"]\n        B2AI_USECASE_39[\"Train a neural network model on tensor data.\"]\n    end\n    subgraph assessment_standalone [\"Assessment\"]\n        direction LR\n        B2AI_USECASE_41[\"Determine whether enough data is available to t...\"]\n        B2AI_USECASE_42[\"Assess the quality of a computational model in ...\"]\n        B2AI_USECASE_43[\"Assess the potential bias in a computational mo...\"]\n        B2AI_USECASE_44[\"Assess the explainability of a computational mo...\"]\n    end\n\n    style B2AI_USECASE_14 fill:#f3e5f5\n    style B2AI_USECASE_15 fill:#f3e5f5\n    style B2AI_USECASE_40 fill:#f3e5f5\n    style B2AI_USECASE_21 fill:#e8f5e8\n    style B2AI_USECASE_23 fill:#e8f5e8\n    style B2AI_USECASE_37 fill:#fff3e0\n    style B2AI_USECASE_38 fill:#fff3e0\n    style B2AI_USECASE_39 fill:#fff3e0\n\n    click B2AI_USECASE_14 \"../usecases/transform-data-from-omop-to-the-i2b2-standard/\" \"Transform data from OMOP to the i2b2 standard.\"\n    click B2AI_USECASE_15 \"../usecases/produce-artifacts-that-map-identifiers-between-source-and-standardized-data-representations/\" \"Produce artifacts that map identifiers between source and standardized data representations.\"\n    click B2AI_USECASE_21 \"../usecases/assemble-standards-for-integrated-maps-of-human-cell-architecture/\" \"Assemble standards for integrated maps of human cell architecture.\"\n    click B2AI_USECASE_23 \"../usecases/construct-standards-for-computational-provenance/\" \"Construct standards for computational provenance.\"\n    click B2AI_USECASE_33 \"../usecases/build-a-relational-database-of-arbitrary-data-types/\" \"Build a relational database of arbitrary data types.\"\n    click B2AI_USECASE_34 \"../usecases/query-a-relational-database-of-arbitrary-data-types/\" \"Query a relational database of arbitrary data types.\"\n    click B2AI_USECASE_35 \"../usecases/build-a-graph-database-of-arbitrary-data-types/\" \"Build a graph database of arbitrary data types.\"\n    click B2AI_USECASE_36 \"../usecases/query-a-graph-database-of-arbitrary-data-types/\" \"Query a graph database of arbitrary data types.\"\n    click B2AI_USECASE_37 \"../usecases/train-a-linear-regression-model-on-data-in-an-r-tibble/\" \"Train a linear regression model on data in an R tibble.\"\n    click B2AI_USECASE_38 \"../usecases/train-a-binary-classification-model-on-data-in-one-or-more-bioconductor-objects/\" \"Train a binary classification model on data in one or more Bioconductor objects.\"\n    click B2AI_USECASE_39 \"../usecases/train-a-neural-network-model-on-tensor-data/\" \"Train a neural network model on tensor data.\"\n    click B2AI_USECASE_40 \"../usecases/transform-fhir-data-to-tsv/\" \"Transform FHIR data to TSV.\"\n    click B2AI_USECASE_41 \"../usecases/determine-whether-enough-data-is-available-to-train-a-computational-model-of-interest/\" \"Determine whether enough data is available to train a computational model of interest.\"\n    click B2AI_USECASE_42 \"../usecases/assess-the-quality-of-a-computational-model-in-terms-of-its-ability-to-complete-a-specific-task/\" \"Assess the quality of a computational model in terms of its ability to complete a specific task.\"\n    click B2AI_USECASE_43 \"../usecases/assess-the-potential-bias-in-a-computational-model/\" \"Assess the potential bias in a computational model.\"\n    click B2AI_USECASE_44 \"../usecases/assess-the-explainability-of-a-computational-model/\" \"Assess the explainability of a computational model.\"\n</code></pre>"},{"location":"ai-access/","title":"AI Access to the Standards Explorer","text":"<p>The Bridge2AI Standards Explorer can be accessed by AI agents and Large Language Models (LLMs) through the Standards Explorer MCP. This enables AI assistants like Claude, ChatGPT, and others to search, query, and retrieve standards information in real-time.</p>"},{"location":"ai-access/#what-is-mcp","title":"What is MCP?","text":"<p>Model Context Protocol (MCP) is an open protocol that standardizes how AI applications connect to external data sources and tools. Think of it as a universal adapter that lets AI assistants access databases, APIs, and services in a consistent way.</p>"},{"location":"ai-access/#standards-explorer-mcp-server","title":"Standards Explorer MCP Server","text":"<p>The Standards Explorer MCP Server provides AI agents with tools to:</p> <ul> <li>\ud83d\udd0d Search standards by name, description, or any text field</li> <li>\ud83d\udcca Execute SQL queries directly against the Standards Explorer tables (standards, topics, substrates, organizations)</li> <li>\ud83c\udfaf Filter by topic, organization, or data substrate</li> <li>\ud83d\udcd6 Retrieve detailed information about specific standards</li> <li>\ud83d\udd04 Browse paginated results for large result sets</li> </ul> <p>No API key is required.</p>"},{"location":"ai-access/#quick-start","title":"Quick Start","text":""},{"location":"ai-access/#installation","title":"Installation","text":"<p>Depending on the software you use to work with AI agents, you may not need to install the MCP on its own.</p> <p>Feel free to skip to the next section if you are not certain.</p> <p>The MCP server requires Python 3.9+ and can be installed using <code>uv</code> or <code>pip</code>:</p> <pre><code># Using uv (recommended)\nuv pip install standards-explorer-mcp\n\n# Or using pip\npip install standards-explorer-mcp\n</code></pre>"},{"location":"ai-access/#using-the-mcp-with-agentic-frameworks","title":"Using the MCP with Agentic Frameworks","text":""},{"location":"ai-access/#using-with-claude-desktop","title":"Using with Claude Desktop","text":"<p>Claude Desktop has native MCP support. To add the Standards Explorer:</p> <ol> <li>Locate your Claude Desktop config file:</li> <li>macOS: <code>~/Library/Application Support/Claude/claude_desktop_config.json</code></li> <li>Windows: <code>%APPDATA%\\Claude\\claude_desktop_config.json</code></li> <li> <p>Linux: <code>~/.config/Claude/claude_desktop_config.json</code></p> </li> <li> <p>Add the Standards Explorer MCP server:</p> </li> </ol> <pre><code>{\n  \"mcpServers\": {\n    \"standards-explorer\": {\n      \"command\": \"uvx\",\n      \"args\": [\"standards-explorer-mcp\"]\n    }\n  }\n}\n</code></pre> <ol> <li> <p>Restart Claude Desktop</p> </li> <li> <p>Verify it's working: Look for the \ud83d\udd0c icon in Claude Desktop, or ask Claude:</p> <p>\"Can you search the Bridge2AI Standards Explorer for FHIR standards?\"</p> </li> </ol>"},{"location":"ai-access/#using-with-vscode-github-copilot-chat","title":"Using with VSCode (GitHub Copilot Chat)","text":"<p>VSCode with GitHub Copilot supports MCP servers through the Copilot Chat interface.</p> <ol> <li>Install the MCP extension for VSCode:</li> <li>Open VSCode Extensions (Ctrl+Shift+X / Cmd+Shift+X)</li> <li>Search for \"Model Context Protocol\"</li> <li> <p>Install the MCP extension</p> </li> <li> <p>Configure the MCP server:</p> </li> <li>Open VSCode Settings (Ctrl+, / Cmd+,)</li> <li>Search for \"MCP Servers\"</li> <li>Add the Standards Explorer configuration:</li> </ol> <pre><code>{\n  \"mcp.servers\": {\n    \"standards-explorer\": {\n      \"command\": \"uvx\",\n      \"args\": [\"standards-explorer-mcp\"]\n    }\n  }\n}\n</code></pre> <ol> <li> <p>Restart VSCode</p> </li> <li> <p>Use in Copilot Chat: Open Copilot Chat (Ctrl+Alt+I / Cmd+Option+I) and ask:</p> <p>\"@standards-explorer Find standards related to FHIR\"</p> </li> </ol> <p>Note: MCP support in VSCode/GitHub Copilot may require specific versions or preview features. Check the GitHub Copilot documentation for the latest information.</p>"},{"location":"ai-access/#using-with-goose","title":"Using with Goose","text":"<p>Goose is an AI developer agent that runs in your terminal. It has native MCP support.</p> <ol> <li> <p>Install Goose: <pre><code># Install via pip\npip install goose-ai\n\n# Or via homebrew (macOS)\nbrew install goose-ai\n</code></pre></p> </li> <li> <p>Configure the MCP server:</p> </li> </ol> <p>Create or edit <code>~/.config/goose/config.yaml</code>:</p> <pre><code>mcp_servers:\n  standards-explorer:\n    command: uvx\n    args:\n      - standards-explorer-mcp\n</code></pre> <ol> <li> <p>Run Goose: <pre><code>goose session start\n</code></pre></p> </li> <li> <p>Use the Standards Explorer: In the Goose session, ask:</p> <p>\"Use the standards-explorer to find genomics standards\"</p> </li> </ol> <p>\"Query the Bridge2AI Standards Explorer for HL7 standards\"</p> <p>Goose will automatically use the MCP server to access the Standards Explorer data.</p>"},{"location":"ai-access/#using-with-other-ai-applications","title":"Using with Other AI Applications","text":"<p>The MCP server uses the standard Model Context Protocol, so it works with any MCP-compatible AI application:</p> <pre><code>from fastmcp import Client\n\nasync with Client(\"standards-explorer-mcp\") as client:\n    # Search for standards\n    result = await client.call_tool(\n        \"search_standards\",\n        {\"search_text\": \"FHIR\", \"max_results\": 5}\n    )\n    print(result.data)\n</code></pre>"},{"location":"ai-access/#available-tools","title":"Available Tools","text":"<p>The MCP server provides several tools that AI agents can use:</p>"},{"location":"ai-access/#1-search_standards","title":"1. <code>search_standards</code>","text":"<p>Search for standards by text across multiple fields.</p> <p>Parameters: - <code>search_text</code> (required): Text to search for - <code>columns_to_search</code> (optional): Specific columns to search (default: name, description) - <code>max_results</code> (optional): Maximum results to return (default: 10) - <code>offset</code> (optional): Skip this many results for pagination (default: 0) - <code>include_topic_search</code> (optional): Also search by topic name (default: true) - <code>include_substrate_search</code> (optional): Also search by substrate name (default: true) - <code>include_organization_search</code> (optional): Also search by organization name (default: true)</p> <p>Example queries you can ask: - \"Find standards related to FHIR\" - \"Search for genomics standards\" - \"Show me standards from HL7\" - \"What standards work with JSON?\"</p>"},{"location":"ai-access/#2-query_table","title":"2. <code>query_table</code>","text":"<p>Execute custom SQL queries against the Standards Explorer tables.</p> <p>Parameters: - <code>sql_query</code> (required): SQL query to execute - <code>max_wait_seconds</code> (optional): Maximum wait time (default: 30)</p> <p>Example SQL queries: <pre><code>-- Find open standards\nSELECT id, name, is_open FROM syn63096833 WHERE is_open = 'true' LIMIT 10\n\n-- Search by description\nSELECT id, name, description FROM syn63096833 \nWHERE description LIKE '%metadata%' LIMIT 5\n\n-- Filter by category\nSELECT name, category FROM syn63096833 \nWHERE category = 'B2AI_STANDARD:BiomedicalStandard' LIMIT 20\n</code></pre></p>"},{"location":"ai-access/#3-search_by_topic","title":"3. <code>search_by_topic</code>","text":"<p>Find standards related to a specific data topic.</p> <p>Parameters: - <code>topic_name</code> (required): Name of the topic (e.g., \"EHR\", \"Genomics\", \"Image\") - <code>max_results</code> (optional): Maximum results (default: 20)</p> <p>Example queries: - \"Find standards for EHR data\" - \"What standards concern genomics?\" - \"Show me imaging standards\"</p>"},{"location":"ai-access/#4-search_by_substrate","title":"4. <code>search_by_substrate</code>","text":"<p>Find standards that work with specific data formats or structures.</p> <p>Parameters: - <code>substrate_name</code> (required): Name of the substrate (e.g., \"JSON\", \"CSV\", \"BIDS\") - <code>max_results</code> (optional): Maximum results (default: 20)</p> <p>Example queries: - \"Find standards that use JSON\" - \"What standards work with CSV files?\" - \"Show me BIDS-compatible standards\"</p>"},{"location":"ai-access/#5-search_by_organization","title":"5. <code>search_by_organization</code>","text":"<p>Find standards associated with specific organizations.</p> <p>Parameters: - <code>organization_name</code> (required): Name of the organization (e.g., \"HL7\", \"W3C\", \"CDISC\") - <code>max_results</code> (optional): Maximum results (default: 20) - <code>search_responsible_only</code> (optional): Only search responsible organizations (default: false)</p> <p>Example queries: - \"What standards does HL7 maintain?\" - \"Find W3C standards\" - \"Show me CDISC standards\"</p>"},{"location":"ai-access/#6-list_topics-list_substrates-list_organizations","title":"6. <code>list_topics</code> / <code>list_substrates</code> / <code>list_organizations</code>","text":"<p>Get complete lists of available topics, substrates, or organizations.</p> <p>Example queries: - \"What topics are available in the Standards Explorer?\" - \"List all data substrates\" - \"Show me all organizations\"</p>"},{"location":"ai-access/#7-get_standards_table_info","title":"7. <code>get_standards_table_info</code>","text":"<p>Get metadata about the Standards Explorer tables and project.</p>"},{"location":"ai-access/#example-conversations","title":"Example Conversations","text":"<p>Here are examples of how you might interact with an AI assistant using the MCP server:</p>"},{"location":"ai-access/#example-1-finding-healthcare-standards","title":"Example 1: Finding Healthcare Standards","text":"<p>You: \"Can you find healthcare interoperability standards?\"</p> <p>AI: Uses <code>search_standards</code> with \"healthcare interoperability\"</p> <p>\"I found several healthcare interoperability standards:</p> <ol> <li>FHIR (Fast Healthcare Interoperability Resources) - A standard for exchanging healthcare information electronically</li> <li>HL7 v2 - Messaging standard for healthcare data exchange</li> <li>HL7 CDA - Clinical Document Architecture for medical documents ...\"</li> </ol>"},{"location":"ai-access/#example-2-finding-standards-by-organization","title":"Example 2: Finding Standards by Organization","text":"<p>You: \"What standards does the W3C maintain?\"</p> <p>AI: Uses <code>search_by_organization</code> with \"W3C\"</p> <p>\"The W3C (World Wide Web Consortium) is responsible for several standards in the Explorer:</p> <ol> <li>RDF - Resource Description Framework</li> <li>JSON-LD - JSON for Linking Data</li> <li>PROV-O - Provenance Ontology ...\"</li> </ol>"},{"location":"ai-access/#example-3-topic-based-search","title":"Example 3: Topic-Based Search","text":"<p>You: \"Show me standards for genomic data\"</p> <p>AI: Uses <code>search_by_topic</code> with \"Genomics\"</p> <p>\"Here are standards that concern genomic data:</p> <ol> <li>VCF - Variant Call Format</li> <li>FASTQ - Format for storing biological sequences</li> <li>BAM/SAM - Binary/Sequence Alignment Map formats ...\"</li> </ol>"},{"location":"ai-access/#example-4-custom-sql-query","title":"Example 4: Custom SQL Query","text":"<p>You: \"Find all open-source standards that work with imaging data\"</p> <p>AI: Uses <code>query_table</code> with a SQL query joining multiple criteria</p> <p>\"I found 15 open-source imaging standards:</p> <ol> <li>NIfTI - Neuroimaging Informatics Technology Initiative format</li> <li>DICOM - Digital Imaging and Communications in Medicine</li> <li>BIDS - Brain Imaging Data Structure ...\"</li> </ol>"},{"location":"ai-access/#advanced-usage","title":"Advanced Usage","text":""},{"location":"ai-access/#running-the-server-standalone","title":"Running the Server Standalone","text":"<p>For development or debugging, you can run the MCP server directly:</p> <pre><code># Start the server\nuv run standards-explorer-mcp\n\n# Or with Python\npython -m standards_explorer_mcp\n</code></pre> <p>The server communicates via stdio using the MCP protocol.</p>"},{"location":"ai-access/#authentication-optional","title":"Authentication (Optional)","text":"<p>The server accesses public Synapse tables and does not require authentication. However, if you need authenticated access for private tables (e.g., if you want to access Standards Explorer data alongside other data on Synapse):</p> <pre><code># Set your Synapse Personal Access Token\nexport SYNAPSE_AUTH_TOKEN=\"your_token_here\"\n\n# Then run the server\nuv run standards-explorer-mcp\n</code></pre> <p>To get a Synapse Personal Access Token: 1. Log in to Synapse 2. Go to Account Settings \u2192 Personal Access Tokens 3. Create a new token with view/download scopes</p>"},{"location":"ai-access/#testing-the-server","title":"Testing the Server","text":"<p>The repository includes tests you can run:</p> <pre><code># Clone the repository\ngit clone https://github.com/bridge2ai/standards-explorer-mcp.git\ncd standards-explorer-mcp\n\n# Install with dev dependencies\nuv pip install -e \".[dev]\"\n\n# Run tests\nuv run pytest tests/ -v\n\n# Run with coverage\nuv run pytest tests/ --cov=src/standards_explorer_mcp --cov-report=html\n</code></pre>"},{"location":"ai-access/#technical-details","title":"Technical Details","text":""},{"location":"ai-access/#architecture","title":"Architecture","text":"<p>The MCP server uses the Synapse Table Query API with an async job pattern:</p> <ol> <li>Start Query: POST to <code>/entity/{id}/table/query/async/start</code> \u2192 returns async token</li> <li>Poll for Results: GET <code>/entity/{id}/table/query/async/get/{token}</code> </li> <li>Returns 202 while processing</li> <li>Returns 200 with results when complete</li> <li>Automatic Retry: Server polls every 1 second with configurable timeout</li> </ol>"},{"location":"ai-access/#tables-accessed","title":"Tables Accessed","text":"<ul> <li><code>syn63096833</code> - DataStandardOrTool (main standards table)</li> <li><code>syn63096835</code> - DataTopics (topics/domains)</li> <li><code>syn63096834</code> - DataSubstrate (data formats)</li> <li><code>syn63096836</code> - Organization (organizations)</li> <li><code>syn63096806</code> - Project container</li> </ul>"},{"location":"ai-access/#implementation","title":"Implementation","text":"<p>Built with: - FastMCP (v2.12.5+) - MCP server framework - httpx (v0.27.0+) - Async HTTP client - Python 3.9+ - Runtime environment</p> <p>The server separates business logic from MCP decorators for easy testing and maintenance.</p>"},{"location":"ai-access/#troubleshooting","title":"Troubleshooting","text":""},{"location":"ai-access/#server-not-starting","title":"Server Not Starting","text":"<p>Problem: MCP server fails to start in Claude Desktop</p> <p>Solutions: - Check that <code>uvx</code> is installed: <code>uv --version</code> - Verify the config file syntax is valid JSON - Check Claude Desktop logs for error messages - Try running <code>uvx standards-explorer-mcp</code> manually to test</p>"},{"location":"ai-access/#no-tools-appearing","title":"No Tools Appearing","text":"<p>Problem: AI assistant doesn't show Standards Explorer tools</p> <p>Solutions: - Restart Claude Desktop after editing config - Look for the \ud83d\udd0c icon to confirm MCP connection - Check that the server process is running - Verify network access to <code>repo-prod.prod.sagebase.org</code></p>"},{"location":"ai-access/#queries-timing-out","title":"Queries Timing Out","text":"<p>Problem: Queries take too long or timeout</p> <p>Solutions: - Increase <code>max_wait_seconds</code> parameter - Use LIMIT clauses to reduce result size - Check internet connection to Synapse API - Try simpler queries first to verify connectivity</p>"},{"location":"ai-access/#search-returns-no-results","title":"Search Returns No Results","text":"<p>Problem: Searches don't find expected standards</p> <p>Solutions: - Try broader search terms - Use <code>list_topics</code> or <code>list_substrates</code> to see available options - Check spelling of organization/topic names - Use <code>query_table</code> with SQL LIKE for flexible matching</p>"},{"location":"ai-access/#resources","title":"Resources","text":"<ul> <li>MCP Server Repository: github.com/bridge2ai/standards-explorer-mcp</li> <li>Model Context Protocol: modelcontextprotocol.io</li> <li>FastMCP Documentation: gofastmcp.com</li> <li>Claude Desktop MCP Guide: Anthropic MCP Documentation</li> <li>Synapse REST API: rest-docs.synapse.org</li> <li>Standards Explorer on Synapse: synapse.org/Synapse:syn63096806</li> </ul>"},{"location":"ai-access/#support","title":"Support","text":"<p>For questions or issues: - MCP Server Issues: GitHub Issues - Standards Explorer Content: b2ai-standards-registry Issues - FastMCP Support: FastMCP Discord - Synapse API Support: help.synapse.org</p>"},{"location":"ai-access/#next-steps","title":"Next Steps","text":"<p>After setting up the MCP server:</p> <ol> <li>Try basic searches: Ask your AI assistant to search for familiar standards</li> <li>Explore topics: Use <code>list_topics</code> to see what domains are covered</li> <li>Experiment with SQL: Try custom queries for specific use cases</li> <li>Combine with other tools: Use Standards Explorer data alongside other MCP servers</li> <li>Provide feedback: Report issues or suggest features on GitHub</li> </ol> <p>For programmatic access without AI agents, see Programmatic Access.</p>"},{"location":"categories/","title":"Categories in the Bridge2AI Standards Explorer","text":"<p>The Bridge2AI Standards Explorer categorizes data standards and tools into several categories. Each category represents a specific type of standard or tool with its own unique characteristics and purposes.</p> <p>The Explorer also contains metadata on other concepts and objects, including data sets, topics, substrates, organizations, and use cases. See the menu on the left for more information about these entries.</p>"},{"location":"categories/#data-standard-or-tool-classes","title":"Data Standard or Tool Classes","text":""},{"location":"categories/#data-standard-or-tool","title":"Data Standard or Tool","text":"<p>The base class for all standards and tools in the Explorer. In practice, no resource will have this category, but will be assigned one of the categories below.</p> <p>Each standard or tool may:</p> <ul> <li> <p>Be associated with data topics</p> </li> <li> <p>Have relevant organizations</p> </li> <li> <p>Have training resources</p> </li> <li> <p>Include details like openness status, registration requirements, URLs, and publications</p> </li> </ul>"},{"location":"categories/#data-standard","title":"Data Standard","text":"<p>A general purpose data. This represents specifications, schemas, or guidelines for data management. It may not have been developed specifically for biomedical or biological research data, but is relevant to data science more broadly or has been adopted for specific research purposes.</p>"},{"location":"categories/#biomedical-standard","title":"Biomedical Standard","text":"<p>A specialized standard with particular applications or relevance to clinical or biomedical research purposes. These standards address the unique needs of biomedical data.</p>"},{"location":"categories/#registry","title":"Registry","text":"<p>A resource that serves to curate and/or index other resources. Registries provide a centralized location to discover and access other standards or tools.</p>"},{"location":"categories/#ontology-or-vocabulary","title":"Ontology Or Vocabulary","text":"<p>A set of concepts and categories, potentially defined or accompanied by their hierarchical relationships. These provide standardized terminologies and semantics for consistent data annotation.</p>"},{"location":"categories/#model-repository","title":"Model Repository","text":"<p>A resource serving to curate and store computational models. Unlike registries that may only index models, a model repository must provide storage functionality, such that users can retrieve the models for their own use.</p>"},{"location":"categories/#software-or-tool","title":"Software Or Tool","text":"<p>A piece of software or computational tool. These resources provide implementations of algorithms, analysis methods, or other computational capabilities. They may not have been developed explicitly for biomedical or biological research.</p>"},{"location":"categories/#reference-implementation","title":"Reference Implementation","text":"<p>An implementation of one or more standards or tools, whether as a full specification in a particular language or as an application to a specific use case. These demonstrate how to properly implement standards or use tools. These implementations may not have their own names and in these cases are referred to with a name based on their corresponding publication (e.g., B2AI_STANDARD:687 is Gupta2021).</p>"},{"location":"categories/#training-program","title":"Training Program","text":"<p>A program for developing skills and experience related to standards or tools. These resources help users learn how to effectively apply standards or use tools.</p>"},{"location":"categories/#classification-tags","title":"Classification Tags","text":"<p>Standards and tools can be tagged with specific collection tags to further categorize them. Some of the available tags include:</p> <ul> <li>audiovisual: Audiovisual standards</li> <li>fileformat: File format standards</li> <li>toolkit: Bioinformatics toolkits</li> <li>clinicaldata: Clinical data standards</li> <li>multimodal: Standards for multimodal data integration</li> <li>text: Text data standards and data sets</li> <li>cloudplatform: Cloud research platforms</li> <li>datamodel: Data models</li> <li>dataregistry: Data registries</li> <li>datavisualization: Data visualization tools</li> <li>machinelearningframework: Machine learning frameworks</li> <li>eyedata: Eye data sets</li> <li>proteindata: Protein data sets</li> <li>referencegenome: Reference genome data</li> <li>scrnaseqanalysis: Single-cell RNA sequencing analysis tools</li> <li>speechdata: Speech data sets</li> </ul> <p>Note: This is not an exhaustive list of all available tags.</p>"},{"location":"categories/#relationships-between-standards-and-topics","title":"Relationships Between Standards and Topics","text":"<p>Standards and tools in the registry can be related to specific data topics and organizations. These relationships help users identify relevant standards for their specific data domains and connect with responsible organizations. See the page on topics for more details.</p>"},{"location":"curation/","title":"Curation Guide","text":"<p>The tasks listed below all help to make the Bridge2AI Standards Registry more complete and informative.</p> <p>The \"source of truth\" data for the Registry is all located in the <code>b2ai-standards-registry</code> repository within the directory <code>src/data/</code>.</p> <p>Each YAML document in this directory is a single data table named for its contents (e.g., every item in <code>DataStandardOrTool.yaml</code> is an object of the <code>DataStandardOrTool</code> class in the corresponding schema).</p> <p>A list of all IDs and names of entities in the Registry may be found here.</p> <p>Some tasks refer to the dataset documentation for the Grand Challenges (GCs).</p> <p>Table 1 contains the names of each GC, its identifier, and links to each its dataset documentation.</p> Full Name Short Name ID Data Documentation AI/ML for Clinical Care CHoRUS B2AI_ORG:115 CHoRUS for Equitable AI Functional Genomics CM4AI B2AI_ORG:116 CM4AI Product Documentation Precision Public Health Voice B2AI_ORG:117 Flagship Dataset of Voice as a Biomarker of Health Salutogenesis AI-READI B2AI_ORG:114 Flagship Dataset of Type 2 Diabetes from the AI-READI Project <p>Table 1. Bridge2AI Grand Challenges</p> <p>You can help with the following tasks:</p>"},{"location":"curation/#add-new-entities","title":"Add New Entities","text":"<p>To add a new entity (e.g., a standard, tool, or organization) to the Registry, use this GitHub form to create a new issue.</p> <p>This is particularly useful to do for resources used by GCs but not yet represented in the registry. To curate these entities:</p> <ol> <li> <p>Visit one of the data documentation pages linked in the table above.</p> </li> <li> <p>When a relevant entity is mentioned, check if it exists in the registry already. The easiest way to do so (for now) is to search the list of all identifiers.</p> </li> <li> <p>If it exists, that's great! If not, create a new issue to add it. The issue form will ask if this entity is related to another. Please put the ID of the corresponding GC (see Table 1 above) in this field.</p> </li> </ol>"},{"location":"curation/#connect-standards-and-tools-to-organizations","title":"Connect Standards and Tools to Organizations","text":"<p>A connection between an standard/tool and an organization (e.g., Precision Public Health B2AI_ORG:117 uses the Praat software B2AI_STANDARD:886) can be defined within the DataStandardOrTool table.</p> <ol> <li> <p>Identify a connection between an entity and an organization. A common and informative type is a standard or tool used by one of the Bridge2AI GCs, so consult their data documentation.</p> </li> <li> <p>Edit the DataStandardOrTool.yaml file, preferably in your own Git branch. Find the entry for the standard or tool and add the ID for the organization to the <code>has_relevant_organization</code> field. Create the field if it does not yet exist for this entry. This field expects a list, so it should look like this:</p> <p>has_relevant_organization:</p> <ul> <li>B2AI_ORG:117</li> </ul> </li> <li> <p>Save your changes. Open a PR to add them to the repository.</p> </li> </ol>"},{"location":"curation/#connect-standards-and-tools-to-sdos","title":"Connect Standards and Tools to SDOs","text":"<p>Standards and tools often are maintained, managed, promoted, and otherwise supported by a dedicated organization. These are often referred to as Standards Development Organizations, or SDOs. Some, such as the International Organization for Standardization (ISO, B2AI_ORG:49) are responsible for many standards across various domains. Others, such as Health Level Seven (HL7, B2AI_ORG:40) are focused on biomedical and healthcare-related standards, such as Fast Healthcare Interoperability Resources (FHIR, B2AI_STANDARD:109).</p> <ol> <li> <p>Identify a connection between an entity and an SDO. An entry for the Organization may already exist. Standards in the category <code>BiomedicalStandard</code> will be most relevant here. If the SDO for a standard is not already known, it can usually be found in its online documentation. Note that multiple SDOs may be responsible for the same standard. </p> </li> <li> <p>Edit the DataStandardOrTool.yaml file, preferably in your own Git branch. Find the entry for the standard or tool and add the ID for the organization to the <code>responsible_organization</code> field. Create the field if it does not yet exist for this entry. This field expects a list, so it should look like this:</p> <p>responsible_organization:</p> <ul> <li>B2AI_ORG:40</li> </ul> </li> <li> <p>If necessary, add the corresponding Organization(s) to a new entry in the Organization.yaml file. Include a URL for each organization, and if possible, a Research Organization Registry (ROR) ID and/or Wikidata ID in <code>ror_id</code> and <code>wikidata_id</code>, respectively. ROR IDs may be found by searching https://ror.org. Wikidata IDs may be found by searching https://www.wikidata.org/, but please provide the ID for the organization itself rather than a related page (for example, Health Level Seven International instead of Health Level 7, since the latter is a page for the standards themselves).</p> </li> <li> <p>Save your changes. Open a PR to add them to the repository.</p> </li> </ol>"},{"location":"curation/#connect-standards-and-tools-to-other-standards-and-tools","title":"Connect Standards and Tools to other Standards and Tools","text":"<p>A connection between an standard/tool and another standard or tool (e.g., the Parselmouth software B2AI_STANDARD:887 is an interface for the Praat software B2AI_STANDARD:886) can be defined within the DataStandardOrTool table.</p> <ol> <li> <p>Identify a connection between a standard/tool and another. This does not include relationships in which one standard or tool is purely a part of another or one of several iterative versions, but two entities may be related in a variety of other ways.</p> </li> <li> <p>Edit the DataStandardOrTool.yaml file, preferably in your own Git branch. Find the entry for the standard or tool and add the ID for the related standard or tool to the <code>related_to</code> field. Create the field if it does not yet exist for this entry. This field expects a list, so it should look like this:</p> <p>related_to:</p> <ul> <li>B2AI_STANDARD:887</li> </ul> </li> <li> <p>Save your changes. Open a PR to add them to the repository.</p> </li> </ol>"},{"location":"manifest/","title":"Bridge2AI Data Manifest","text":"<p>This page provides a comprehensive manifest of all data subsets, standards, substrates, topics, and relevant anatomy used across the Bridge2AI consortium.</p> <p>Each data type is listed with its associated metadata and standards.</p> <p>Table Features</p> <ul> <li>Click on any column header to sort the table</li> <li>Links are provided to standards, substrates, topics, and anatomy ontologies</li> <li>Icons indicate different types of metadata: \ud83d\udccb Standards, \ud83d\udcbe Substrates, \ud83c\udff7\ufe0f Topics, \ud83e\uddec Anatomy</li> </ul>"},{"location":"manifest/#functional-genomics-grand-challenge","title":"Functional Genomics Grand Challenge","text":"Data Type Description \ud83d\udccb Standards &amp; Tools \ud83d\udcbe Substrates \ud83c\udff7\ufe0f Topics \ud83e\uddec Anatomy Cell maps Cell maps of cellular systems. B2AI_STANDARD:372 (RO-CRATE) B2AI_TOPIC:2 (Cell) CLO:0000031 (cell line) Cell line metadata Cell line metadata. B2AI_STANDARD:372 (RO-CRATE) B2AI_TOPIC:2 (Cell) CLO:0000031 (cell line) AP-MS - Level 1 AP-MS raw signal and metadata. B2AI_STANDARD:372 (RO-CRATE) B2AI_SUBSTRATE:58 (Mass Spectrometry Data) B2AI_TOPIC:2 (Cell), B2AI_TOPIC:28 (Proteome) CLO:0000031 (cell line) AP-MS - Level 3 AP-MS peptide counts. B2AI_STANDARD:372 (RO-CRATE) B2AI_SUBSTRATE:58 (Mass Spectrometry Data) B2AI_TOPIC:2 (Cell), B2AI_TOPIC:28 (Proteome) CLO:0000031 (cell line) Confocal IF - Level 1 Confocal immunofluorescence cell imaging raw signal (pixel intensity) and metadata. B2AI_STANDARD:344 (JPEG), B2AI_STANDARD:372 (RO-CRATE) B2AI_SUBSTRATE:56 (Immunofluorescence Image) B2AI_TOPIC:2 (Cell), B2AI_TOPIC:19 (Microscale Imaging) CLO:0000031 (cell line) CROP-seq - Level 1 CROP-seq raw signal (unaligned reads) and metadata. B2AI_STANDARD:111 (FASTQ), B2AI_STANDARD:372 (RO-CRATE) B2AI_SUBSTRATE:64 (Perturb-seq Data) B2AI_TOPIC:34 (Transcriptome) CLO:0000031 (cell line) CROP-seq - Level 2 CROP-seq aligned reads and metadata. B2AI_STANDARD:21 (BAM/CRAM), B2AI_STANDARD:372 (RO-CRATE) B2AI_SUBSTRATE:64 (Perturb-seq Data) B2AI_TOPIC:34 (Transcriptome) CLO:0000031 (cell line) CROP-seq - Level 3 CROP-seq gene counts and metadata. B2AI_STANDARD:372 (RO-CRATE) B2AI_SUBSTRATE:64 (Perturb-seq Data), B2AI_SUBSTRATE:43 (Text) B2AI_TOPIC:34 (Transcriptome) CLO:0000031 (cell line) CROP-seq protocol CROP-seq assay attributes. B2AI_STANDARD:372 (RO-CRATE) B2AI_TOPIC:34 (Transcriptome) CLO:0000031 (cell line) CROP-seq sample metadata CROP-seq sample attributes. B2AI_STANDARD:372 (RO-CRATE) B2AI_SUBSTRATE:64 (Perturb-seq Data), B2AI_SUBSTRATE:6 (Comma-separated values) B2AI_TOPIC:34 (Transcriptome) CLO:0000031 (cell line) CROP-seq QC CROP-seq quality control metrics. B2AI_STANDARD:372 (RO-CRATE) B2AI_SUBSTRATE:64 (Perturb-seq Data), B2AI_SUBSTRATE:43 (Text) B2AI_TOPIC:34 (Transcriptome) CLO:0000031 (cell line) Evidence Evidence supporting predictions, modeled as provenance graphs. B2AI_STANDARD:372 (RO-CRATE), B2AI_STANDARD:444 (EVI) B2AI_SUBSTRATE:20 (JSON) B2AI_TOPIC:34 (Transcriptome) CLO:0000031 (cell line)"},{"location":"manifest/#salutogenesis-grand-challenge","title":"Salutogenesis Grand Challenge","text":"Data Type Description \ud83d\udccb Standards &amp; Tools \ud83d\udcbe Substrates \ud83c\udff7\ufe0f Topics \ud83e\uddec Anatomy WGS - Level 1 Whole genome sequencing raw reads and metadata. B2AI_STANDARD:111 (FASTQ) B2AI_SUBSTRATE:61 (DNA Sequence Data) B2AI_TOPIC:13 (Genome) OCT Optical coherence tomography (Retinal layer thickness measurements) and metadata. B2AI_STANDARD:98 (DICOM) B2AI_SUBSTRATE:67 (Optical coherence tomography data) B2AI_TOPIC:24 (Ophthalmic Imaging) UBERON:0003951 (ocular fundus) Near-IR ophthalmic imaging Near-infrared ophthalmic imaging and metadata. B2AI_STANDARD:98 (DICOM) B2AI_SUBSTRATE:65 (Retinal Image) B2AI_TOPIC:24 (Ophthalmic Imaging) UBERON:0003951 (ocular fundus) Retinal fundus imaging Retinal fundus imaging and metadata. B2AI_STANDARD:98 (DICOM) B2AI_SUBSTRATE:65 (Retinal Image) B2AI_TOPIC:24 (Ophthalmic Imaging) UBERON:0003951 (ocular fundus) OCTA Optical coherence tomography angiography and metadata. B2AI_STANDARD:98 (DICOM) B2AI_SUBSTRATE:68 (Optical coherence tomography angiography data) B2AI_TOPIC:24 (Ophthalmic Imaging) UBERON:0003951 (ocular fundus) FLIO Fluorescence lifetime imaging ophthalmoscopy and metadata. B2AI_STANDARD:98 (DICOM) B2AI_SUBSTRATE:66 (Fluorescence Lifetime Imaging Ophthalmoscopy data) B2AI_TOPIC:24 (Ophthalmic Imaging) UBERON:0003951 (ocular fundus) Clinical visit Data produced during clinical visits, including results of vision assessments. B2AI_STANDARD:243 (OMOP CDM) B2AI_TOPIC:4 (Clinical Observations), B2AI_TOPIC:44 (Eye Diseases) UBERON:0000468 (multicellular organism) Clinical labs Clinical laboratory measurements. B2AI_STANDARD:243 (OMOP CDM) B2AI_TOPIC:9 (EHR) UBERON:0000468 (multicellular organism) Survey data Data from patient surveys, including social determinants of health (SDoH), diet, lifestyle, family history, and MoCA cognitive scores. B2AI_STANDARD:243 (OMOP CDM), B2AI_STANDARD:821 (REDCap) B2AI_SUBSTRATE:80 (Questionnaire response data) B2AI_TOPIC:4 (Clinical Observations)B2AI_TOPIC:29 (SDoH)B2AI_TOPIC:40 (Governance) Glucose levels Patient glucose data from continuous monitoring over 10 days. B2AI_STANDARD:246 (Open mHealth) B2AI_SUBSTRATE:78 (Glucose monitoring data) B2AI_TOPIC:38 (Glucose Monitoring) UBERON:0000178 (blood) Activity levels Patient activity data from continuous monitoring over 10 days. B2AI_STANDARD:246 (Open mHealth) B2AI_SUBSTRATE:73 (Physical activity data), B2AI_SUBSTRATE:74 (Caloric burn data) B2AI_TOPIC:39 (Activity Monitoring) UBERON:0000468 (multicellular organism) Heart rate Patient heart rate data from continuous monitoring over 10 days. B2AI_STANDARD:246 (Open mHealth) B2AI_SUBSTRATE:71 (Heart rate) B2AI_TOPIC:39 (Activity Monitoring) UBERON:0000948 (heart) SpO2 levels Patient blood oxygen saturation levels from continuous monitoring over 10 days. B2AI_STANDARD:246 (Open mHealth) B2AI_SUBSTRATE:72 (Oxygen saturation) B2AI_TOPIC:39 (Activity Monitoring), B2AI_TOPIC:46 (Respiration) ECG Patient cardiac 12-lead electrocardiogram (waveform) data and metadata. B2AI_STANDARD:202 (WFDB Format) B2AI_SUBSTRATE:49 (Waveform Data) B2AI_TOPIC:37 (Waveform) UBERON:0000948 (heart) Environmental data Patient environment and air quality data. Includes temperature, humidity, oxygen, particle, and other measures of the environment. B2AI_TOPIC:11 (Environment) UBERON:0000468 (multicellular organism)"},{"location":"manifest/#precision-public-health-grand-challenge","title":"Precision Public Health Grand Challenge","text":"Data Type Description \ud83d\udccb Standards &amp; Tools \ud83d\udcbe Substrates \ud83c\udff7\ufe0f Topics \ud83e\uddec Anatomy WGS - Level 1 Whole genome sequencing raw reads and metadata. Preserving/sharing unaligned reads (in same file as aligned reads) via CRAM. B2AI_STANDARD:21 (BAM/CRAM) B2AI_TOPIC:13 (Genome) WGS - Level 2 Whole genome sequencing aligned reads and metadata. Preserving/sharing unaligned reads (in same file as aligned reads) via CRAM. B2AI_STANDARD:21 (BAM/CRAM) B2AI_TOPIC:13 (Genome) WGS - Level 3 Whole genome sequencing variant calls (SNV/INDEL/CNV/SV) and metadata. Preserving/sharing unaligned reads (in same file as aligned reads) via CRAM. B2AI_STANDARD:299 (VCF) B2AI_TOPIC:13 (Genome) WGS protocol Whole genome sequencing protocol and metadata. B2AI_TOPIC:13 (Genome) WGS sample metadata Whole genome sequencing sample attributes. B2AI_TOPIC:13 (Genome) WGS QC Whole genome sequencing quality control metrics. B2AI_TOPIC:13 (Genome) CT Computed tomography (CT) scans and metadata. B2AI_STANDARD:98 (DICOM) B2AI_SUBSTRATE:11 (DICOM) B2AI_TOPIC:22 (Neurologic Imaging) MR Magnetic resonance (MR) imaging and metadata. B2AI_STANDARD:98 (DICOM) B2AI_SUBSTRATE:11 (DICOM) B2AI_TOPIC:22 (Neurologic Imaging) X-ray X-ray imaging and metadata. B2AI_STANDARD:98 (DICOM) B2AI_SUBSTRATE:11 (DICOM) Voice Voice recordings (spectrographs) and metadata. B2AI_STANDARD:202 (WFDB Format) B2AI_SUBSTRATE:49 (Waveform Data) B2AI_TOPIC:36 (Voice) UBERON:0000468 (multicellular organism) Laryngoscopy Laryngoscopy videos and metadata. B2AI_STANDARD:98 (DICOM), B2AI_STANDARD:352 (MPEG-4) B2AI_SUBSTRATE:19 (Image) UBERON:0001737 (larynx) Speech test assessment Speech test assessment results. B2AI_SUBSTRATE:49 (Waveform Data) B2AI_TOPIC:36 (Voice), B2AI_TOPIC:45 (Voice Disorders) UBERON:0000468 (multicellular organism) Spontaneous speech assessment Spontaneous speech assessment results. B2AI_SUBSTRATE:49 (Waveform Data) B2AI_TOPIC:36 (Voice), B2AI_TOPIC:45 (Voice Disorders) UBERON:0000468 (multicellular organism) Forced cough assessment Forced cough assessment results. B2AI_SUBSTRATE:49 (Waveform Data) B2AI_TOPIC:36 (Voice), B2AI_TOPIC:45 (Voice Disorders) UBERON:0000468 (multicellular organism) Informed consent Informed consent form responses. B2AI_STANDARD:821 (REDCap) Questionnaire Questionnaire responses, including MoCA, GAD-7, VHI-10, PANAS, and DI. B2AI_STANDARD:109 (FHIR) B2AI_TOPIC:31 (Survey) Demographics Participant demographics information. B2AI_STANDARD:109 (FHIR) B2AI_TOPIC:29 (SDoH), B2AI_TOPIC:31 (Survey) Treatment Participant treatment history information. B2AI_STANDARD:243 (OMOP CDM) B2AI_TOPIC:4 (Clinical Observations) UBERON:0000468 (multicellular organism) Diagnosis Participant diagnosis history information and results of functional assessment. B2AI_STANDARD:174 (ICD-10-CM) B2AI_TOPIC:4 (Clinical Observations), B2AI_TOPIC:45 (Voice Disorders) UBERON:0000468 (multicellular organism) Vital signs Participant vital signs information. B2AI_STANDARD:109 (FHIR) B2AI_TOPIC:4 (Clinical Observations) Social history Participant social history information, including social history (e.g., smoking and alcohol use). B2AI_TOPIC:29 (SDoH)"},{"location":"manifest/#aiml-for-clinical-care-grand-challenge","title":"AI/ML for Clinical Care Grand Challenge","text":"Data Type Description \ud83d\udccb Standards &amp; Tools \ud83d\udcbe Substrates \ud83c\udff7\ufe0f Topics \ud83e\uddec Anatomy Clinical labs Clinical laboratory measurements. B2AI_TOPIC:4 (Clinical Observations), B2AI_TOPIC:9 (EHR) Clinical treatments Clinical treatment information, including details of medications administered. B2AI_TOPIC:4 (Clinical Observations) Physiologic telemetry Physiologic telemetry data. B2AI_SUBSTRATE:49 (Waveform Data) B2AI_TOPIC:4 (Clinical Observations), B2AI_TOPIC:9 (EHR) Physiologic EEG Physiologic electroencephalogram data. B2AI_SUBSTRATE:49 (Waveform Data) B2AI_TOPIC:4 (Clinical Observations), B2AI_TOPIC:9 (EHR) UBERON:0000955 (brain) ECG Patient cardiac 5-lead electrocardiogram (waveform) data and metadata. B2AI_STANDARD:202 (WFDB Format) B2AI_SUBSTRATE:49 (Waveform Data) B2AI_TOPIC:37 (Waveform) UBERON:0000948 (heart) Heart rate Patient heart rate data. B2AI_SUBSTRATE:71 (Heart rate) B2AI_TOPIC:39 (Activity Monitoring) UBERON:0000948 (heart) SpO2 levels Patient blood oxygen saturation levels. B2AI_SUBSTRATE:72 (Oxygen saturation) B2AI_TOPIC:46 (Respiration) X-ray X-ray imaging and metadata. B2AI_STANDARD:98 (DICOM) B2AI_SUBSTRATE:11 (DICOM) CT Computed tomography (CT) scans and metadata. B2AI_STANDARD:98 (DICOM) B2AI_SUBSTRATE:11 (DICOM) B2AI_TOPIC:22 (Neurologic Imaging) MR Magnetic resonance (MR) imaging and metadata. B2AI_STANDARD:98 (DICOM) B2AI_SUBSTRATE:11 (DICOM) B2AI_TOPIC:22 (Neurologic Imaging) Social determinants of health Social determinants of health data based on Area Deprivation Index (ADI). B2AI_TOPIC:29 (SDoH) Practice metadata Metadata about clinical practice."},{"location":"programmatic-access/","title":"Programmatic Access to the Standards Explorer","text":"<p>The Bridge2AI Standards Explorer data is hosted on Sage Synapse and is accessible through the Synapse REST API. All data tables are public, so no API key or authentication is required for read access.</p>"},{"location":"programmatic-access/#overview","title":"Overview","text":"<p>The Standards Explorer consists of several public Synapse tables:</p> <ul> <li>DataStandardOrTool (<code>syn63096833</code>): Main table containing all standards, tools, and resources</li> <li>DataTopics (<code>syn63096835</code>): Topics/domains that standards concern (e.g., EHR, Genomics, Image)</li> <li>DataSubstrate (<code>syn63096834</code>): Data formats and structures (e.g., JSON, CSV, BIDS)</li> <li>Organization (<code>syn63096836</code>): Organizations related to standards (e.g., HL7, W3C, CDISC)</li> <li>DataStandardOrTool_denormalized (<code>syn65676531</code>): Flattened view for easier querying</li> </ul> <p>All tables belong to the Bridge2AI Standards Explorer project (<code>syn63096806</code>).</p>"},{"location":"programmatic-access/#rest-api-access","title":"REST API Access","text":"<p>The Synapse REST API endpoint is: <code>https://repo-prod.prod.sagebase.org</code></p>"},{"location":"programmatic-access/#basic-query-structure","title":"Basic Query Structure","text":"<p>To query a Synapse table, you need to:</p> <ol> <li>Start an async query job</li> <li>Poll for results using the returned token</li> <li>Retrieve the final results</li> </ol>"},{"location":"programmatic-access/#example-query-standards-table-curl","title":"Example: Query Standards Table (cURL)","text":"<pre><code># Step 1: Start the async query\ncurl -X POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn63096833/table/query/async/start \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"concreteType\": \"org.sagebionetworks.repo.model.table.QueryBundleRequest\",\n    \"entityId\": \"syn63096833\",\n    \"query\": {\n      \"sql\": \"SELECT * FROM syn63096833 LIMIT 10\"\n    },\n    \"partMask\": 29\n  }'\n\n# This returns a token like: {\"token\": \"12345\"}\n\n# Step 2: Poll for results (repeat until status is not 202)\ncurl https://repo-prod.prod.sagebase.org/repo/v1/entity/syn63096833/table/query/async/get/12345\n\n# Step 3: Parse the results from the JSON response\n</code></pre>"},{"location":"programmatic-access/#example-search-by-name-curl","title":"Example: Search by Name (cURL)","text":"<pre><code># Search for standards with \"FHIR\" in the name\ncurl -X POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn63096833/table/query/async/start \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"concreteType\": \"org.sagebionetworks.repo.model.table.QueryBundleRequest\",\n    \"entityId\": \"syn63096833\",\n    \"query\": {\n      \"sql\": \"SELECT id, name, description FROM syn63096833 WHERE name LIKE '\\''%FHIR%'\\'' LIMIT 5\"\n    },\n    \"partMask\": 29\n  }'\n</code></pre>"},{"location":"programmatic-access/#example-query-denormalized-table","title":"Example: Query Denormalized Table","text":"<p>The denormalized table includes expanded columns for easier querying:</p> <pre><code>curl -X POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn65676531/table/query/async/start \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"concreteType\": \"org.sagebionetworks.repo.model.table.QueryBundleRequest\",\n    \"entityId\": \"syn65676531\",\n    \"query\": {\n      \"sql\": \"SELECT * FROM syn65676531 WHERE concerns_data_topic_names LIKE '\\''%Genomics%'\\''\"\n    },\n    \"partMask\": 29\n  }'\n</code></pre>"},{"location":"programmatic-access/#python-access","title":"Python Access","text":""},{"location":"programmatic-access/#simplest-example-requests-library","title":"Simplest Example (requests library)","text":"<p>Here's the most minimal example to search the Standards Explorer:</p> <pre><code>import requests\nimport time\n\ndef search_standards(search_term):\n    \"\"\"Simple function to search standards by name.\"\"\"\n    # Start query\n    response = requests.post(\n        \"https://repo-prod.prod.sagebase.org/repo/v1/entity/syn63096833/table/query/async/start\",\n        json={\n            \"concreteType\": \"org.sagebionetworks.repo.model.table.QueryBundleRequest\",\n            \"entityId\": \"syn63096833\",\n            \"query\": {\"sql\": f\"SELECT id, name, description FROM syn63096833 WHERE name LIKE '%{search_term}%' LIMIT 10\"},\n            \"partMask\": 29\n        },\n        headers={\"Content-Type\": \"application/json\"}\n    )\n    token = response.json()[\"token\"]\n\n    # Wait for results\n    while True:\n        result = requests.get(\n            f\"https://repo-prod.prod.sagebase.org/repo/v1/entity/syn63096833/table/query/async/get/{token}\",\n            headers={\"Content-Type\": \"application/json\"}\n        )\n        if result.status_code != 202:  # 202 = still processing\n            return result.json()[\"queryResult\"][\"queryResults\"][\"rows\"]\n        time.sleep(1)\n\n# Use it\nfor row in search_standards(\"FHIR\"):\n    values = row[\"values\"]\n    print(f\"{values[0]}: {values[1]}\")\n\n# Output:\n# B2AI_STANDARD:109: FHIR\n# B2AI_STANDARD:845: CDC Introduction to FHIR\n# B2AI_STANDARD:846: FHIR Drills\n</code></pre> <p>Note: The Synapse API requires an async query pattern (start query \u2192 poll for results), but the above function wraps this complexity for you.</p>"},{"location":"programmatic-access/#using-httpx-async","title":"Using httpx (Async)","text":"<p>This example shows how to query the API without the Synapse Python client:</p> <pre><code>import httpx\nimport asyncio\nimport json\n\nSYNAPSE_BASE_URL = \"https://repo-prod.prod.sagebase.org\"\nTABLE_ID = \"syn63096833\"\n\nasync def poll_async_job(client, table_id, async_token, max_wait=30):\n    \"\"\"Poll an async job until it completes or times out.\"\"\"\n    url = f\"{SYNAPSE_BASE_URL}/repo/v1/entity/{table_id}/table/query/async/get/{async_token}\"\n    headers = {\"Content-Type\": \"application/json\"}\n\n    start_time = asyncio.get_event_loop().time()\n    while True:\n        elapsed = asyncio.get_event_loop().time() - start_time\n        if elapsed &gt; max_wait:\n            raise TimeoutError(f\"Query timed out after {max_wait} seconds\")\n\n        response = await client.get(url, headers=headers)\n\n        # 202 means still processing\n        if response.status_code == 202:\n            await asyncio.sleep(1)\n            continue\n\n        response.raise_for_status()\n        return response.json()\n\nasync def query_standards(sql_query):\n    \"\"\"Query the Standards Explorer table.\"\"\"\n    query_request = {\n        \"concreteType\": \"org.sagebionetworks.repo.model.table.QueryBundleRequest\",\n        \"entityId\": TABLE_ID,\n        \"query\": {\"sql\": sql_query},\n        \"partMask\": 0x1 | 0x4 | 0x10  # queryResults + selectColumns + columnModels\n    }\n\n    async with httpx.AsyncClient(timeout=60.0) as client:\n        # Start the async query\n        start_response = await client.post(\n            f\"{SYNAPSE_BASE_URL}/repo/v1/entity/{TABLE_ID}/table/query/async/start\",\n            json=query_request,\n            headers={\"Content-Type\": \"application/json\"}\n        )\n        start_response.raise_for_status()\n\n        # Get the async token\n        async_token = start_response.json().get(\"token\")\n\n        # Poll for results\n        result_bundle = await poll_async_job(client, TABLE_ID, async_token)\n\n        # Extract rows\n        rows = result_bundle.get(\"queryResult\", {}).get(\"queryResults\", {}).get(\"rows\", [])\n        columns = result_bundle.get(\"selectColumns\", [])\n\n        return {\n            \"columns\": [col.get(\"name\") for col in columns],\n            \"rows\": rows,\n            \"row_count\": len(rows)\n        }\n\n# Example usage\nasync def main():\n    # Get all standards (limited to 10)\n    result = await query_standards(\"SELECT * FROM syn63096833 LIMIT 10\")\n    print(f\"Found {result['row_count']} standards\")\n\n    # Search for FHIR-related standards\n    result = await query_standards(\n        \"SELECT id, name, description FROM syn63096833 WHERE name LIKE '%FHIR%'\"\n    )\n    for row in result['rows']:\n        values = row.get('values', [])\n        print(f\"ID: {values[0]}, Name: {values[1]}\")\n\n# Run the async function\nasyncio.run(main())\n\n# Expected output:\n# Found 10 standards\n# ID: B2AI_STANDARD:109, Name: FHIR\n# ID: B2AI_STANDARD:845, Name: CDC Introduction to FHIR\n# ID: B2AI_STANDARD:846, Name: FHIR Drills\n</code></pre>"},{"location":"programmatic-access/#using-requests-synchronous","title":"Using requests (Synchronous)","text":"<pre><code>import requests\nimport time\n\nSYNAPSE_BASE_URL = \"https://repo-prod.prod.sagebase.org\"\nTABLE_ID = \"syn63096833\"\n\ndef query_standards(sql_query, max_wait=30):\n    \"\"\"Query the Standards Explorer table synchronously.\"\"\"\n    query_request = {\n        \"concreteType\": \"org.sagebionetworks.repo.model.table.QueryBundleRequest\",\n        \"entityId\": TABLE_ID,\n        \"query\": {\"sql\": sql_query},\n        \"partMask\": 29  # Request all parts\n    }\n\n    # Start the async query\n    response = requests.post(\n        f\"{SYNAPSE_BASE_URL}/repo/v1/entity/{TABLE_ID}/table/query/async/start\",\n        json=query_request,\n        headers={\"Content-Type\": \"application/json\"}\n    )\n    response.raise_for_status()\n    async_token = response.json().get(\"token\")\n\n    # Poll for results\n    start_time = time.time()\n    while True:\n        if time.time() - start_time &gt; max_wait:\n            raise TimeoutError(f\"Query timed out after {max_wait} seconds\")\n\n        result = requests.get(\n            f\"{SYNAPSE_BASE_URL}/repo/v1/entity/{TABLE_ID}/table/query/async/get/{async_token}\",\n            headers={\"Content-Type\": \"application/json\"}\n        )\n\n        if result.status_code == 202:  # Still processing\n            time.sleep(1)\n            continue\n\n        result.raise_for_status()\n        return result.json()\n\n# Example usage\nresult = query_standards(\"SELECT id, name, description FROM syn63096833 WHERE name LIKE '%FHIR%' LIMIT 5\")\nrows = result.get(\"queryResult\", {}).get(\"queryResults\", {}).get(\"rows\", [])\n\nfor row in rows:\n    values = row.get(\"values\", [])\n    print(f\"ID: {values[0]}, Name: {values[1]}\")\n\n# Output:\n# ID: B2AI_STANDARD:109, Name: FHIR\n# ID: B2AI_STANDARD:845, Name: CDC Introduction to FHIR\n# ID: B2AI_STANDARD:846, Name: FHIR Drills\n</code></pre>"},{"location":"programmatic-access/#using-the-synapse-python-client","title":"Using the Synapse Python Client","text":"<p>The official Synapse Python client provides a simpler interface:</p> <pre><code>import synapseclient\n\n# Login (anonymous access for public data)\nsyn = synapseclient.Synapse()\nsyn.login()\n\n# Query the table\nquery = \"SELECT * FROM syn63096833 WHERE name LIKE '%FHIR%' LIMIT 10\"\nresults = syn.tableQuery(query)\n\n# Convert to pandas DataFrame\ndf = results.asDataFrame()\nprint(df.head())\n\n# Access specific columns\nprint(df[['id', 'name', 'description']])\n\n# Example output:\n#                    id                           name  \\\n# 0  B2AI_STANDARD:109                           FHIR   \n# 1  B2AI_STANDARD:845  CDC Introduction to FHIR   \n# 2  B2AI_STANDARD:846                    FHIR Drills   \n#\n#                                         description  \n# 0       Fast Healthcare Interoperability Resources  \n# 1          CDC Introduction to FHIR - Training...  \n# 2                                        FHIR Drills\n</code></pre> <p>Installation: <pre><code>pip install synapseclient\n</code></pre></p>"},{"location":"programmatic-access/#using-the-synapse-cli","title":"Using the Synapse CLI","text":"<p>Query tables directly from the command line:</p> <pre><code># Install synapseclient\npip install synapseclient\n\n# Query and save to CSV\nsynapse query \"SELECT * FROM syn63096833 LIMIT 10\" &gt; tmp.csv\n\n# Clean the result (remove header rows)\ntail -n +3 tmp.csv &gt; standards.csv\nrm tmp.csv\n</code></pre>"},{"location":"programmatic-access/#common-query-examples","title":"Common Query Examples","text":""},{"location":"programmatic-access/#list-available-topics","title":"List Available Topics","text":"<p>First, see what topics are available:</p> <pre><code>import requests\nimport time\n\ndef query_topics():\n    result = query_standards(\"SELECT id, name FROM syn63096835 LIMIT 10\")\n    rows = result.get(\"queryResult\", {}).get(\"queryResults\", {}).get(\"rows\", [])\n    for row in rows:\n        values = row.get(\"values\", [])\n        print(f\"{values[0]}: {values[1]}\")\n\n# Output:\n# B2AI_TOPIC:1: Biology\n# B2AI_TOPIC:2: Cell\n# B2AI_TOPIC:3: Cheminformatics\n# B2AI_TOPIC:4: Clinical Observations\n# B2AI_TOPIC:5: Data\n# B2AI_TOPIC:6: Demographics\n# B2AI_TOPIC:7: Disease\n# B2AI_TOPIC:8: Drug\n# B2AI_TOPIC:9: EHR\n# B2AI_TOPIC:10: EKG\n</code></pre>"},{"location":"programmatic-access/#search-by-topic","title":"Search by Topic","text":"<pre><code>-- Find all standards related to genomics (topic ID: B2AI_TOPIC:5)\nSELECT id, name, description \nFROM syn63096833 \nWHERE concerns_data_topic LIKE '%B2AI_TOPIC:5%'\nLIMIT 5\n</code></pre> <pre><code># Example output:\n# B2AI_STANDARD:114: Genomics Operations\n# B2AI_STANDARD:127: FuGE-ML\n# B2AI_STANDARD:128: FuGEFlow\n# B2AI_STANDARD:141: GCDML\n</code></pre>"},{"location":"programmatic-access/#search-by-organization","title":"Search by Organization","text":"<pre><code>-- Find standards from HL7 (org ID: B2AI_ORG:48)\nSELECT id, name, description, url\nFROM syn63096833 \nWHERE responsible_organization LIKE '%B2AI_ORG:48%' \n   OR has_relevant_organization LIKE '%B2AI_ORG:48%'\n</code></pre>"},{"location":"programmatic-access/#search-by-data-substrate","title":"Search by Data Substrate","text":"<pre><code>-- Find standards that work with JSON (substrate ID: B2AI_SUBSTRATE:58)\nSELECT id, name, description \nFROM syn63096833 \nWHERE has_relevant_data_substrate LIKE '%B2AI_SUBSTRATE:58%'\n</code></pre>"},{"location":"programmatic-access/#filter-by-category","title":"Filter by Category","text":"<pre><code>-- Find all biomedical standards\nSELECT id, name, description \nFROM syn63096833 \nWHERE category = 'B2AI_STANDARD:BiomedicalStandard'\n</code></pre>"},{"location":"programmatic-access/#full-text-search","title":"Full-text Search","text":"<pre><code>-- Search across multiple text fields\nSELECT id, name \nFROM syn63096833 \nWHERE description LIKE '%genomic%'\nLIMIT 5\n</code></pre> <pre><code># Example output:\n# B2AI_STANDARD:44: SDTM\n# B2AI_STANDARD:114: Genomics Operations\n# B2AI_STANDARD:127: FuGE-ML\n# B2AI_STANDARD:128: FuGEFlow\n# B2AI_STANDARD:141: GCDML\n</code></pre>"},{"location":"programmatic-access/#filter-by-properties","title":"Filter by Properties","text":"<pre><code>-- Find open standards\nSELECT id, name, is_open \nFROM syn63096833 \nWHERE is_open = 'true'\nLIMIT 5\n</code></pre> <pre><code># Example output:\n# B2AI_STANDARD:1: .ACE format (Open: true)\n# B2AI_STANDARD:2: DMS (Open: true)\n# B2AI_STANDARD:3: ABCD (Open: true)\n# B2AI_STANDARD:4: AGP (Open: true)\n# B2AI_STANDARD:5: AnIML (Open: true)\n</code></pre>"},{"location":"programmatic-access/#query-the-denormalized-table","title":"Query the Denormalized Table","text":"<p>For easier querying with human-readable values, use the denormalized table:</p> <pre><code>-- Search by topic name instead of ID\nSELECT id, name, concerns_data_topic_names\nFROM syn65676531 \nWHERE concerns_data_topic_names LIKE '%Genomics%'\n</code></pre> <pre><code>import synapseclient\n\nsyn = synapseclient.Synapse()\nsyn.login()\n\n# Query denormalized table with readable column names\nquery = \"\"\"\nSELECT id, name, category_label, concerns_data_topic_names, \n       responsible_organization_names\nFROM syn65676531 \nWHERE concerns_data_topic_names LIKE '%EHR%'\n\"\"\"\n\ndf = syn.tableQuery(query).asDataFrame()\nprint(df)\n</code></pre>"},{"location":"programmatic-access/#rate-limits-and-best-practices","title":"Rate Limits and Best Practices","text":"<ul> <li>No authentication required for public tables (read-only access)</li> <li>The API uses async queries - always poll for results rather than expecting immediate responses</li> <li>Set reasonable timeouts (30-60 seconds for most queries)</li> <li>Use LIMIT clauses to avoid retrieving too much data at once</li> <li>The partMask parameter controls which parts of the query result are returned:</li> <li><code>0x1</code> (1): Query results</li> <li><code>0x4</code> (4): Select columns</li> <li><code>0x10</code> (16): Column models</li> <li><code>0x1D</code> (29): All parts (commonly used)</li> </ul>"},{"location":"programmatic-access/#additional-resources","title":"Additional Resources","text":"<ul> <li>Synapse REST API Documentation</li> <li>Synapse Python Client Documentation</li> <li>Standards Explorer MCP Implementation</li> <li>Standards Explorer Project on Synapse</li> </ul>"},{"location":"programmatic-access/#support","title":"Support","text":"<p>For questions or issues: - Open an issue on the b2ai-standards-registry GitHub repository - Contact the Bridge2AI Standards team</p>"},{"location":"substrates/","title":"Data Substrates in the Bridge2AI Standards Explorer","text":""},{"location":"substrates/#what-is-a-substrate","title":"What is a Substrate?","text":"<p>A Substrate is a high-level data structure or a specific implementation of that structure. Interpret as \"data, in this form or format\", as compared to DataStandard, which refers to the set of rules defining a standard. For example, data in TSV format is represented as a DataSubstrate but the concept of TSV format is a DataStandard.</p> <p>This is also distinct from a DataTopic, which is a concept or field of study a standard may be applied to.</p>"},{"location":"substrates/#substrate-hierarchy","title":"Substrate Hierarchy","text":"<p>Below is an interactive Mermaid diagram representing a subset of the substrate hierarchy. Click any node to navigate to its page.</p> <pre><code>flowchart LR\n    B2AI_SUBSTRATE_1[Array]\n    B2AI_SUBSTRATE_2[Associative Array]\n    B2AI_SUBSTRATE_3[BIDS]\n    B2AI_SUBSTRATE_4[BigQuery]\n    B2AI_SUBSTRATE_5[Column Store]\n    B2AI_SUBSTRATE_6[Comma-separated values]\n    B2AI_SUBSTRATE_7[Data]\n    B2AI_SUBSTRATE_8[Data Frame]\n    B2AI_SUBSTRATE_9[Database]\n    B2AI_SUBSTRATE_10[Delimited Text]\n    B2AI_SUBSTRATE_11[DICOM]\n    B2AI_SUBSTRATE_12[Directed acyclic graph]\n    B2AI_SUBSTRATE_13[Document Database]\n    B2AI_SUBSTRATE_14[Graph]\n    B2AI_SUBSTRATE_15[Graph Database]\n    B2AI_SUBSTRATE_16[HDF5]\n    B2AI_SUBSTRATE_17[Heap]\n    B2AI_SUBSTRATE_18[Hierarchical Array]\n    B2AI_SUBSTRATE_19[Image]\n    B2AI_SUBSTRATE_20[JSON]\n    B2AI_SUBSTRATE_21[KGX TSV]\n    B2AI_SUBSTRATE_22[MongoDB]\n    B2AI_SUBSTRATE_23[MySQL]\n    B2AI_SUBSTRATE_24[N-Dimensional Array]\n    B2AI_SUBSTRATE_25[Neo4j]\n    B2AI_SUBSTRATE_26[Neural Network Model]\n    B2AI_SUBSTRATE_27[NNEF]\n    B2AI_SUBSTRATE_28[ONNX]\n    B2AI_SUBSTRATE_29[Pandas DataFrame]\n    B2AI_SUBSTRATE_30[Parquet]\n    B2AI_SUBSTRATE_31[PostgreSQL]\n    B2AI_SUBSTRATE_32[Property graph]\n    B2AI_SUBSTRATE_33[PyTorch Tensor]\n    B2AI_SUBSTRATE_34[R data.frame]\n    B2AI_SUBSTRATE_35[R tibble]\n    B2AI_SUBSTRATE_36[Raster Image]\n    B2AI_SUBSTRATE_37[Relational Database]\n    B2AI_SUBSTRATE_38[Set]\n    B2AI_SUBSTRATE_39[String]\n    B2AI_SUBSTRATE_40[SummarizedExperiment]\n    B2AI_SUBSTRATE_41[Tab-separated values]\n    B2AI_SUBSTRATE_42[Tensor]\n    B2AI_SUBSTRATE_43[Text]\n    B2AI_SUBSTRATE_44[Tree]\n    B2AI_SUBSTRATE_45[Trie]\n    B2AI_SUBSTRATE_46[Vector]\n    B2AI_SUBSTRATE_47[Vector Image]\n    B2AI_SUBSTRATE_48[Waveform Audio File Format]\n    B2AI_SUBSTRATE_49[Waveform Data]\n    B2AI_SUBSTRATE_50[xarray]\n    B2AI_SUBSTRATE_51[Zarr]\n    B2AI_SUBSTRATE_52[Compressed Data]\n    B2AI_SUBSTRATE_53[BED]\n    B2AI_SUBSTRATE_54[Vector Database]\n    B2AI_SUBSTRATE_55[Pinecone]\n    B2AI_SUBSTRATE_56[Immunofluorescence Image]\n    B2AI_SUBSTRATE_57[Spectral Data]\n    B2AI_SUBSTRATE_58[Mass Spectrometry Data]\n    B2AI_SUBSTRATE_59[Size Exclusion Chromatography-Mass Spectrometry Data]\n    B2AI_SUBSTRATE_60[Sequence]\n    B2AI_SUBSTRATE_61[DNA Sequence Data]\n    B2AI_SUBSTRATE_62[RNA Sequence Data]\n    B2AI_SUBSTRATE_63[Single-cell RNA Sequence Data]\n    B2AI_SUBSTRATE_64[Perturb-seq Data]\n    B2AI_SUBSTRATE_65[Retinal Image]\n    B2AI_SUBSTRATE_66[Fluorescence Lifetime Imaging Ophthalmoscopy data]\n    B2AI_SUBSTRATE_67[Optical coherence tomography data]\n    B2AI_SUBSTRATE_68[Optical coherence tomography angiography data]\n    B2AI_SUBSTRATE_69[Time-series data]\n    B2AI_SUBSTRATE_70[Physiological data]\n    B2AI_SUBSTRATE_71[Heart rate]\n    B2AI_SUBSTRATE_72[Oxygen saturation]\n    B2AI_SUBSTRATE_73[Physical activity data]\n    B2AI_SUBSTRATE_74[Caloric burn data]\n    B2AI_SUBSTRATE_75[Respiratory rate]\n    B2AI_SUBSTRATE_76[Sleep tracking data]\n    B2AI_SUBSTRATE_77[Stress tracking data]\n    B2AI_SUBSTRATE_78[Glucose monitoring data]\n    B2AI_SUBSTRATE_79[Participant response data]\n    B2AI_SUBSTRATE_80[Questionnaire response data]\n    B2AI_SUBSTRATE_81[File headers]\n    B2AI_SUBSTRATE_1 --&gt; B2AI_SUBSTRATE_2\n    B2AI_SUBSTRATE_1 --&gt; B2AI_SUBSTRATE_18\n    B2AI_SUBSTRATE_1 --&gt; B2AI_SUBSTRATE_24\n    B2AI_SUBSTRATE_2 --&gt; B2AI_SUBSTRATE_20\n    B2AI_SUBSTRATE_5 --&gt; B2AI_SUBSTRATE_4\n    B2AI_SUBSTRATE_5 --&gt; B2AI_SUBSTRATE_30\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_1\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_8\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_9\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_14\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_19\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_26\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_38\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_39\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_42\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_46\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_49\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_52\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_57\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_69\n    B2AI_SUBSTRATE_7 --&gt; B2AI_SUBSTRATE_79\n    B2AI_SUBSTRATE_8 --&gt; B2AI_SUBSTRATE_29\n    B2AI_SUBSTRATE_8 --&gt; B2AI_SUBSTRATE_34\n    B2AI_SUBSTRATE_8 --&gt; B2AI_SUBSTRATE_35\n    B2AI_SUBSTRATE_9 --&gt; B2AI_SUBSTRATE_5\n    B2AI_SUBSTRATE_9 --&gt; B2AI_SUBSTRATE_13\n    B2AI_SUBSTRATE_9 --&gt; B2AI_SUBSTRATE_15\n    B2AI_SUBSTRATE_9 --&gt; B2AI_SUBSTRATE_37\n    B2AI_SUBSTRATE_9 --&gt; B2AI_SUBSTRATE_54\n    B2AI_SUBSTRATE_10 --&gt; B2AI_SUBSTRATE_6\n    B2AI_SUBSTRATE_10 --&gt; B2AI_SUBSTRATE_41\n    B2AI_SUBSTRATE_10 --&gt; B2AI_SUBSTRATE_53\n    B2AI_SUBSTRATE_13 --&gt; B2AI_SUBSTRATE_22\n    B2AI_SUBSTRATE_14 --&gt; B2AI_SUBSTRATE_12\n    B2AI_SUBSTRATE_14 --&gt; B2AI_SUBSTRATE_15\n    B2AI_SUBSTRATE_14 --&gt; B2AI_SUBSTRATE_32\n    B2AI_SUBSTRATE_14 --&gt; B2AI_SUBSTRATE_44\n    B2AI_SUBSTRATE_15 --&gt; B2AI_SUBSTRATE_25\n    B2AI_SUBSTRATE_18 --&gt; B2AI_SUBSTRATE_16\n    B2AI_SUBSTRATE_18 --&gt; B2AI_SUBSTRATE_20\n    B2AI_SUBSTRATE_18 --&gt; B2AI_SUBSTRATE_40\n    B2AI_SUBSTRATE_19 --&gt; B2AI_SUBSTRATE_3\n    B2AI_SUBSTRATE_19 --&gt; B2AI_SUBSTRATE_36\n    B2AI_SUBSTRATE_19 --&gt; B2AI_SUBSTRATE_47\n    B2AI_SUBSTRATE_24 --&gt; B2AI_SUBSTRATE_50\n    B2AI_SUBSTRATE_24 --&gt; B2AI_SUBSTRATE_51\n    B2AI_SUBSTRATE_26 --&gt; B2AI_SUBSTRATE_27\n    B2AI_SUBSTRATE_26 --&gt; B2AI_SUBSTRATE_28\n    B2AI_SUBSTRATE_32 --&gt; B2AI_SUBSTRATE_21\n    B2AI_SUBSTRATE_36 --&gt; B2AI_SUBSTRATE_11\n    B2AI_SUBSTRATE_36 --&gt; B2AI_SUBSTRATE_56\n    B2AI_SUBSTRATE_36 --&gt; B2AI_SUBSTRATE_65\n    B2AI_SUBSTRATE_37 --&gt; B2AI_SUBSTRATE_23\n    B2AI_SUBSTRATE_37 --&gt; B2AI_SUBSTRATE_31\n    B2AI_SUBSTRATE_39 --&gt; B2AI_SUBSTRATE_43\n    B2AI_SUBSTRATE_39 --&gt; B2AI_SUBSTRATE_60\n    B2AI_SUBSTRATE_41 --&gt; B2AI_SUBSTRATE_21\n    B2AI_SUBSTRATE_42 --&gt; B2AI_SUBSTRATE_33\n    B2AI_SUBSTRATE_43 --&gt; B2AI_SUBSTRATE_10\n    B2AI_SUBSTRATE_44 --&gt; B2AI_SUBSTRATE_45\n    B2AI_SUBSTRATE_49 --&gt; B2AI_SUBSTRATE_3\n    B2AI_SUBSTRATE_49 --&gt; B2AI_SUBSTRATE_48\n    B2AI_SUBSTRATE_54 --&gt; B2AI_SUBSTRATE_55\n    B2AI_SUBSTRATE_57 --&gt; B2AI_SUBSTRATE_58\n    B2AI_SUBSTRATE_58 --&gt; B2AI_SUBSTRATE_59\n    B2AI_SUBSTRATE_60 --&gt; B2AI_SUBSTRATE_61\n    B2AI_SUBSTRATE_60 --&gt; B2AI_SUBSTRATE_62\n    B2AI_SUBSTRATE_62 --&gt; B2AI_SUBSTRATE_63\n    B2AI_SUBSTRATE_63 --&gt; B2AI_SUBSTRATE_64\n    B2AI_SUBSTRATE_65 --&gt; B2AI_SUBSTRATE_66\n    B2AI_SUBSTRATE_65 --&gt; B2AI_SUBSTRATE_67\n    B2AI_SUBSTRATE_67 --&gt; B2AI_SUBSTRATE_68\n    B2AI_SUBSTRATE_69 --&gt; B2AI_SUBSTRATE_70\n    B2AI_SUBSTRATE_70 --&gt; B2AI_SUBSTRATE_71\n    B2AI_SUBSTRATE_70 --&gt; B2AI_SUBSTRATE_72\n    B2AI_SUBSTRATE_70 --&gt; B2AI_SUBSTRATE_73\n    B2AI_SUBSTRATE_70 --&gt; B2AI_SUBSTRATE_75\n    B2AI_SUBSTRATE_70 --&gt; B2AI_SUBSTRATE_76\n    B2AI_SUBSTRATE_70 --&gt; B2AI_SUBSTRATE_77\n    B2AI_SUBSTRATE_70 --&gt; B2AI_SUBSTRATE_78\n    B2AI_SUBSTRATE_73 --&gt; B2AI_SUBSTRATE_74\n    B2AI_SUBSTRATE_79 --&gt; B2AI_SUBSTRATE_80\n\n    click B2AI_SUBSTRATE_1 \"array/\" \"Array\"\n    click B2AI_SUBSTRATE_2 \"associative-array/\" \"Associative Array\"\n    click B2AI_SUBSTRATE_3 \"bids/\" \"BIDS\"\n    click B2AI_SUBSTRATE_4 \"bigquery/\" \"BigQuery\"\n    click B2AI_SUBSTRATE_5 \"column-store/\" \"Column Store\"\n    click B2AI_SUBSTRATE_6 \"comma-separated-values/\" \"Comma-separated values\"\n    click B2AI_SUBSTRATE_7 \"data/\" \"Data\"\n    click B2AI_SUBSTRATE_8 \"data-frame/\" \"Data Frame\"\n    click B2AI_SUBSTRATE_9 \"database/\" \"Database\"\n    click B2AI_SUBSTRATE_10 \"delimited-text/\" \"Delimited Text\"\n    click B2AI_SUBSTRATE_11 \"dicom/\" \"DICOM\"\n    click B2AI_SUBSTRATE_12 \"directed-acyclic-graph/\" \"Directed acyclic graph\"\n    click B2AI_SUBSTRATE_13 \"document-database/\" \"Document Database\"\n    click B2AI_SUBSTRATE_14 \"graph/\" \"Graph\"\n    click B2AI_SUBSTRATE_15 \"graph-database/\" \"Graph Database\"\n    click B2AI_SUBSTRATE_16 \"hdf5/\" \"HDF5\"\n    click B2AI_SUBSTRATE_17 \"heap/\" \"Heap\"\n    click B2AI_SUBSTRATE_18 \"hierarchical-array/\" \"Hierarchical Array\"\n    click B2AI_SUBSTRATE_19 \"image/\" \"Image\"\n    click B2AI_SUBSTRATE_20 \"json/\" \"JSON\"\n    click B2AI_SUBSTRATE_21 \"kgx-tsv/\" \"KGX TSV\"\n    click B2AI_SUBSTRATE_22 \"mongodb/\" \"MongoDB\"\n    click B2AI_SUBSTRATE_23 \"mysql/\" \"MySQL\"\n    click B2AI_SUBSTRATE_24 \"n-dimensional-array/\" \"N-Dimensional Array\"\n    click B2AI_SUBSTRATE_25 \"neo4j/\" \"Neo4j\"\n    click B2AI_SUBSTRATE_26 \"neural-network-model/\" \"Neural Network Model\"\n    click B2AI_SUBSTRATE_27 \"nnef/\" \"NNEF\"\n    click B2AI_SUBSTRATE_28 \"onnx/\" \"ONNX\"\n    click B2AI_SUBSTRATE_29 \"pandas-dataframe/\" \"Pandas DataFrame\"\n    click B2AI_SUBSTRATE_30 \"parquet/\" \"Parquet\"\n    click B2AI_SUBSTRATE_31 \"postgresql/\" \"PostgreSQL\"\n    click B2AI_SUBSTRATE_32 \"property-graph/\" \"Property graph\"\n    click B2AI_SUBSTRATE_33 \"pytorch-tensor/\" \"PyTorch Tensor\"\n    click B2AI_SUBSTRATE_34 \"r-data-frame/\" \"R data.frame\"\n    click B2AI_SUBSTRATE_35 \"r-tibble/\" \"R tibble\"\n    click B2AI_SUBSTRATE_36 \"raster-image/\" \"Raster Image\"\n    click B2AI_SUBSTRATE_37 \"relational-database/\" \"Relational Database\"\n    click B2AI_SUBSTRATE_38 \"set/\" \"Set\"\n    click B2AI_SUBSTRATE_39 \"string/\" \"String\"\n    click B2AI_SUBSTRATE_40 \"summarizedexperiment/\" \"SummarizedExperiment\"\n    click B2AI_SUBSTRATE_41 \"tab-separated-values/\" \"Tab-separated values\"\n    click B2AI_SUBSTRATE_42 \"tensor/\" \"Tensor\"\n    click B2AI_SUBSTRATE_43 \"text/\" \"Text\"\n    click B2AI_SUBSTRATE_44 \"tree/\" \"Tree\"\n    click B2AI_SUBSTRATE_45 \"trie/\" \"Trie\"\n    click B2AI_SUBSTRATE_46 \"vector/\" \"Vector\"\n    click B2AI_SUBSTRATE_47 \"vector-image/\" \"Vector Image\"\n    click B2AI_SUBSTRATE_48 \"waveform-audio-file-format/\" \"Waveform Audio File Format\"\n    click B2AI_SUBSTRATE_49 \"waveform-data/\" \"Waveform Data\"\n    click B2AI_SUBSTRATE_50 \"xarray/\" \"xarray\"\n    click B2AI_SUBSTRATE_51 \"zarr/\" \"Zarr\"\n    click B2AI_SUBSTRATE_52 \"compressed-data/\" \"Compressed Data\"\n    click B2AI_SUBSTRATE_53 \"bed/\" \"BED\"\n    click B2AI_SUBSTRATE_54 \"vector-database/\" \"Vector Database\"\n    click B2AI_SUBSTRATE_55 \"pinecone/\" \"Pinecone\"\n    click B2AI_SUBSTRATE_56 \"immunofluorescence-image/\" \"Immunofluorescence Image\"\n    click B2AI_SUBSTRATE_57 \"spectral-data/\" \"Spectral Data\"\n    click B2AI_SUBSTRATE_58 \"mass-spectrometry-data/\" \"Mass Spectrometry Data\"\n    click B2AI_SUBSTRATE_59 \"size-exclusion-chromatography-mass-spectrometry-data/\" \"Size Exclusion Chromatography-Mass Spectrometry Data\"\n    click B2AI_SUBSTRATE_60 \"sequence/\" \"Sequence\"\n    click B2AI_SUBSTRATE_61 \"dna-sequence-data/\" \"DNA Sequence Data\"\n    click B2AI_SUBSTRATE_62 \"rna-sequence-data/\" \"RNA Sequence Data\"\n    click B2AI_SUBSTRATE_63 \"single-cell-rna-sequence-data/\" \"Single-cell RNA Sequence Data\"\n    click B2AI_SUBSTRATE_64 \"perturb-seq-data/\" \"Perturb-seq Data\"\n    click B2AI_SUBSTRATE_65 \"retinal-image/\" \"Retinal Image\"\n    click B2AI_SUBSTRATE_66 \"fluorescence-lifetime-imaging-ophthalmoscopy-data/\" \"Fluorescence Lifetime Imaging Ophthalmoscopy data\"\n    click B2AI_SUBSTRATE_67 \"optical-coherence-tomography-data/\" \"Optical coherence tomography data\"\n    click B2AI_SUBSTRATE_68 \"optical-coherence-tomography-angiography-data/\" \"Optical coherence tomography angiography data\"\n    click B2AI_SUBSTRATE_69 \"time-series-data/\" \"Time-series data\"\n    click B2AI_SUBSTRATE_70 \"physiological-data/\" \"Physiological data\"\n    click B2AI_SUBSTRATE_71 \"heart-rate/\" \"Heart rate\"\n    click B2AI_SUBSTRATE_72 \"oxygen-saturation/\" \"Oxygen saturation\"\n    click B2AI_SUBSTRATE_73 \"physical-activity-data/\" \"Physical activity data\"\n    click B2AI_SUBSTRATE_74 \"caloric-burn-data/\" \"Caloric burn data\"\n    click B2AI_SUBSTRATE_75 \"respiratory-rate/\" \"Respiratory rate\"\n    click B2AI_SUBSTRATE_76 \"sleep-tracking-data/\" \"Sleep tracking data\"\n    click B2AI_SUBSTRATE_77 \"stress-tracking-data/\" \"Stress tracking data\"\n    click B2AI_SUBSTRATE_78 \"glucose-monitoring-data/\" \"Glucose monitoring data\"\n    click B2AI_SUBSTRATE_79 \"participant-response-data/\" \"Participant response data\"\n    click B2AI_SUBSTRATE_80 \"questionnaire-response-data/\" \"Questionnaire response data\"\n    click B2AI_SUBSTRATE_81 \"file-headers/\" \"File headers\"\n</code></pre>"},{"location":"topics/","title":"Topics in the Bridge2AI Standards Explorer","text":"<p>The following topics are used in the Standards Explorer:</p>"},{"location":"topics/#topic-hierarchy","title":"Topic Hierarchy","text":"<p>Below is an interactive Mermaid diagram representing a subset of the topic hierarchy. Click any node to navigate to its page.</p> <pre><code>flowchart LR\n     %% Core root\n        DATA([Data]):::topic\n\n        %% High-level branches\n        DATA --&gt; BIO(Biology)\n        DATA --&gt; CLINOBS(Clinical Observations)\n        DATA --&gt; DEMO(Demographics)\n        DATA --&gt; IMAGE(Image)\n        DATA --&gt; PHENO(Phenotype)\n        DATA --&gt; TEXT(Text)\n        DATA --&gt; WAVE(Waveform)\n        DATA --&gt; NETPATH(\"Networks and Pathways\")\n        DATA --&gt; GOV(Governance)\n        DATA --&gt; MH(mHealth)\n        DATA --&gt; GEO(Geolocation)\n        DATA --&gt; DISEASE(Disease)\n        DATA --&gt; SURVEY(Survey)\n        DATA --&gt; ENV(Environment)\n        DATA --&gt; CHEM(Cheminformatics)\n\n        %% Molecular / omics branch\n        BIO --&gt; MOLBIO(\"Molecular Biology\")\n        MOLBIO --&gt; OMICS(Omics)\n        OMICS --&gt; GENOME(Genome)\n        OMICS --&gt; PROTEOME(Proteome)\n        OMICS --&gt; METAB(Metabolome)\n        OMICS --&gt; TRANSCRIPTOME(Transcriptome)\n        TRANSCRIPTOME --&gt; TRANSCRIPT(Transcript)\n        GENOME --&gt; GENE(Gene)\n        GENE --&gt; VARIANT(Variant)\n        PROTEOME --&gt; PROTEIN(Protein)\n        PROTEIN --&gt; PROTEIN_STRUCT(\"Protein Structure Model\")\n\n        %% Cellular / physiology\n        BIO --&gt; CELL(Cell)\n        CELL --&gt; NEURON(Neuron)\n        CELL --&gt; CARDIO(Cardiomyocyte)\n        BIO --&gt; RESP(Respiration)\n\n        %% Imaging\n        IMAGE --&gt; MICROIMG(\"Microscale Imaging\")\n        IMAGE --&gt; NEUROIMG(\"Neurologic Imaging\")\n        IMAGE --&gt; OPHTHIMG(\"Ophthalmic Imaging\")\n\n        %% Clinical observation sub-areas\n        CLINOBS --&gt; EHR(EHR)\n        CLINOBS --&gt; NEURO(Neurology)\n        NEURO --&gt; NEURODIS(\"Neurological Disorders\")\n        CLINOBS --&gt; PSYCH(Psychiatry)\n        PSYCH --&gt; PSYCHDIS(\"Psychiatric Disorders\")\n\n        %% Mobile / monitoring\n        MH --&gt; ACTMON(\"Activity Monitoring\")\n        MH --&gt; GLUCOSE(\"Glucose Monitoring\")\n\n        %% Waveforms / voice\n        WAVE --&gt; VOICE(Voice)\n\n        %% Social determinants (multi-parent shown via dashed helpers)\n        DEMO --&gt; SDOH(SDoH)\n        ENV --&gt; SDOH\n        GEO --&gt; SDOH\n\n        %% Disease specializations\n        DISEASE --&gt; EYE(\"Eye Diseases\")\n        DISEASE --&gt; DIAB(Diabetes)\n        DISEASE --&gt; RESP_DIS(\"Respiratory Disorders\")\n        DISEASE --&gt; VOICEDIS(\"Voice Disorders\")\n\n        %% Chemistry / drugs\n        CHEM --&gt; DRUG(Drug)\n\n        %% Text related\n        TEXT --&gt; LIT(Literature)\n        TEXT --&gt; SOCIAL(\"Social Media\")\n        LIT --&gt; TRAIN(Training)\n\n        classDef topic fill:#eef4ff,stroke:#4a3b8f,stroke-width:1px,rx:4,ry:4;\n\n        %% Click interactions\n        click DATA \"Data/\" \"Data\"\n        click BIO \"Biology/\" \"Biology\"\n        click CLINOBS \"ClinicalObservations/\" \"Clinical Observations\"\n        click DEMO \"Demographics/\" \"Demographics\"\n        click PHENO \"Phenotype/\" \"Phenotype\"\n        click IMAGE \"Image/\" \"Image\"\n        click MICROIMG \"MicroscaleImaging/\" \"Microscale Imaging\"\n        click NEUROIMG \"NeurologicImaging/\" \"Neurologic Imaging\"\n        click OPHTHIMG \"OphthalmicImaging/\" \"Ophthalmic Imaging\"\n        click LIT \"Literature/\" \"Literature\"\n        click TEXT \"Text/\" \"Text\"\n        click TRAIN \"Training/\" \"Training\"\n        click MH \"mHealth/\" \"mHealth\"\n        click ACTMON \"ActivityMonitoring/\" \"Activity Monitoring\"\n        click GLUCOSE \"GlucoseMonitoring/\" \"Glucose Monitoring\"\n        click WAVE \"Waveform/\" \"Waveform\"\n        click VOICE \"Voice/\" \"Voice\"\n        click ENV \"Environment/\" \"Environment\"\n        click GEO \"Geolocation/\" \"Geolocation\"\n        click GOV \"Governance/\" \"Governance\"\n        click MOLBIO \"MolecularBiology/\" \"Molecular Biology\"\n        click OMICS \"Omics/\" \"Omics\"\n        click GENOME \"Genome/\" \"Genome\"\n        click GENE \"Gene/\" \"Gene\"\n        click VARIANT \"Variant/\" \"Variant\"\n        click PROTEOME \"Proteome/\" \"Proteome\"\n        click PROTEIN \"Protein/\" \"Protein\"\n        click PROTEIN_STRUCT \"ProteinStructureModel/\" \"Protein Structure Model\"\n        click METAB \"Metabolome/\" \"Metabolome\"\n        click TRANSCRIPTOME \"Transcriptome/\" \"Transcriptome\"\n        click TRANSCRIPT \"Transcript/\" \"Transcript\"\n        click EHR \"EHR/\" \"EHR\"\n        click NEURO \"Neurology/\" \"Neurology\"\n        click NEURODIS \"NeurologicalDisorders/\" \"Neurological Disorders\"\n        click PSYCH \"Psychiatry/\" \"Psychiatry\"\n        click PSYCHDIS \"PsychiatricDisorders/\" \"Psychiatric Disorders\"\n        click DISEASE \"Disease/\" \"Disease\"\n        click DIAB \"Diabetes/\" \"Diabetes\"\n        click RESP_DIS \"RespiratoryDisorders/\" \"Respiratory Disorders\"\n        click EYE \"EyeDiseases/\" \"Eye Diseases\"\n        click VOICEDIS \"VoiceDisorders/\" \"Voice Disorders\"\n        click DRUG \"Drug/\" \"Drug\"\n        click CHEM \"Cheminformatics/\" \"Cheminformatics\"\n        click SURVEY \"Survey/\" \"Survey\"\n        click CELL \"Cell/\" \"Cell\"\n        click NEURON \"Neuron/\" \"Neuron\"\n        click CARDIO \"Cardiomyocyte/\" \"Cardiomyocyte\"\n        click RESP \"Respiration/\" \"Respiration\"\n        click SOCIAL \"SocialMedia/\" \"Social Media\"\n        click SDOH \"SDoH/\" \"Social Determinants of Health\"\n        click NETPATH \"NetworksAndPathways/\" \"Networks and Pathways\"\n</code></pre> <p>Note: For readability, some cross-links (e.g., multi-parent relationships) are not shown.</p>"},{"location":"substrates/array/","title":"Array","text":"<p>id: B2AI_SUBSTRATE:1</p> <p>name: Array</p> <p>description: A data type that represents a collection of elements (values or variables), each selected by one or more indices.</p> <p>edam id: edam.data:2082</p> <p>ncit id: ncit:C26358</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:7 (Data)</li> </ul>"},{"location":"substrates/associative-array/","title":"Associative Array","text":"<p>id: B2AI_SUBSTRATE:2</p> <p>name: Associative Array</p> <p>description: A data structure that stores a collection of key-value pairs, where each key is associated with a value. It allows for fast and efficient lookups by using the keys as indices to access the corresponding values.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:1 (Array)</li> </ul>"},{"location":"substrates/bed/","title":"Bed","text":"<p>id: B2AI_SUBSTRATE:53</p> <p>name: BED</p> <p>description: BED (Browser Extensible Data) format provides a flexible way to define the data lines that are displayed in a genome annotation track.</p> <p>edam id: edam.format:3003</p> <p>ncit id: ncit:C153367</p> <p>file extensions: txt bed</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:10 (Delimited Text)</li> </ul>"},{"location":"substrates/bids/","title":"BIDS","text":"<p>id: B2AI_SUBSTRATE:3</p> <p>name: BIDS</p> <p>description: Data conforming to the Brain Imaging Data Structure (BIDS).</p> <p>subclass of:</p> <ul> <li> <p>B2AI_SUBSTRATE:19 (Image)</p> </li> <li> <p>B2AI_SUBSTRATE:49 (Waveform Data)</p> </li> </ul>"},{"location":"substrates/bigquery/","title":"BigQuery","text":"<p>id: B2AI_SUBSTRATE:4</p> <p>name: BigQuery</p> <p>description: A fully managed, serverless data warehouse that enables scalable analysis over petabytes of data. It is a Platform as a Service (PaaS) that supports querying using ANSI SQL.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:5 (Column Store)</li> </ul>"},{"location":"substrates/caloric-burn-data/","title":"Caloric burn data","text":"<p>id: B2AI_SUBSTRATE:74</p> <p>name: Caloric burn data</p> <p>description: Caloric burn data is a type of physical activity data that measures the number of calories burned during physical activity. It is used in biomedicine and biology to assess energy expenditure and the effects of physical activity on metabolism and other physical characteristics.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:73 (Physical activity data)</li> </ul>"},{"location":"substrates/column-store/","title":"Column Store","text":"<p>id: B2AI_SUBSTRATE:5</p> <p>name: Column Store</p> <p>description: A database that stores data tables by column rather than by row.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:9 (Database)</li> </ul>"},{"location":"substrates/comma-separated-values/","title":"Comma-separated values","text":"<p>id: B2AI_SUBSTRATE:6</p> <p>name: Comma-separated values</p> <p>description: Any text or mixed data with distinct records in columns separated by commas and rows separated by newlines.</p> <p>edam id: edam.format:3752</p> <p>ncit id: ncit:C182456</p> <p>file extensions: csv</p> <p>limitations:</p> <ul> <li>Differences in newline characters can cause inconsistency across operating systems.</li> </ul> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:10 (Delimited Text)</li> </ul>"},{"location":"substrates/compressed-data/","title":"Compressed Data","text":"<p>id: B2AI_SUBSTRATE:52</p> <p>name: Compressed Data</p> <p>description: Data in which information is represented with fewer bits than the original, uncompressed representation.</p> <p>ncit id: ncit:C190416</p> <p>file extensions: tar zip</p> <p>limitations:</p> <ul> <li> <p>Must be decompressed before reading.</p> </li> <li> <p>Compression may be lossy, i.e., it discards information in the process of encoding.</p> </li> </ul> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:7 (Data)</li> </ul>"},{"location":"substrates/data-frame/","title":"Data Frame","text":"<p>id: B2AI_SUBSTRATE:8</p> <p>name: Data Frame</p> <p>description: A data structure that organizes data into a 2-dimensional table of rows and columns.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:7 (Data)</li> </ul>"},{"location":"substrates/data/","title":"Data","text":"<p>id: B2AI_SUBSTRATE:7</p> <p>name: Data</p> <p>description: Any collection of discrete values conveying information.</p> <p>edam id: edam.data:0006</p> <p>mesh id: mesh:D064886</p> <p>ncit id: ncit:C25474</p>"},{"location":"substrates/database/","title":"Database","text":"<p>id: B2AI_SUBSTRATE:9</p> <p>name: Database</p> <p>description: An organized collection of structured information, stored electronically and organized for rapid search and retrieval.</p> <p>mesh id: mesh:D019991</p> <p>ncit id: ncit:C15426</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:7 (Data)</li> </ul>"},{"location":"substrates/delimited-text/","title":"Delimited Text","text":"<p>id: B2AI_SUBSTRATE:10</p> <p>name: Delimited Text</p> <p>description: Any data with distinct records separated or delimited by a specific character pattern.</p> <p>edam id: edam.format:3751</p> <p>file extensions: txt</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:43 (Text)</li> </ul>"},{"location":"substrates/dicom/","title":"DICOM","text":"<p>id: B2AI_SUBSTRATE:11</p> <p>name: DICOM</p> <p>description: An image and metadata format for radiology imaging.</p> <p>edam id: edam.format:3548</p> <p>ncit id: ncit:C63537</p> <p>file extensions: dicom dcm</p> <p>limitations:</p> <ul> <li> <p>Files are generally named using unique identifiers that may not be compatible across all operating systems (i.e., they may be too long).</p> </li> <li> <p>Patient data is included in each image file header so all files must be processed in order to anonymize them.</p> </li> </ul> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:36 (Raster Image)</li> </ul>"},{"location":"substrates/directed-acyclic-graph/","title":"Directed acyclic graph","text":"<p>id: B2AI_SUBSTRATE:12</p> <p>name: Directed acyclic graph</p> <p>description: A directed graph with no directed cycles.</p> <p>ncit id: ncit:C45803</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:14 (Graph)</li> </ul>"},{"location":"substrates/dna-sequence-data/","title":"Dna sequence data","text":"<p>id: B2AI_SUBSTRATE:61</p> <p>name: DNA Sequence Data</p> <p>description: DNA sequence data is a representation of the nucleotide sequence of a DNA molecule. It may be a raw sequence or a processed sequence with additional metadata, such as annotations or quality scores.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:60 (Sequence)</li> </ul>"},{"location":"substrates/document-database/","title":"Document Database","text":"<p>id: B2AI_SUBSTRATE:13</p> <p>name: Document Database</p> <p>description: A database that stores and retrieves information in documents.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:9 (Database)</li> </ul>"},{"location":"substrates/file-headers/","title":"File headers","text":"<p>id: B2AI_SUBSTRATE:81</p> <p>name: File headers</p> <p>description: Metadata stored in file headers.</p>"},{"location":"substrates/fluorescence-lifetime-imaging-ophthalmoscopy-data/","title":"Fluorescence lifetime imaging ophthalmoscopy data","text":"<p>id: B2AI_SUBSTRATE:66</p> <p>name: Fluorescence Lifetime Imaging Ophthalmoscopy data</p> <p>description: Fluorescence Lifetime Imaging Ophthalmoscopy (FLIO) data is the result of imaging the retina using FLIO, a technique that measures the fluorescence lifetime of endogenous fluorophores in the retina. FLIO data is used in ophthalmology to diagnose and monitor eye diseases, such as age-related macular degeneration and retinitis pigmentosa.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:65 (Retinal Image)</li> </ul>"},{"location":"substrates/glucose-monitoring-data/","title":"Glucose monitoring data","text":"<p>id: B2AI_SUBSTRATE:78</p> <p>name: Glucose monitoring data</p> <p>description: Glucose monitoring data is time-series data that captures the blood glucose levels of living organisms. It is used in biomedicine and biology to study the effects of diet, exercise, and medication on blood sugar levels. It is frequently collected through wearable devices, such as continuous glucose monitors and blood glucose meters.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:70 (Physiological data)</li> </ul>"},{"location":"substrates/graph-database/","title":"Graph Database","text":"<p>id: B2AI_SUBSTRATE:15</p> <p>name: Graph Database</p> <p>description: A type of database that stores nodes and relationships instead of tables or documents.</p> <p>subclass of:</p> <ul> <li> <p>B2AI_SUBSTRATE:9 (Database)</p> </li> <li> <p>B2AI_SUBSTRATE:14 (Graph)</p> </li> </ul>"},{"location":"substrates/graph/","title":"Graph","text":"<p>id: B2AI_SUBSTRATE:14</p> <p>name: Graph</p> <p>description: A structure of nodes (sometimes called vertices) and edges between them.</p> <p>edam id: edam.format:3617</p> <p>ncit id: ncit:C75914</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:7 (Data)</li> </ul>"},{"location":"substrates/hdf5/","title":"HDF5","text":"<p>id: B2AI_SUBSTRATE:16</p> <p>name: HDF5</p> <p>description: A data model, library, and file format for storing and managing data. It supports an unlimited variety of datatypes, and is designed for flexible and efficient I/O and for high volume and complex data.</p> <p>edam id: edam.format:3590</p> <p>ncit id: ncit:C184763</p> <p>file extensions: h5 hdf5</p> <p>limitations:</p> <ul> <li>Structure is not optimized for data access through cloud storage infrastructure.</li> </ul> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:18 (Hierarchical Array)</li> </ul>"},{"location":"substrates/heap/","title":"Heap","text":"<p>id: B2AI_SUBSTRATE:17</p> <p>name: Heap</p> <p>description: A complete binary tree, i.e., each node has no more than two children.</p> <p>subclass of:</p> <ul> <li>Tree</li> </ul>"},{"location":"substrates/heart-rate/","title":"Heart rate","text":"<p>id: B2AI_SUBSTRATE:71</p> <p>name: Heart rate</p> <p>description: Heart rate is a physiological signal that measures the number of heartbeats per minute. It is used in biomedicine and biology to assess cardiovascular health and function.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:70 (Physiological data)</li> </ul>"},{"location":"substrates/hierarchical-array/","title":"Hierarchical Array","text":"<p>id: B2AI_SUBSTRATE:18</p> <p>name: Hierarchical Array</p> <p>description: A data structure of a list, such that list elements may be subsets of other elements.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:1 (Array)</li> </ul>"},{"location":"substrates/image/","title":"Image","text":"<p>id: B2AI_SUBSTRATE:19</p> <p>name: Image</p> <p>description: Any visual representation of something.</p> <p>edam id: edam.data:2968</p> <p>ncit id: ncit:C48179</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:7 (Data)</li> </ul>"},{"location":"substrates/immunofluorescence-image/","title":"Immunofluorescence Image","text":"<p>id: B2AI_SUBSTRATE:56</p> <p>name: Immunofluorescence Image</p> <p>description: An immunofluorescence image is a picture derived from microscopy that uses fluorescently labeled antibodies to visualize the location and distribution of specific proteins or molecules within cells or tissues.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:36 (Raster Image)</li> </ul>"},{"location":"substrates/json/","title":"JSON","text":"<p>id: B2AI_SUBSTRATE:20</p> <p>name: JSON</p> <p>description: JavaScript Object Notation (JSON) is a lightweight format for storing and transporting data.</p> <p>edam id: edam.format:3464</p> <p>ncit id: ncit:C184769</p> <p>file extensions: json</p> <p>subclass of:</p> <ul> <li> <p>B2AI_SUBSTRATE:2 (Associative Array)</p> </li> <li> <p>B2AI_SUBSTRATE:18 (Hierarchical Array)</p> </li> </ul>"},{"location":"substrates/kgx-tsv/","title":"KGX TSV","text":"<p>id: B2AI_SUBSTRATE:21</p> <p>name: KGX TSV</p> <p>description: A tab-delimited data format for exchanging property graph data.</p> <p>file extensions: tsv</p> <p>subclass of:</p> <ul> <li> <p>B2AI_SUBSTRATE:32 (Property graph)</p> </li> <li> <p>B2AI_SUBSTRATE:41 (Tab-separated values)</p> </li> </ul>"},{"location":"substrates/mass-spectrometry-data/","title":"Mass Spectrometry Data","text":"<p>id: B2AI_SUBSTRATE:58</p> <p>name: Mass Spectrometry Data</p> <p>description: Mass spectrometry data, also referred to as a mass spectrum, is a representation of the mass to charge (m/z) ratios of the ions present in a sample plotted against their intensities. Each peak in a mass spectrum shows a component of unique m/z in the sample, and heights of the peaks connote the relative abundance of the various components in the sample.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:57 (Spectral Data)</li> </ul>"},{"location":"substrates/mongodb/","title":"MongoDB","text":"<p>id: B2AI_SUBSTRATE:22</p> <p>name: MongoDB</p> <p>description: A non-relational document database that provides support for JSON-like storage.</p> <p>file extensions: mongo</p> <p>limitations:</p> <ul> <li>The maximum size of an individual document in MongoDB is 16MB with a nested depth of 100 levels.</li> </ul> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:13 (Document Database)</li> </ul>"},{"location":"substrates/mysql/","title":"MySQL","text":"<p>id: B2AI_SUBSTRATE:23</p> <p>name: MySQL</p> <p>description: A relational database management system developed by Oracle that is based on structured query language (SQL).</p> <p>file extensions: mysql sql</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:37 (Relational Database)</li> </ul>"},{"location":"substrates/n-dimensional-array/","title":"N-Dimensional Array","text":"<p>id: B2AI_SUBSTRATE:24</p> <p>name: N-Dimensional Array</p> <p>description: A data structure that can store a collection of items, where each item is identified by a set of indices. The number of indices required to identify an item is referred to as the dimension of the array, hence the name N-dimensional array.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:1 (Array)</li> </ul>"},{"location":"substrates/neo4j/","title":"Neo4j","text":"<p>id: B2AI_SUBSTRATE:25</p> <p>name: Neo4j</p> <p>description: A popular graph database platform.</p> <p>limitations:</p> <ul> <li>All data is stored locally - this can cause slowdowns when data exceeds available memory.</li> </ul> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:15 (Graph Database)</li> </ul>"},{"location":"substrates/neural-network-model/","title":"Neural Network Model","text":"<p>id: B2AI_SUBSTRATE:26</p> <p>name: Neural Network Model</p> <p>description: The result of training a neural network on a certain set of inputs.</p> <p>mesh id: mesh:D016571</p> <p>ncit id: ncit:C17429</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:7 (Data)</li> </ul>"},{"location":"substrates/nnef/","title":"NNEF","text":"<p>id: B2AI_SUBSTRATE:27</p> <p>name: NNEF</p> <p>description: An exchange format for neural network models produced using Torch, Caffe, TensorFlow, Theano, Chainer, Caffe2, PyTorch, or MXNet.</p> <p>file extensions: nnef</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:26 (Neural Network Model)</li> </ul>"},{"location":"substrates/onnx/","title":"ONNX","text":"<p>id: B2AI_SUBSTRATE:28</p> <p>name: ONNX</p> <p>description: An open format built to represent machine learning models.</p> <p>file extensions: onnx</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:26 (Neural Network Model)</li> </ul>"},{"location":"substrates/optical-coherence-tomography-angiography-data/","title":"Optical coherence tomography angiography data","text":"<p>id: B2AI_SUBSTRATE:68</p> <p>name: Optical coherence tomography angiography data</p> <p>description: Optical coherence tomography angiography (OCTA) is a non-invasive imaging technique that uses light waves to create high-resolution images of blood flow in the retina and choroid, offering a detailed view of the eye's microvasculature without the need for dye injection. OCTA data is used in ophthalmology to diagnose and monitor eye diseases, such as diabetic retinopathy and macular degeneration.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:67 (Optical coherence tomography data)</li> </ul>"},{"location":"substrates/optical-coherence-tomography-data/","title":"Optical coherence tomography data","text":"<p>id: B2AI_SUBSTRATE:67</p> <p>name: Optical coherence tomography data</p> <p>description: Optical coherence tomography (OCT) data is the result of imaging the retina using OCT, a non-invasive imaging technique that uses light waves to take cross-sectional images of the retina. OCT data is used in ophthalmology to diagnose and monitor eye diseases, such as glaucoma and macular degeneration.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:65 (Retinal Image)</li> </ul>"},{"location":"substrates/oxygen-saturation/","title":"Oxygen saturation","text":"<p>id: B2AI_SUBSTRATE:72</p> <p>name: Oxygen saturation</p> <p>description: Oxygen saturation is a physiological signal that measures the percentage of hemoglobin in the blood that is saturated with oxygen. It is used in biomedicine and biology to assess respiratory function and oxygen delivery to tissues.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:70 (Physiological data)</li> </ul>"},{"location":"substrates/pandas-dataframe/","title":"Pandas DataFrame","text":"<p>id: B2AI_SUBSTRATE:29</p> <p>name: Pandas DataFrame</p> <p>description: A two-dimensional, size-mutable, potentially heterogeneous tabular data object.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:8 (Data Frame)</li> </ul>"},{"location":"substrates/parquet/","title":"Parquet","text":"<p>id: B2AI_SUBSTRATE:30</p> <p>name: Parquet</p> <p>description: Apache Parquet is a free and open-source column-oriented data storage format in the Apache Hadoop ecosystem.</p> <p>file extensions: parquet pqt</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:5 (Column Store)</li> </ul>"},{"location":"substrates/participant-response-data/","title":"Participant response data","text":"<p>id: B2AI_SUBSTRATE:79</p> <p>name: Participant response data</p> <p>description: Participant response data is a collection of data that captures the responses of participants in a study or experiment. It may include survey responses, questionnaire data, interview transcripts, and other forms of participant feedback.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:7 (Data)</li> </ul>"},{"location":"substrates/perturb-seq-data/","title":"Perturb-seq Data","text":"<p>id: B2AI_SUBSTRATE:64</p> <p>name: Perturb-seq Data</p> <p>description: Perturb-seq data is the result of combining single-cell RNA sequencing (RNA-seq) and clustered regularly interspaced short palindromic repeats (CRISPR)-based perturbations to perform many pooled phenotype assays.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:63 (Single-cell RNA Sequence Data)</li> </ul>"},{"location":"substrates/physical-activity-data/","title":"Physical activity data","text":"<p>id: B2AI_SUBSTRATE:73</p> <p>name: Physical activity data</p> <p>description: Physical activity data is time-series data that captures the movement and activity levels of living organisms. It is used in biomedicine and biology to study the effects of physical activity on health and well-being. It is frequently collected through wearable devices, such as fitness trackers and smartwatches.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:70 (Physiological data)</li> </ul>"},{"location":"substrates/physiological-data/","title":"Physiological data","text":"<p>id: B2AI_SUBSTRATE:70</p> <p>name: Physiological data</p> <p>description: Physiological data is time-series data that captures the physiological signals of living organisms, such as heart rate, blood pressure, temperature, and brain activity. It is used in biomedicine and biology to study the health and function of biological systems over time.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:69 (Time-series data)</li> </ul>"},{"location":"substrates/pinecone/","title":"Pinecone","text":"<p>id: B2AI_SUBSTRATE:55</p> <p>name: Pinecone</p> <p>description: A vector database. Includes a single-stage filtering function allowing complex searches in single queries.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:54 (Vector Database)</li> </ul>"},{"location":"substrates/postgresql/","title":"PostgreSQL","text":"<p>id: B2AI_SUBSTRATE:31</p> <p>name: PostgreSQL</p> <p>description: An open-source relational database management system emphasizing extensibility and SQL compliance.</p> <p>file extensions: sql</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:37 (Relational Database)</li> </ul>"},{"location":"substrates/property-graph/","title":"Property graph","text":"<p>id: B2AI_SUBSTRATE:32</p> <p>name: Property graph</p> <p>description: A graph model in which nodes and edges may be assigned properties (i.e., values or key-value pairs).</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:14 (Graph)</li> </ul>"},{"location":"substrates/pytorch-tensor/","title":"PyTorch Tensor","text":"<p>id: B2AI_SUBSTRATE:33</p> <p>name: PyTorch Tensor</p> <p>description: In PyTorch, a torch.Tensor is a multi-dimensional matrix containing elements of a single data type.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:42 (Tensor)</li> </ul>"},{"location":"substrates/questionnaire-response-data/","title":"Questionnaire response data","text":"<p>id: B2AI_SUBSTRATE:80</p> <p>name: Questionnaire response data</p> <p>description: Questionnaire response data is a type of participant response data that captures the responses of participants to a series of questions. This data may include the responses themselves, as well as metadata about the participants and the study, including the questions asked, the response format, and the response rate.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:79 (Participant response data)</li> </ul>"},{"location":"substrates/r-data-frame/","title":"R data.frame","text":"<p>id: B2AI_SUBSTRATE:34</p> <p>name: R data.frame</p> <p>description: A tightly coupled collection of variables that shares many of the properties of matrices and of lists.</p> <p>limitations:</p> <ul> <li>Memory-limited.</li> </ul> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:8 (Data Frame)</li> </ul>"},{"location":"substrates/r-tibble/","title":"R tibble","text":"<p>id: B2AI_SUBSTRATE:35</p> <p>name: R tibble</p> <p>description: A redesigned version of an R data frame. Never changes the input type, can have columns that are lists, can have non-standard variable names, can start with a number or contain spaces, only recycles vectors of length 1, and never creates row names.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:8 (Data Frame)</li> </ul>"},{"location":"substrates/raster-image/","title":"Raster Image","text":"<p>id: B2AI_SUBSTRATE:36</p> <p>name: Raster Image</p> <p>description: Any visual representation of something represented as a two-dimensional matrix of pixel values denoting intensity, potentially accompanied by other values for colors or other image properties (e.g., compression).</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:19 (Image)</li> </ul>"},{"location":"substrates/relational-database/","title":"Relational Database","text":"<p>id: B2AI_SUBSTRATE:37</p> <p>name: Relational Database</p> <p>description: A database that stores and provides access to data points related to one another.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:9 (Database)</li> </ul>"},{"location":"substrates/respiratory-rate/","title":"Respiratory rate","text":"<p>id: B2AI_SUBSTRATE:75</p> <p>name: Respiratory rate</p> <p>description: Respiratory rate is a physiological signal that measures the number of breaths per minute. It is used in biomedicine and biology to assess respiratory function and the effects of physical activity on breathing patterns.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:70 (Physiological data)</li> </ul>"},{"location":"substrates/retinal-image/","title":"Retinal Image","text":"<p>id: B2AI_SUBSTRATE:65</p> <p>name: Retinal Image</p> <p>description: A retinal image is a picture derived from imaging the retina, the light-sensitive tissue at the back of the eye. Retinal images are used in ophthalmology to diagnose and monitor eye diseases, such as diabetic retinopathy and age-related macular degeneration.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:36 (Raster Image)</li> </ul>"},{"location":"substrates/rna-sequence-data/","title":"RNA Sequence Data","text":"<p>id: B2AI_SUBSTRATE:62</p> <p>name: RNA Sequence Data</p> <p>description: RNA sequence data is a representation of the nucleotide sequence of one or more RNA molecules. It may be a raw sequence or a processed sequence with additional metadata, such as annotations or quality scores. It may be called transcriptomic data when it is derived from RNA sequencing, and in general may be referred to as RNA-seq data.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:60 (Sequence)</li> </ul>"},{"location":"substrates/sequence/","title":"Sequence","text":"<p>id: B2AI_SUBSTRATE:60</p> <p>name: Sequence</p> <p>description: A sequence is an ordered collection of elements, typically characters or numbers, that may be of fixed or variable length. This specifically refers to a biological sequence, such as a DNA, RNA, or protein sequence, so the characters are typically nucleotides or amino acids accompanied by metadata about the sequence.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:39 (String)</li> </ul>"},{"location":"substrates/set/","title":"Set","text":"<p>id: B2AI_SUBSTRATE:38</p> <p>name: Set</p> <p>description: A sorted data structure of unique elements of the same type.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:7 (Data)</li> </ul>"},{"location":"substrates/single-cell-rna-sequence-data/","title":"Single-cell RNA Sequence Data","text":"<p>id: B2AI_SUBSTRATE:63</p> <p>name: Single-cell RNA Sequence Data</p> <p>description: Single-cell RNA sequence data is a representation of the nucleotide sequence of one or more RNA molecules from individual cells. It may be a raw sequence or a processed sequence with additional metadata, such as annotations or quality scores. It may be called single-cell transcriptomic data when it is derived from single-cell RNA sequencing.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:62 (RNA Sequence Data)</li> </ul>"},{"location":"substrates/size-exclusion-chromatography-mass-spectrometry-data/","title":"Size Exclusion Chromatography-Mass Spectrometry Data","text":"<p>id: B2AI_SUBSTRATE:59</p> <p>name: Size Exclusion Chromatography-Mass Spectrometry Data</p> <p>description: Size Exclusion Chromatography-Mass Spectrometry (SEC-MS) data is the result of combining size-exclusion chromatography for separation based on molecular size with mass spectrometry for accurate mass determination, enabling the analysis of protein complexes and their interactions</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:58 (Mass Spectrometry Data)</li> </ul>"},{"location":"substrates/sleep-tracking-data/","title":"Sleep tracking data","text":"<p>id: B2AI_SUBSTRATE:76</p> <p>name: Sleep tracking data</p> <p>description: Sleep tracking data is time-series data that captures the sleep patterns and quality of living organisms. It is used in biomedicine and biology to study the effects of sleep on health and well-being. It is frequently collected through wearable devices, such as fitness trackers and smartwatches.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:70 (Physiological data)</li> </ul>"},{"location":"substrates/spectral-data/","title":"Spectral Data","text":"<p>id: B2AI_SUBSTRATE:57</p> <p>name: Spectral Data</p> <p>description: Spectral data contains information about the intensity or strength of different frequencies or wavelengths of some type of energy, including light or other electromagnetic radiation. It may be a representation of the composition and properties of materials or signals. It may be obtained by transforming waveforms (i.e., data in the time domain) into the frequency domain with a Fourier transform or other method.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:7 (Data)</li> </ul>"},{"location":"substrates/stress-tracking-data/","title":"Stress tracking data","text":"<p>id: B2AI_SUBSTRATE:77</p> <p>name: Stress tracking data</p> <p>description: Stress tracking data is time-series data that captures the stress levels and responses of living organisms. It is used in biomedicine and biology to study the effects of stress on health and well-being. It is frequently collected through wearable devices, such as fitness trackers and smartwatches.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:70 (Physiological data)</li> </ul>"},{"location":"substrates/string/","title":"String","text":"<p>id: B2AI_SUBSTRATE:39</p> <p>name: String</p> <p>description: An array data structure of bytes (or words) that stores a sequence of elements, typically characters, using some character encoding.</p> <p>ncit id: ncit:C45253</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:7 (Data)</li> </ul>"},{"location":"substrates/summarizedexperiment/","title":"SummarizedExperiment","text":"<p>id: B2AI_SUBSTRATE:40</p> <p>name: SummarizedExperiment</p> <p>description: The SummarizedExperiment Bioconductor container contains one or more assays, each represented by a matrix-like object of numeric or other mode. The rows typically represent genomic ranges of interest and the columns represent samples.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:18 (Hierarchical Array)</li> </ul>"},{"location":"substrates/tab-separated-values/","title":"Tab-separated values","text":"<p>id: B2AI_SUBSTRATE:41</p> <p>name: Tab-separated values</p> <p>description: Any text or mixed data with distinct records in columns separated by tab characters and rows separated by newlines.</p> <p>edam id: edam.format:3475</p> <p>ncit id: ncit:C164049</p> <p>file extensions: tsv</p> <p>limitations:</p> <ul> <li>Differences in newline characters can cause inconsistency across operating systems.</li> </ul> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:10 (Delimited Text)</li> </ul>"},{"location":"substrates/tensor/","title":"Tensor","text":"<p>id: B2AI_SUBSTRATE:42</p> <p>name: Tensor</p> <p>description: An algebraic object that describes a multilinear relationship between sets of algebraic objects related to a vector space.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:7 (Data)</li> </ul>"},{"location":"substrates/text/","title":"Text","text":"<p>id: B2AI_SUBSTRATE:43</p> <p>name: Text</p> <p>description: Any form of written information that is composed of letters, words, and sentences. This may include anything from written documents, articles, or books, to emails, social media posts, and transcribed speech. It may also include unstructured, human-readable fields of documents containing other data.</p> <p>edam id: edam.data:2526</p> <p>ncit id: ncit:C25704</p> <p>file extensions: txt</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:39 (String)</li> </ul>"},{"location":"substrates/time-series-data/","title":"Time-series data","text":"<p>id: B2AI_SUBSTRATE:69</p> <p>name: Time-series data</p> <p>description: Time-series data is a sequence of data points collected at successive points in time. It is used in biomedicine and biology to study the dynamics of biological systems over time. It may cover short or long time periods and may be collected at regular or irregular intervals.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:7 (Data)</li> </ul>"},{"location":"substrates/tree/","title":"Tree","text":"<p>id: B2AI_SUBSTRATE:44</p> <p>name: Tree</p> <p>description: An undirected graph with each pair of vertices connected by no more than one path. Also known as a connected acyclic undirected graph.</p> <p>ncit id: ncit:C45418</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:14 (Graph)</li> </ul>"},{"location":"substrates/trie/","title":"Trie","text":"<p>id: B2AI_SUBSTRATE:45</p> <p>name: Trie</p> <p>description: A sorted, associative tree. Also known as a radix tree or prefix tree.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:44 (Tree)</li> </ul>"},{"location":"substrates/vector-database/","title":"Vector Database","text":"<p>id: B2AI_SUBSTRATE:54</p> <p>name: Vector Database</p> <p>description: A database that stores and retrieves information represented as high-dimensional vectors. The original data may be very unstructured.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:9 (Database)</li> </ul>"},{"location":"substrates/vector-image/","title":"Vector Image","text":"<p>id: B2AI_SUBSTRATE:47</p> <p>name: Vector Image</p> <p>description: Any visual representation of something represented as a set of geometric shapes defined on a Cartesian plane.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:19 (Image)</li> </ul>"},{"location":"substrates/vector/","title":"Vector","text":"<p>id: B2AI_SUBSTRATE:46</p> <p>name: Vector</p> <p>description: A mathematical object that has magnitude and direction. A vector is often represented as a one-dimensional array or list with numerical elements.</p> <p>ncit id: ncit:C54169</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:7 (Data)</li> </ul>"},{"location":"substrates/waveform-audio-file-format/","title":"Waveform Audio File Format","text":"<p>id: B2AI_SUBSTRATE:48</p> <p>name: Waveform Audio File Format</p> <p>description: An audio file format standard. Generally supported by digital audio software.</p> <p>file extensions: wav</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:49 (Waveform Data)</li> </ul>"},{"location":"substrates/waveform-data/","title":"Waveform Data","text":"<p>id: B2AI_SUBSTRATE:49</p> <p>name: Waveform Data</p> <p>description: The two-dimensional representation of a signal as a function of time.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:7 (Data)</li> </ul>"},{"location":"substrates/xarray/","title":"xarray","text":"<p>id: B2AI_SUBSTRATE:50</p> <p>name: xarray</p> <p>description: A format for defining arrays with labels in the form of dimensions, coordinates, and attributes on top of raw NumPy-like arrays, which allows for more intuitive, more concise, and less error-prone user experience.</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:24 (N-Dimensional Array)</li> </ul>"},{"location":"substrates/zarr/","title":"Zarr","text":"<p>id: B2AI_SUBSTRATE:51</p> <p>name: Zarr</p> <p>description: A format for storage of large N-dimensional typed arrays. Has implementations in multiple programming languages.</p> <p>edam id: edam.format:3915</p> <p>file extensions: zarr</p> <p>subclass of:</p> <ul> <li>B2AI_SUBSTRATE:24 (N-Dimensional Array)</li> </ul>"},{"location":"topics/ActivityMonitoring/","title":"Activity Monitoring","text":"<p>id: B2AI_TOPIC:39</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Mobile health data involving estimates of physical activity frequency, duration, and/or intensity. May include data from accelerometers, pedometers, or other mobile devices.</p> <p>ncit id: ncit:C187892</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:18 (mHealth)</li> </ul>"},{"location":"topics/Biology/","title":"Biology","text":"<p>id: B2AI_TOPIC:1</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Data involving any study of living organisms at any scale.</p> <p>edam id: edam.topic:3070</p> <p>mesh id: mesh:D001695</p> <p>ncit id: ncit:C16345</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>parent of:</p> <ul> <li> <p>B2AI_TOPIC:11 (Environment)</p> </li> <li> <p>B2AI_TOPIC:20 (Molecular Biology)</p> </li> <li> <p>B2AI_TOPIC:46 (Respiration)</p> </li> </ul>"},{"location":"topics/Cardiomyocyte/","title":"Cardiomyocyte","text":"<p>id: B2AI_TOPIC:42</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Cardiomyocytes are the muscle cells of the heart. They are responsible for the contraction of the heart muscle, which enables the heart to pump blood throughout the body. This topic refers to studies of cardiomyocytes and their properties.</p> <p>mesh id: mesh:D032383</p> <p>ncit id: ncit:C13002</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:2 (Cell)</li> </ul>"},{"location":"topics/Cell/","title":"Cell","text":"<p>id: B2AI_TOPIC:2</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Observations and measurements of cellular physiology and variation in cell types.</p> <p>mesh id: mesh:D002477</p> <p>ncit id: ncit:C12508</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:20 (Molecular Biology)</li> </ul> <p>parent of:</p> <ul> <li> <p>B2AI_TOPIC:42 (Cardiomyocyte)</p> </li> <li> <p>B2AI_TOPIC:41 (Neuron)</p> </li> </ul>"},{"location":"topics/Cheminformatics/","title":"Cheminformatics","text":"<p>id: B2AI_TOPIC:3</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Data regarding the physical properties of chemical compounds.</p> <p>edam id: edam.data:1086</p> <p>mesh id: mesh:D000080911</p> <p>ncit id: ncit:C188483</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>parent of:</p> <ul> <li>B2AI_TOPIC:8 (Drug)</li> </ul>"},{"location":"topics/ClinicalObservations/","title":"Clinical Observations","text":"<p>id: B2AI_TOPIC:4</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: All data derived from observations of individual clinical patients, whether as part of a clinical trial or in the course of diagnosis, treatment, and follow-up.</p> <p>mesh id: mesh:D008499</p> <p>ncit id: ncit:C15783</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>parent of:</p> <ul> <li> <p>B2AI_TOPIC:9 (EHR)</p> </li> <li> <p>B2AI_TOPIC:48 (Neurology)</p> </li> <li> <p>B2AI_TOPIC:50 (Psychiatry)</p> </li> </ul>"},{"location":"topics/Data/","title":"Data","text":"<p>id: B2AI_TOPIC:5</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Collected information at any stage of processing and analysis.</p> <p>edam id: edam.data:0006</p> <p>mesh id: mesh:D003625</p> <p>ncit id: ncit:C25474</p> <p>parent of:</p> <ul> <li> <p>B2AI_TOPIC:1 (Biology)</p> </li> <li> <p>B2AI_TOPIC:3 (Cheminformatics)</p> </li> <li> <p>B2AI_TOPIC:4 (Clinical Observations)</p> </li> <li> <p>B2AI_TOPIC:6 (Demographics)</p> </li> <li> <p>B2AI_TOPIC:7 (Disease)</p> </li> <li> <p>B2AI_TOPIC:14 (Geolocation)</p> </li> <li> <p>B2AI_TOPIC:40 (Governance)</p> </li> <li> <p>B2AI_TOPIC:15 (Image)</p> </li> <li> <p>B2AI_TOPIC:21 (Networks And Pathways)</p> </li> <li> <p>B2AI_TOPIC:25 (Phenotype)</p> </li> <li> <p>B2AI_TOPIC:31 (Survey)</p> </li> <li> <p>B2AI_TOPIC:32 (Text)</p> </li> <li> <p>B2AI_TOPIC:37 (Waveform)</p> </li> <li> <p>B2AI_TOPIC:18 (mHealth)</p> </li> </ul>"},{"location":"topics/Demographics/","title":"Demographics","text":"<p>id: B2AI_TOPIC:6</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Data describing a subset of a population, including sex, age, ethnicity, geographic location, or other factors.</p> <p>mesh id: mesh:D003710</p> <p>ncit id: ncit:C16495</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>parent of:</p> <ul> <li>B2AI_TOPIC:29 (SDoH)</li> </ul>"},{"location":"topics/Diabetes/","title":"Diabetes","text":"<p>id: B2AI_TOPIC:43</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Diabetes is a chronic disease that occurs when the body is unable to regulate blood sugar levels properly. This topic refers to data related to any form of diabetes mellitus and its management.</p> <p>mesh id: mesh:D003920</p> <p>ncit id: ncit:C2985</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:7 (Disease)</li> </ul>"},{"location":"topics/Disease/","title":"Disease","text":"<p>id: B2AI_TOPIC:7</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Data describing a disordered health state and its relationships to phenotype, genotype, other organisms, and environmental exposures.</p> <p>edam id: edam.data:3667</p> <p>mesh id: mesh:D004194</p> <p>ncit id: ncit:C2991</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>parent of:</p> <ul> <li> <p>B2AI_TOPIC:43 (Diabetes)</p> </li> <li> <p>B2AI_TOPIC:44 (Eye Diseases)</p> </li> <li> <p>B2AI_TOPIC:47 (Respiratory Disorders)</p> </li> <li> <p>B2AI_TOPIC:45 (Voice Disorders)</p> </li> </ul>"},{"location":"topics/Drug/","title":"Drug","text":"<p>id: B2AI_TOPIC:8</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Data regarding the properties of substances intended to be used or investigated for their therapeutic properties.</p> <p>edam id: edam.data:0993</p> <p>mesh id: mesh:D004364</p> <p>ncit id: ncit:C1909</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:3 (Cheminformatics)</li> </ul>"},{"location":"topics/EHR/","title":"EHR","text":"<p>id: B2AI_TOPIC:9</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Electronic health record data, including structured and unstructured text, lab values, and associated metadata.</p> <p>edam id: edam.data:3861</p> <p>mesh id: mesh:D055991</p> <p>ncit id: ncit:C142529</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:4 (Clinical Observations)</li> </ul>"},{"location":"topics/EKG/","title":"EKG","text":"<p>id: B2AI_TOPIC:10</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Measurements of the electrical signals of the heart over time.</p> <p>mesh id: mesh:D004562</p> <p>ncit id: ncit:C168186</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:37 (Waveform)</li> </ul>"},{"location":"topics/Environment/","title":"Environment","text":"<p>id: B2AI_TOPIC:11</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Descriptions and measurements of the relationships between people and their ecosystem(s).</p> <p>edam id: edam.topic:3855</p> <p>mesh id: mesh:D004777</p> <p>ncit id: ncit:C16551</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:1 (Biology)</li> </ul>"},{"location":"topics/EyeDiseases/","title":"EyeDiseases","text":"<p>id: B2AI_TOPIC:44</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Eye diseases are conditions that affect the eye and its surrounding structures. This topic refers to data related to any eye disease, including but not limited to cataracts, glaucoma, and macular degeneration.</p> <p>mesh id: mesh:D005128</p> <p>ncit id: ncit:C26767</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:7 (Disease)</li> </ul>"},{"location":"topics/Gene/","title":"Gene","text":"<p>id: B2AI_TOPIC:12</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: One or a select set of DNA sequences, coding or non-coding, and their properties.</p> <p>edam id: edam.data:3494</p> <p>mesh id: mesh:D005796</p> <p>ncit id: ncit:C16612</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:13 (Genome)</li> </ul> <p>parent of:</p> <ul> <li>B2AI_TOPIC:35 (Variant)</li> </ul>"},{"location":"topics/Genome/","title":"Genome","text":"<p>id: B2AI_TOPIC:13</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: One or more complete collections of gene sequences from a single individual, potentially including ony exon sequences.</p> <p>edam id: edam.data:1288</p> <p>mesh id: mesh:D016678</p> <p>ncit id: ncit:C16629</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:23 (Omics)</li> </ul> <p>parent of:</p> <ul> <li>B2AI_TOPIC:12 (Gene)</li> </ul>"},{"location":"topics/Geolocation/","title":"Geolocation","text":"<p>id: B2AI_TOPIC:14</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Measurements describing the location of an object or person on planet Earth.</p> <p>edam id: edam.data:3720</p> <p>ncit id: ncit:C25341</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul>"},{"location":"topics/GlucoseMonitoring/","title":"Glucose Monitoring","text":"<p>id: B2AI_TOPIC:38</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Tracking a person's glucose levels over time, whether in real-time using a small sensor inserted under the skin, or through glucose readings collected at regular intervals.</p> <p>mesh id: mesh:D015190</p> <p>ncit id: ncit:C92744</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:18 (mHealth)</li> </ul>"},{"location":"topics/Governance/","title":"Governance","text":"<p>id: B2AI_TOPIC:40</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: All data components created to maintain security, privacy, accuracy, availability, and usability of other parts of the same or other data.</p> <p>edam id: edam.topic:3571</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul>"},{"location":"topics/Image/","title":"Image","text":"<p>id: B2AI_TOPIC:15</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Visual representation of an observation, including but not limited to photographs, micrographs, radiology results, or data plots.</p> <p>edam id: edam.data:2968</p> <p>ncit id: ncit:C48179</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>parent of:</p> <ul> <li> <p>B2AI_TOPIC:19 (Microscale Imaging)</p> </li> <li> <p>B2AI_TOPIC:22 (Neurologic Imaging)</p> </li> <li> <p>B2AI_TOPIC:24 (Ophthalmic Imaging)</p> </li> </ul>"},{"location":"topics/Literature/","title":"Literature","text":"<p>id: B2AI_TOPIC:16</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: The unstructured text contents of a selection of scholarly documents and/or the metadata of those documents.</p> <p>mesh id: mesh:D008091</p> <p>ncit id: ncit:C48471</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:32 (Text)</li> </ul> <p>parent of:</p> <ul> <li>B2AI_TOPIC:52 (Training)</li> </ul>"},{"location":"topics/Metabolome/","title":"Metabolome","text":"<p>id: B2AI_TOPIC:17</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Measurements of the presence, structure, and potential amount of small molecule metabolites within a sample from one individual, cell, organ, sample, or site.</p> <p>edam id: edam.data:2603</p> <p>mesh id: mesh:D055442</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:23 (Omics)</li> </ul>"},{"location":"topics/MicroscaleImaging/","title":"Microscale Imaging","text":"<p>id: B2AI_TOPIC:19</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Images obtained through microscopy (e.g., optical, fluorescence, electron).</p> <p>edam id: edam.data:3424</p> <p>mesh id: mesh:D008853</p> <p>ncit id: ncit:C16853</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:15 (Image)</li> </ul>"},{"location":"topics/MolecularBiology/","title":"Molecular Biology","text":"<p>id: B2AI_TOPIC:20</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Any data concerning studies of the structure, function, and interactions of biological molecules.</p> <p>edam id: edam.topic:3047</p> <p>mesh id: mesh:D008967</p> <p>ncit id: ncit:C16872</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:1 (Biology)</li> </ul> <p>parent of:</p> <ul> <li> <p>B2AI_TOPIC:2 (Cell)</p> </li> <li> <p>B2AI_TOPIC:23 (Omics)</p> </li> </ul>"},{"location":"topics/NetworksAndPathways/","title":"Networks and Pathways","text":"<p>id: B2AI_TOPIC:21</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Models of the interactions among biological entities or concepts.</p> <p>edam id: edam.data:2600</p> <p>ncit id: ncit:C61377</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul>"},{"location":"topics/NeurologicImaging/","title":"Neurologic Imaging","text":"<p>id: B2AI_TOPIC:22</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Images obtained through one or more brain imaging techniques, including computed tomography, positron emission tomography, magnetic resonance imaging, or imaging of associated body structures (e.g., angiography).</p> <p>edam id: edam.data:3424</p> <p>mesh id: mesh:D059906</p> <p>ncit id: ncit:C173635</p> <p>subclass of:</p> <ul> <li> <p>B2AI_TOPIC:15 (Image)</p> </li> <li> <p>B2AI_TOPIC:48 (Neurology)</p> </li> </ul>"},{"location":"topics/NeurologicalDisorders/","title":"NeurologicalDisorders","text":"<p>id: B2AI_TOPIC:49</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Neurological disorders are conditions that affect the nervous system, including the brain, spinal cord, and peripheral nerves. This topic refers to data related to any neurological disorder, including but not limited to Alzheimer's disease, Parkinson's disease, and multiple sclerosis.</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:48 (Neurology)</li> </ul>"},{"location":"topics/Neurology/","title":"Neurology","text":"<p>id: B2AI_TOPIC:48</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Neurology is the branch of medicine that deals with disorders of the nervous system, including the brain, spinal cord, and peripheral nerves. This topic refers to data related to any aspect of neurology, including but not limited to neurological diseases, brain imaging, and nerve function.</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:4 (Clinical Observations)</li> </ul> <p>parent of:</p> <ul> <li> <p>B2AI_TOPIC:22 (Neurologic Imaging)</p> </li> <li> <p>B2AI_TOPIC:49 (Neurological Disorders)</p> </li> </ul>"},{"location":"topics/Neuron/","title":"Neuron","text":"<p>id: B2AI_TOPIC:41</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Neurons, also known as nerve cells, are the fundamental units of the brain and nervous system. They are responsible for transmitting electrical and chemical signals to enable communication throughout the body. This topic refers to studies of neurons and their properties.</p> <p>mesh id: mesh:D009474</p> <p>ncit id: ncit:C12623</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:2 (Cell)</li> </ul>"},{"location":"topics/Omics/","title":"Omics","text":"<p>id: B2AI_TOPIC:23</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Data involving two or more comprehensive biomolecular screens, such as those of genomes, transcriptomes, proteomes, or others.</p> <p>edam id: edam.topic:3391</p> <p>mesh id: mesh:D000095028</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:20 (Molecular Biology)</li> </ul> <p>parent of:</p> <ul> <li> <p>B2AI_TOPIC:13 (Genome)</p> </li> <li> <p>B2AI_TOPIC:17 (Metabolome)</p> </li> <li> <p>B2AI_TOPIC:28 (Proteome)</p> </li> <li> <p>B2AI_TOPIC:34 (Transcriptome)</p> </li> </ul>"},{"location":"topics/OphthalmicImaging/","title":"Ophthalmic Imaging","text":"<p>id: B2AI_TOPIC:24</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Images of the interior and/or exterior of the eye.</p> <p>ncit id: ncit:C38060</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:15 (Image)</li> </ul>"},{"location":"topics/Phenotype/","title":"Phenotype","text":"<p>id: B2AI_TOPIC:25</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: The set of observable traits of an organism, whether constant or in response to a given set of conditions.</p> <p>edam id: edam.data:3275</p> <p>mesh id: mesh:D010641</p> <p>ncit id: ncit:C16977</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul>"},{"location":"topics/Protein/","title":"Protein","text":"<p>id: B2AI_TOPIC:26</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: One or a select set of amino acid sequences and their properties.</p> <p>edam id: edam.data:2976</p> <p>mesh id: mesh:D011506</p> <p>ncit id: ncit:C17021</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:28 (Proteome)</li> </ul> <p>parent of:</p> <ul> <li>B2AI_TOPIC:27 (Protein Structure Model)</li> </ul>"},{"location":"topics/ProteinStructureModel/","title":"Protein Structure Model","text":"<p>id: B2AI_TOPIC:27</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Representations of the three-dimensional structure of a protein in one or more states or conformations.</p> <p>edam id: edam.data:1460</p> <p>mesh id: mesh:D011487</p> <p>ncit id: ncit:C13303</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:26 (Protein)</li> </ul>"},{"location":"topics/Proteome/","title":"Proteome","text":"<p>id: B2AI_TOPIC:28</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Measurements of the presence, sequence, and potential amount of proteins within a sample from one individual, organ, sample, or site.</p> <p>mesh id: mesh:D020543</p> <p>ncit id: ncit:C18276</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:23 (Omics)</li> </ul> <p>parent of:</p> <ul> <li>B2AI_TOPIC:26 (Protein)</li> </ul>"},{"location":"topics/PsychiatricDisorders/","title":"PsychiatricDisorders","text":"<p>id: B2AI_TOPIC:51</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Psychiatric disorders are conditions that affect mental health, including mood disorders, anxiety disorders, and psychotic disorders. This topic refers to data related to any psychiatric disorder, including but not limited to major depressive disorder, generalized anxiety disorder, and schizophrenia. It also includes data related to mood disorders.</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:50 (Psychiatry)</li> </ul>"},{"location":"topics/Psychiatry/","title":"Psychiatry","text":"<p>id: B2AI_TOPIC:50</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Psychiatry is the branch of medicine that deals with mental health disorders, including depression, anxiety, and schizophrenia. This topic refers to data related to any aspect of psychiatry, including but not limited to mental health treatments, psychiatric diagnoses, and psychological assessments.</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:4 (Clinical Observations)</li> </ul> <p>parent of:</p> <ul> <li>B2AI_TOPIC:51 (Psychiatric Disorders)</li> </ul>"},{"location":"topics/Respiration/","title":"Respiration","text":"<p>id: B2AI_TOPIC:46</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Respiration is the process of breathing, which involves the exchange of oxygen and carbon dioxide between the body and the environment. This topic refers to data related to any aspect of respiration, including but not limited to lung function, respiratory diseases, and breathing patterns.</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:1 (Biology)</li> </ul> <p>parent of:</p> <ul> <li>B2AI_TOPIC:47 (Respiratory Disorders)</li> </ul>"},{"location":"topics/RespiratoryDisorders/","title":"RespiratoryDisorders","text":"<p>id: B2AI_TOPIC:47</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Respiratory disorders are conditions that affect the lungs and other parts of the respiratory system. This topic refers to data related to any respiratory disorder, including but not limited to asthma, chronic obstructive pulmonary disease (COPD), and pneumonia.</p> <p>subclass of:</p> <ul> <li> <p>B2AI_TOPIC:7 (Disease)</p> </li> <li> <p>B2AI_TOPIC:46 (Respiration)</p> </li> </ul>"},{"location":"topics/SDoH/","title":"SDoH","text":"<p>id: B2AI_TOPIC:29</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Social Determinants of Health, i.e., properties of one or more people contributing to their health, wellness, and disease risk.</p> <p>mesh id: mesh:D064890</p> <p>ncit id: ncit:C171586</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:6 (Demographics)</li> </ul>"},{"location":"topics/SocialMedia/","title":"Social Media","text":"<p>id: B2AI_TOPIC:30</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: The unstructured text derived from social media correspondence.</p> <p>mesh id: mesh:D061108</p> <p>ncit id: ncit:C97003</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:32 (Text)</li> </ul>"},{"location":"topics/Survey/","title":"Survey","text":"<p>id: B2AI_TOPIC:31</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Data submitted by members of a study population, usually in response to specific questions.</p> <p>mesh id: mesh:D006306</p> <p>ncit id: ncit:C17176</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul>"},{"location":"topics/Text/","title":"Text","text":"<p>id: B2AI_TOPIC:32</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Any unstructured or semi-structured collection of written human language.</p> <p>edam id: edam.data:2526</p> <p>ncit id: ncit:C25704</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>parent of:</p> <ul> <li> <p>B2AI_TOPIC:16 (Literature)</p> </li> <li> <p>B2AI_TOPIC:30 (Social Media)</p> </li> </ul>"},{"location":"topics/Training/","title":"Training","text":"<p>id: B2AI_TOPIC:52</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: This topic refers to resources or data intended for training or educational purposes. This includes instructional materials, educational resources, tutorials, and other content designed to develop skills or knowledge in a particular domain. Training data may exist in various formats including text, multimedia, interactive modules, or datasets specifically curated for learning purposes, but there is nearly always some textual component.</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:16 (Literature)</li> </ul>"},{"location":"topics/Transcript/","title":"Transcript","text":"<p>id: B2AI_TOPIC:33</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: One or a select set of RNA sequences derived from gene expression, and their properties.</p> <p>edam id: edam.data:3495</p> <p>mesh id: mesh:D012333</p> <p>ncit id: ncit:C1936</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:34 (Transcriptome)</li> </ul>"},{"location":"topics/Transcriptome/","title":"Transcriptome","text":"<p>id: B2AI_TOPIC:34</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Measurements of the presence, sequence, and potential expression level of gene transcripts within a sample from one individual, cell, organ, sample, or site.</p> <p>edam id: edam.data:2603</p> <p>mesh id: mesh:D059467</p> <p>ncit id: ncit:C153194</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:23 (Omics)</li> </ul> <p>parent of:</p> <ul> <li>B2AI_TOPIC:33 (Transcript)</li> </ul>"},{"location":"topics/Variant/","title":"Variant","text":"<p>id: B2AI_TOPIC:35</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: An alteration in a gene sequence relative to another set of sequences, whether associated with a phenotype or not.</p> <p>mesh id: mesh:D014644</p> <p>ncit id: ncit:C25713</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:12 (Gene)</li> </ul>"},{"location":"topics/Voice/","title":"Voice","text":"<p>id: B2AI_TOPIC:36</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Audio data produced by human speech, not including non-linguistic utterances.</p> <p>mesh id: mesh:D014831</p> <p>ncit id: ncit:C92692</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:37 (Waveform)</li> </ul> <p>parent of:</p> <ul> <li>B2AI_TOPIC:45 (Voice Disorders)</li> </ul>"},{"location":"topics/VoiceDisorders/","title":"VoiceDisorders","text":"<p>id: B2AI_TOPIC:45</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Voice disorders are conditions that affect the vocal cords and other parts of the larynx. This topic refers to data related to any voice disorder, including but not limited to vocal cord paralysis, laryngitis, and vocal nodules.</p> <p>subclass of:</p> <ul> <li> <p>B2AI_TOPIC:7 (Disease)</p> </li> <li> <p>B2AI_TOPIC:36 (Voice)</p> </li> </ul>"},{"location":"topics/Waveform/","title":"Waveform","text":"<p>id: B2AI_TOPIC:37</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Representations of a signal as a function of time, including audio recordings or electrocardiogram readings.</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>parent of:</p> <ul> <li> <p>B2AI_TOPIC:10 (EKG)</p> </li> <li> <p>B2AI_TOPIC:36 (Voice)</p> </li> </ul>"},{"location":"topics/mHealth/","title":"mHealth","text":"<p>id: B2AI_TOPIC:18</p> <p>contributor github name: caufieldjh</p> <p>contributor name: Harry Caufield</p> <p>contributor orcid: ORCID:0000-0001-5705-7831</p> <p>description: Mobile health data generated by individuals using health-related mobile applications and devices, concerning location, physical activity, and physiological metrics.</p> <p>ncit id: ncit:C97005</p> <p>subclass of:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>parent of:</p> <ul> <li> <p>B2AI_TOPIC:39 (Activity Monitoring)</p> </li> <li> <p>B2AI_TOPIC:38 (Glucose Monitoring)</p> </li> </ul>"},{"location":"usecases/assemble-standards-for-integrated-maps-of-human-cell-architecture/","title":"Assemble standards for integrated maps of human cell architecture","text":"<p>ID: B2AI_USECASE:21</p> <p>Name: Assemble standards for integrated maps of human cell architecture.</p> <p>Description: As per Qin et al. (2021) Nature (https://doi.org/10.1038/s41586-021-04115-9), imaging data and biophysical association data may be combined to develop measurements of protein distance within subcellular systems. When combined with other data (see B2AI_USECASE:16) the result is a map of cell architecture. Some degree of standardization will be necessary among these maps, such that they may be combined while retaining consistent biologically-relevant observations.</p> <p>Category: standardization</p> <p>Involved in: Metadata Management, Quality Control</p> <p>Data Topics:</p> <ul> <li> <p>B2AI_TOPIC:19 (Microscale Imaging)</p> </li> <li> <p>B2AI_TOPIC:27 (Protein Structure Model)</p> </li> <li> <p>B2AI_TOPIC:28 (Proteome)</p> </li> <li> <p>B2AI_TOPIC:34 (Transcriptome)</p> </li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:116</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/assemble-standards-for-voice-data/","title":"Assemble standards for voice data","text":"<p>ID: B2AI_USECASE:22</p> <p>Name: Assemble standards for voice data.</p> <p>Description: Standardizing voice recordings involves ensuring that all recordings have consistent properties, including volume, equalization, and noise reduction. These standards also incorporate processes for storing metadata about recorded voice samples.</p> <p>Category: standardization</p> <p>Involved in: Metadata Management, Quality Control</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:36 (Voice)</li> </ul> <p>Enables:</p> <ul> <li> <p>B2AI_USECASE:31 (Develop software and cloud infrastructure for automated voice data collection through a smartphone application.)</p> </li> <li> <p>B2AI_USECASE:32 (Build a database of human voice samples and associations with biomarkers of health.)</p> </li> </ul> <p>Enabled by:</p> <ul> <li>B2AI_USECASE:8 (Obtain voice data from patients.)</li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:117</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/assess-the-explainability-of-a-computational-model/","title":"Assess the explainability of a computational model","text":"<p>ID: B2AI_USECASE:44</p> <p>Name: Assess the explainability of a computational model.</p> <p>Description: Computational models are not equivalently explainable. A model\u2019s operations may appear correct, but without the ability to justify its responses based on a particular reasoning process, it may remain challenging to identify its weaknesses.</p> <p>Category: assessment</p> <p>Involved in: Quality Control</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/assess-the-potential-bias-in-a-computational-model/","title":"Assess the potential bias in a computational model","text":"<p>ID: B2AI_USECASE:43</p> <p>Name: Assess the potential bias in a computational model.</p> <p>Description: Even a high-performing computational model may be subject to bias, both explicitly and implicitly. The model may not accurately represent the population it was trained on. It may be algorithmically biased, with some features gaining weight over others in unexpected ways. There may be biases resulting from human preconceptions, e.g., human curators may have already made assumptions about disease status of patients contributing data to the model\u2019s training set. There may also be unexpected confounders, such as social or economic factors contributing to clinical outcomes.</p> <p>Category: assessment</p> <p>Involved in: Quality Control</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/assess-the-quality-of-a-computational-model-in-terms-of-its-ability-to-complete-a-specific-task/","title":"Assess the quality of a computational model in terms of its ability to complete a specific task","text":"<p>ID: B2AI_USECASE:42</p> <p>Name: Assess the quality of a computational model in terms of its ability to complete a specific task.</p> <p>Description: Independent of their application, computational models may be evaluated using a core set of metrics, including accuracy, precision, and recall.</p> <p>Category: assessment</p> <p>Involved in: Experimental Design, Quality Control</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/build-a-database-of-human-voice-samples-and-associations-with-biomarkers-of-health/","title":"Build a database of human voice samples and associations with biomarkers of health","text":"<p>ID: B2AI_USECASE:32</p> <p>Name: Build a database of human voice samples and associations with biomarkers of health.</p> <p>Description: Building a database of human voice samples and associations with biomarkers of health may begin with a secure database, either on-premise or based in cloud infrastructure. Data organization and labeling should support retrieval and analysis. Machine learning algorithms can be applied to the data to identify patterns and associations between the voice samples and the biomarkers of health. Regularly updating the database with new data and re-analyzing the data could improve the accuracy and resolution of the predicted associations.</p> <p>Category: application</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li> <p>B2AI_TOPIC:4 (Clinical Observations)</p> </li> <li> <p>B2AI_TOPIC:35 (Variant)</p> </li> <li> <p>B2AI_TOPIC:36 (Voice)</p> </li> </ul> <p>Enabled by:</p> <ul> <li>B2AI_USECASE:22 (Assemble standards for voice data.)</li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:117</li> </ul> <p>Standards and Tools:</p> <ul> <li>B2AI_STANDARD:732</li> </ul> <p>Alternative Standards and Tools:</p> <ul> <li> <p>B2AI_STANDARD:723</p> </li> <li> <p>B2AI_STANDARD:790</p> </li> <li> <p>B2AI_STANDARD:758</p> </li> <li> <p>B2AI_STANDARD:767</p> </li> <li> <p>B2AI_STANDARD:785</p> </li> <li> <p>B2AI_STANDARD:791</p> </li> <li> <p>B2AI_STANDARD:839</p> </li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/build-a-graph-database-of-arbitrary-data-types/","title":"Build a graph database of arbitrary data types","text":"<p>ID: B2AI_USECASE:35</p> <p>Name: Build a graph database of arbitrary data types.</p> <p>Description: To set up a graph database, first choose a graph database management system. Create a graph data model to define the nodes, edges, and properties of the graph. Once the data model is in place, create nodes, edges, and properties in the graph corresponding to input data. Depending on the graph database platform, there may be functionality to set up indexes on certain properties to optimize query performance. Setting up constraints on the data can help to ensure data integrity.</p> <p>Category: application</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/build-a-relational-database-of-arbitrary-data-types/","title":"Build a relational database of arbitrary data types","text":"<p>ID: B2AI_USECASE:33</p> <p>Name: Build a relational database of arbitrary data types.</p> <p>Description: To set up a relational database, first choose a relational database management system (RDBMS). Create a schema to define the database structure, including the tables and fields. Build tables within the schema and define the fields and data types for each table, then populate them with data by inserting rows. It's also crucial to set up relationships between tables, such as linking a primary key in one table to a foreign key in another table. This ensures data integrity and simplifies querying.</p> <p>Category: application</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/construct-standards-for-computational-provenance/","title":"Construct standards for computational provenance","text":"<p>ID: B2AI_USECASE:23</p> <p>Name: Construct standards for computational provenance.</p> <p>Description: Computational provenance is a record of the processes and data used to produce a computational result. Constructing standards for computational provenance involves establishing protocols for how this information should be recorded, stored, and shared. This can include what information provenance records must contain, their format(s), and any connections to the resulting computation. Additionally, standards may be established for how provenance should be validated and authenticated to ensure its accuracy and trustworthiness.</p> <p>Category: standardization</p> <p>Involved in: Metadata Management, Quality Control</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:116</li> </ul> <p>Standards and Tools:</p> <ul> <li>B2AI_STANDARD:444</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/deploy-a-federated-learning-system-for-analysis-of-voice-data/","title":"Deploy a Federated Learning System for analysis of voice data","text":"<p>ID: B2AI_USECASE:27</p> <p>Name: Deploy a Federated Learning System for analysis of voice data.</p> <p>Description: As presented by the Voice GC, a set of patient voice recordings may be analyzed in an automated manner through the machine learning approach of federated learning. In federated learning, a central model is first trained on a dataset distributed among many devices or clients. Individual clients train their own copies of the model on their own data, then send updated model parameters to the central server. The server then averages newly updated parameters from all clients to produce a new global model. It returns the new model to the clients and the process repeats.</p> <p>Category: application</p> <p>Involved in: Experimental Design, Metadata Management, Quality Control</p> <p>Data Topics:</p> <ul> <li> <p>B2AI_TOPIC:4 (Clinical Observations)</p> </li> <li> <p>B2AI_TOPIC:31 (Survey)</p> </li> <li> <p>B2AI_TOPIC:36 (Voice)</p> </li> </ul> <p>Enabled by:</p> <ul> <li>B2AI_USECASE:8 (Obtain voice data from patients.)</li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:117</li> </ul> <p>Standards and Tools:</p> <ul> <li> <p>B2AI_STANDARD:723</p> </li> <li> <p>B2AI_STANDARD:839</p> </li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/determine-whether-enough-data-is-available-to-train-a-computational-model-of-interest/","title":"Determine whether enough data is available to train a computational model of interest","text":"<p>ID: B2AI_USECASE:41</p> <p>Name: Determine whether enough data is available to train a computational model of interest.</p> <p>Description: Computational models may require a certain amount or complexity of data for their training to be effective. It may be useful to define these properties before beginning modeling.</p> <p>Category: assessment</p> <p>Involved in: Experimental Design, Quality Control</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/develop-cross-sectional-ai-models-of-relationships-between-diabetes-severity-cognitive-function-and-presence-of-biomarkers/","title":"Develop cross-sectional AI models of relationships between diabetes severity, cognitive function, and presence of biomarkers","text":"<p>ID: B2AI_USECASE:28</p> <p>Name: Develop cross-sectional AI models of relationships between diabetes severity, cognitive function, and presence of biomarkers.</p> <p>Description: As presented by the AI-READI GC, this use case develops models capable of interpreting relationships between clinical observations of diabetes patients and their features, with a focus on cognitive function. This case does not depend upon availability of pseudotime models, unlike B2AI_USECASE:29.</p> <p>Category: application</p> <p>Involved in: Experimental Design, Metadata Management, Quality Control</p> <p>Data Topics:</p> <ul> <li> <p>B2AI_TOPIC:4 (Clinical Observations)</p> </li> <li> <p>B2AI_TOPIC:10 (EKG)</p> </li> <li> <p>B2AI_TOPIC:13 (Genome)</p> </li> <li> <p>B2AI_TOPIC:18 (mHealth)</p> </li> <li> <p>B2AI_TOPIC:24 (Ophthalmic Imaging)</p> </li> <li> <p>B2AI_TOPIC:29 (SDoH)</p> </li> </ul> <p>Enabled by:</p> <ul> <li> <p>B2AI_USECASE:6 (Obtain patient data from wearable devices.)</p> </li> <li> <p>B2AI_USECASE:7 (Obtain genomics data from patients.)</p> </li> <li> <p>B2AI_USECASE:9 (Obtain social determinants of health data from patients.)</p> </li> <li> <p>B2AI_USECASE:17 (Standardize clinical record data collected from multiple sites and sources.)</p> </li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:114</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/develop-models-of-clinical-image-data/","title":"Develop models of clinical image data","text":"<p>ID: B2AI_USECASE:25</p> <p>Name: Develop models of clinical image data.</p> <p>Description: Developing models of clinical image data may involve annotation, preprocessing, and model training. Generally, annotation requires labeling  images with disease or clinical phenotype-relevant information such as labels, bounding boxes, and segmentation masks. The annotation process may be assisted by automated methods, particularly in cases where patient features are already known. Preprocessing such as resizing, normalization, and data augmentation then prepares the labeled images for model training. The training process applies machine learning algorithms to learn patterns from the data and make predictions on new images.</p> <p>Category: modeling</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:15 (Image)</li> </ul> <p>Enables:</p> <ul> <li>B2AI_USECASE:30 (Test and deploy analytical models of clinical image data.)</li> </ul> <p>Enabled by:</p> <ul> <li>B2AI_USECASE:19 (Standardize clinical image data collected from multiple sites and sources.)</li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:115</li> </ul> <p>Standards and Tools:</p> <ul> <li>B2AI_STANDARD:788</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/develop-multi-scale-maps-of-human-cell-architecture/","title":"Develop multi-scale maps of human cell architecture","text":"<p>ID: B2AI_USECASE:24</p> <p>Name: Develop multi-scale maps of human cell architecture.</p> <p>Description: Given the availability of integrated imaging, biophysical, and transcriptome data centered on a specific set of proteins (see B2AI_USECASE:16), we may then use these results to assemble maps of the physical proximities and relationships among those proteins.</p> <p>Category: modeling</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li> <p>B2AI_TOPIC:19 (Microscale Imaging)</p> </li> <li> <p>B2AI_TOPIC:27 (Protein Structure Model)</p> </li> <li> <p>B2AI_TOPIC:28 (Proteome)</p> </li> <li> <p>B2AI_TOPIC:34 (Transcriptome)</p> </li> </ul> <p>Enabled by:</p> <ul> <li>B2AI_USECASE:16 (Link cellular objects to functions through associations between proteins, cell structure proximity, and transcriptomics.)</li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:116</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/develop-predictive-models-of-insulin-dependence-and-salutogenesis/","title":"Develop predictive models of insulin dependence and salutogenesis","text":"<p>ID: B2AI_USECASE:29</p> <p>Name: Develop predictive models of insulin dependence and salutogenesis.</p> <p>Description: As presented by the AI-READI GC, this use case develops models capable of interpreting relationships between clinical observations of diabetes patients and their features, with a focus on insulin dependence. Its goal is to produce a model capable of yielding predictions about a given patient\u2019s progression towards a health or disease state. This case depends upon availability of pseudotime models, unlike B2AI_USECASE:28.</p> <p>Category: application</p> <p>Involved in: Experimental Design, Metadata Management, Quality Control</p> <p>Data Topics:</p> <ul> <li> <p>B2AI_TOPIC:4 (Clinical Observations)</p> </li> <li> <p>B2AI_TOPIC:10 (EKG)</p> </li> <li> <p>B2AI_TOPIC:13 (Genome)</p> </li> <li> <p>B2AI_TOPIC:18 (mHealth)</p> </li> <li> <p>B2AI_TOPIC:24 (Ophthalmic Imaging)</p> </li> <li> <p>B2AI_TOPIC:29 (SDoH)</p> </li> </ul> <p>Enabled by:</p> <ul> <li> <p>B2AI_USECASE:7 (Obtain genomics data from patients.)</p> </li> <li> <p>B2AI_USECASE:9 (Obtain social determinants of health data from patients.)</p> </li> <li> <p>B2AI_USECASE:17 (Standardize clinical record data collected from multiple sites and sources.)</p> </li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:114</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/develop-pseudotime-patient-models-of-health-and-salutogenesis/","title":"Develop pseudotime patient models of health and salutogenesis","text":"<p>ID: B2AI_USECASE:26</p> <p>Name: Develop pseudotime patient models of health and salutogenesis.</p> <p>Description: As presented by the AI-READI GC, developing pseudotime patient models of health and salutogenesis hinges on the idea that health is a time-sensitive process, with various events contributing to a progression towards clinical outcomes in a chronological fashion. The exact amount of time between events may not be as important as their order and may therefore be abstracted.</p> <p>Category: modeling</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li> <p>B2AI_TOPIC:4 (Clinical Observations)</p> </li> <li> <p>B2AI_TOPIC:10 (EKG)</p> </li> <li> <p>B2AI_TOPIC:13 (Genome)</p> </li> <li> <p>B2AI_TOPIC:18 (mHealth)</p> </li> <li> <p>B2AI_TOPIC:24 (Ophthalmic Imaging)</p> </li> <li> <p>B2AI_TOPIC:29 (SDoH)</p> </li> </ul> <p>Enabled by:</p> <ul> <li> <p>B2AI_USECASE:4 (Obtain image data from retinal and other ophthalmic imaging.)</p> </li> <li> <p>B2AI_USECASE:6 (Obtain patient data from wearable devices.)</p> </li> <li> <p>B2AI_USECASE:7 (Obtain genomics data from patients.)</p> </li> <li> <p>B2AI_USECASE:9 (Obtain social determinants of health data from patients.)</p> </li> <li> <p>B2AI_USECASE:17 (Standardize clinical record data collected from multiple sites and sources.)</p> </li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:114</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/develop-software-and-cloud-infrastructure-for-automated-voice-data-collection-through-a-smartphone-application/","title":"Develop software and cloud infrastructure for automated voice data collection through a smartphone application","text":"<p>ID: B2AI_USECASE:31</p> <p>Name: Develop software and cloud infrastructure for automated voice data collection through a smartphone application.</p> <p>Description: Developing software and cloud infrastructure for automated voice data collection in this use case first requires development of a smartphone application. The application would need to be able to record audio, allow user logins, upload the recorded audio to cloud storage, and permit users to view and manage recorded audio data. The cloud infrastructure would need to store and process the audio data to handle the storage, as well as potentially using machine learning algorithms to analyze the audio data. Additionally, the infrastructure would need to have a secure and reliable means of transmitting data between the smartphone application and the cloud.</p> <p>Category: application</p> <p>Involved in: Metadata Management, Quality Control</p> <p>Data Topics:</p> <ul> <li> <p>B2AI_TOPIC:31 (Survey)</p> </li> <li> <p>B2AI_TOPIC:36 (Voice)</p> </li> </ul> <p>Enabled by:</p> <ul> <li> <p>B2AI_USECASE:8 (Obtain voice data from patients.)</p> </li> <li> <p>B2AI_USECASE:22 (Assemble standards for voice data.)</p> </li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:117</li> </ul> <p>Alternative Standards and Tools:</p> <ul> <li> <p>B2AI_STANDARD:723</p> </li> <li> <p>B2AI_STANDARD:790</p> </li> <li> <p>B2AI_STANDARD:758</p> </li> <li> <p>B2AI_STANDARD:767</p> </li> <li> <p>B2AI_STANDARD:785</p> </li> <li> <p>B2AI_STANDARD:791</p> </li> <li> <p>B2AI_STANDARD:839</p> </li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/integrate-clinical-record-data-with-voice-data/","title":"Integrate clinical record data with voice data","text":"<p>ID: B2AI_USECASE:13</p> <p>Name: Integrate clinical record data with voice data.</p> <p>Description: Clinical records generally do not include mechanisms for accessing voice recordings. Data records must therefore be linked to associate voice data samples with their source patients.</p> <p>Category: integration</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li> <p>B2AI_TOPIC:9 (EHR)</p> </li> <li> <p>B2AI_TOPIC:36 (Voice)</p> </li> </ul> <p>Enables:</p> <ul> <li>B2AI_USECASE:17 (Standardize clinical record data collected from multiple sites and sources.)</li> </ul> <p>Enabled by:</p> <ul> <li> <p>B2AI_USECASE:1 (Obtain patient data from records of clinical visits.)</p> </li> <li> <p>B2AI_USECASE:8 (Obtain voice data from patients.)</p> </li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:117</li> </ul> <p>Standards and Tools:</p> <ul> <li> <p>B2AI_STANDARD:732</p> </li> <li> <p>B2AI_STANDARD:109</p> </li> <li> <p>B2AI_STANDARD:271</p> </li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/link-cellular-objects-to-functions-through-associations-between-proteins-cell-structure-proximity-and-transcriptomics/","title":"Link cellular objects to functions through associations between proteins, cell structure, proximity, and transcriptomics","text":"<p>ID: B2AI_USECASE:16</p> <p>Name: Link cellular objects to functions through associations between proteins, cell structure proximity, and transcriptomics.</p> <p>Description: As per Qin et al. (2021) Nature (https://doi.org/10.1038/s41586-021-04115-9), imaging data and biophysical association data may be combined to develop measurements of protein distance within subcellular systems. This use case builds on that strategy by adding a third component: measurement of transcript changes under perturbation conditions for each protein. For the CM4AI GC, this process involves evidence graphs. The result here is not a full subcellular map, but rather the integrated data necessary to assemble such a map.</p> <p>Category: integration</p> <p>Involved in: Experimental Design, Metadata Management, Quality Control</p> <p>Data Topics:</p> <ul> <li> <p>B2AI_TOPIC:19 (Microscale Imaging)</p> </li> <li> <p>B2AI_TOPIC:28 (Proteome)</p> </li> <li> <p>B2AI_TOPIC:27 (Protein Structure Model)</p> </li> <li> <p>B2AI_TOPIC:34 (Transcriptome)</p> </li> </ul> <p>Enables:</p> <ul> <li>B2AI_USECASE:24 (Develop multi-scale maps of human cell architecture.)</li> </ul> <p>Enabled by:</p> <ul> <li> <p>B2AI_USECASE:10 (Obtain molecular proximity observations from microscopy images of human cells.)</p> </li> <li> <p>B2AI_USECASE:11 (Obtain proteome data from human cell samples.)</p> </li> <li> <p>B2AI_USECASE:12 (Obtain transcriptome data from human cell populations perturbed through CRISPR-driven mutagenesis.)</p> </li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:116</li> </ul> <p>Standards and Tools:</p> <ul> <li>B2AI_STANDARD:764</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/obtain-clinical-waveform-data-from-patients/","title":"Obtain clinical waveform data from patients","text":"<p>ID: B2AI_USECASE:3</p> <p>Name: Obtain clinical waveform data from patients.</p> <p>Description: Clinical waveform data from an electrocardiogram (EKG or ECG) is a representation of the electrical activity of the heart. The EKG measures the voltage between different points on the body and records the resulting waveform. This waveform can be used to diagnose a variety of heart conditions, including arrhythmias and heart attacks. It is typically recorded using a machine that is attached to the patient via electrodes.</p> <p>Category: acquisition</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li> <p>B2AI_TOPIC:9 (EHR)</p> </li> <li> <p>B2AI_TOPIC:10 (EKG)</p> </li> </ul> <p>Enables:</p> <ul> <li>B2AI_USECASE:18 (Standardize clinical waveform data collected from multiple sites and sources.)</li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:114</li> </ul> <p>Standards and Tools:</p> <ul> <li>B2AI_STANDARD:202</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/obtain-genomics-data-from-patients/","title":"Obtain genomics data from patients","text":"<p>ID: B2AI_USECASE:7</p> <p>Name: Obtain genomics data from patients.</p> <p>Description: Clinical genomics data refers to the genetic information collected from individuals as part of their medical care or clinical research. This data may include information about an individual's DNA sequence, as well as any genetic variations or mutations that may be associated with disease phenotypes.</p> <p>Category: acquisition</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li> <p>B2AI_TOPIC:13 (Genome)</p> </li> <li> <p>B2AI_TOPIC:35 (Variant)</p> </li> </ul> <p>Enables:</p> <ul> <li> <p>B2AI_USECASE:20 (Standardize clinical omics data collected from multiple sites and sources.)</p> </li> <li> <p>B2AI_USECASE:26 (Develop pseudotime patient models of health and salutogenesis.)</p> </li> <li> <p>B2AI_USECASE:28 (Develop cross-sectional AI models of relationships between diabetes severity, cognitive function, and presence of biomarkers.)</p> </li> <li> <p>B2AI_USECASE:29 (Develop predictive models of insulin dependence and salutogenesis.)</p> </li> </ul> <p>Relevant to GCs:</p> <ul> <li> <p>B2AI_ORG:114</p> </li> <li> <p>B2AI_ORG:117</p> </li> </ul> <p>Standards and Tools:</p> <ul> <li> <p>B2AI_STANDARD:36</p> </li> <li> <p>B2AI_STANDARD:154</p> </li> <li> <p>B2AI_STANDARD:819</p> </li> <li> <p>B2AI_STANDARD:278</p> </li> <li> <p>B2AI_STANDARD:299</p> </li> <li> <p>B2AI_STANDARD:301</p> </li> </ul> <p>External References:</p> <ul> <li>EDAM:topic_3673</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/obtain-image-data-from-brain-magnetic-resonance-imaging/","title":"Obtain image data from brain magnetic resonance imaging","text":"<p>ID: B2AI_USECASE:2</p> <p>Name: Obtain image data from brain magnetic resonance imaging.</p> <p>Description: Magnetic resonance imaging (MRI) is a medical imaging technique that produces detailed images of the body's internal structures, including the brain. These images can be used to diagnose a variety of medical conditions and to evaluate the health of the brain. Brain MRI image data refers to the detailed images of the brain that are produced by the MRI machine.</p> <p>Category: acquisition</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li> <p>B2AI_TOPIC:4 (Clinical Observations)</p> </li> <li> <p>B2AI_TOPIC:22 (Neurologic Imaging)</p> </li> </ul> <p>Enables:</p> <ul> <li>B2AI_USECASE:19 (Standardize clinical image data collected from multiple sites and sources.)</li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:114</li> </ul> <p>Standards and Tools:</p> <ul> <li>B2AI_STANDARD:33</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/obtain-image-data-from-retinal-and-other-ophthalmic-imaging/","title":"Obtain image data from retinal and other ophthalmic imaging","text":"<p>ID: B2AI_USECASE:4</p> <p>Name: Obtain image data from retinal and other ophthalmic imaging.</p> <p>Description: Ophthalmic image data is data that is collected from images of the eye. This type of data is typically used in the field of ophthalmology, which is the branch of medicine that deals with the diagnosis and treatment of eye diseases and disorders. Ophthalmic images can provide valuable information about the health of the eye, including the structure and function of the various parts of the eye, such as the retina, cornea, and lens.</p> <p>Category: acquisition</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li> <p>B2AI_TOPIC:4 (Clinical Observations)</p> </li> <li> <p>B2AI_TOPIC:24 (Ophthalmic Imaging)</p> </li> </ul> <p>Enables:</p> <ul> <li> <p>B2AI_USECASE:19 (Standardize clinical image data collected from multiple sites and sources.)</p> </li> <li> <p>B2AI_USECASE:26 (Develop pseudotime patient models of health and salutogenesis.)</p> </li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:114</li> </ul> <p>Standards and Tools:</p> <ul> <li>B2AI_STANDARD:98</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/obtain-molecular-proximity-observations-from-microscopy-images-of-human-cells/","title":"Obtain molecular proximity observations from microscopy images of human cells","text":"<p>ID: B2AI_USECASE:10</p> <p>Name: Obtain molecular proximity observations from microscopy images of human cells.</p> <p>Description: Images of objects at the microscale (i.e., those at 0.1\u2013100\u03bcm) are obtained through a variety of microscopy approaches. In the CM4AI project, images of cell structures are obtained through confocal immunofluorescence microscopy.</p> <p>Category: acquisition</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:19 (Microscale Imaging)</li> </ul> <p>Enables:</p> <ul> <li>B2AI_USECASE:16 (Link cellular objects to functions through associations between proteins, cell structure proximity, and transcriptomics.)</li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:116</li> </ul> <p>Standards and Tools:</p> <ul> <li>B2AI_STANDARD:764</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/obtain-patient-data-from-laboratory-analysis-including-serological-testing-and-urinalysis/","title":"Obtain patient data from laboratory analysis including serological testing and urinalysis","text":"<p>ID: B2AI_USECASE:5</p> <p>Name: Obtain patient data from laboratory analysis, including serological testing and urinalysis.</p> <p>Description: Patient data from laboratory analysis typically includes results from tests that have been performed on samples taken from the patient, such as blood, urine, or other bodily fluids. Serological testing is a type of laboratory analysis that involves testing blood serum (the liquid part of blood) for the presence of various indicators of disease or health. Urinalysis is another common type of laboratory analysis that involves testing urine samples for various factors, such as the presence of bacteria, glucose, or other substances. Test results may or may not be derived from EHR data. Here, data includes records from mobile devices used to complement laboratory diagnostics, including continuous glucose monitoring.</p> <p>Category: acquisition</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li> <p>B2AI_TOPIC:4 (Clinical Observations)</p> </li> <li> <p>B2AI_TOPIC:9 (EHR)</p> </li> <li> <p>B2AI_TOPIC:18 (mHealth)</p> </li> </ul> <p>Enables:</p> <ul> <li>B2AI_USECASE:17 (Standardize clinical record data collected from multiple sites and sources.)</li> </ul> <p>Enabled by:</p> <ul> <li>B2AI_USECASE:1 (Obtain patient data from records of clinical visits.)</li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:114</li> </ul> <p>Standards and Tools:</p> <ul> <li>B2AI_STANDARD:243</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/obtain-patient-data-from-records-of-clinical-visits/","title":"Obtain patient data from records of clinical visits","text":"<p>ID: B2AI_USECASE:1</p> <p>Name: Obtain patient data from records of clinical visits.</p> <p>Description: Collecting clinical data from patient visits involves the process of gathering information about a patient's medical history, current symptoms, and other relevant information during a healthcare appointment. This typically includes taking a detailed medical history, conducting a physical examination, ordering and interpreting diagnostic tests, and documenting the findings in the patient's medical record. This may also include more focused evaluations, as with the AI-READI project\u2019s assessments of cognitive function and visual acuity. Medical records may include structured/unstructured text, values for lab results, and/or images.</p> <p>Category: acquisition</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li> <p>B2AI_TOPIC:15 (Image)</p> </li> <li> <p>B2AI_TOPIC:4 (Clinical Observations)</p> </li> </ul> <p>Enables:</p> <ul> <li> <p>B2AI_USECASE:5 (Obtain patient data from laboratory analysis, including serological testing and urinalysis.)</p> </li> <li> <p>B2AI_USECASE:13 (Integrate clinical record data with voice data.)</p> </li> <li> <p>B2AI_USECASE:17 (Standardize clinical record data collected from multiple sites and sources.)</p> </li> <li> <p>B2AI_USECASE:19 (Standardize clinical image data collected from multiple sites and sources.)</p> </li> </ul> <p>Relevant to GCs:</p> <ul> <li> <p>B2AI_ORG:114</p> </li> <li> <p>B2AI_ORG:115</p> </li> <li> <p>B2AI_ORG:117</p> </li> </ul> <p>Standards and Tools:</p> <ul> <li> <p>B2AI_STANDARD:98</p> </li> <li> <p>B2AI_STANDARD:243</p> </li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/obtain-patient-data-from-wearable-devices/","title":"Obtain patient data from wearable devices","text":"<p>ID: B2AI_USECASE:6</p> <p>Name: Obtain patient data from wearable devices.</p> <p>Description: Wearable devices are small electronic devices that can be worn on the body to collect data about the user's activity, movements, and other physiological information. This data can include things like steps taken, heart rate, sleep patterns, and other metrics that can be used to track health and fitness. Activity data may be viewed in aggregate (e.g., number of steps per day above a threshold rather than exact counts or geolocation data) to serve as approximates of physical fitness assessments otherwise performed by clinical personnel.</p> <p>Category: acquisition</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:18 (mHealth)</li> </ul> <p>Enables:</p> <ul> <li> <p>B2AI_USECASE:17 (Standardize clinical record data collected from multiple sites and sources.)</p> </li> <li> <p>B2AI_USECASE:26 (Develop pseudotime patient models of health and salutogenesis.)</p> </li> <li> <p>B2AI_USECASE:28 (Develop cross-sectional AI models of relationships between diabetes severity, cognitive function, and presence of biomarkers.)</p> </li> </ul> <p>Relevant to GCs:</p> <ul> <li> <p>B2AI_ORG:114</p> </li> <li> <p>B2AI_ORG:115</p> </li> </ul> <p>Standards and Tools:</p> <ul> <li>B2AI_STANDARD:246</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/obtain-proteome-data-from-human-cell-samples/","title":"Obtain proteome data from human cell samples","text":"<p>ID: B2AI_USECASE:11</p> <p>Name: Obtain proteome data from human cell samples.</p> <p>Description: The proteome is the complete set of proteins that is expressed by a genome, cell, tissue, or organism at a given time and set of conditions. Proteome data refers to the information that is generated from studies of the proteome, such as the identification and characterization of the proteins that are expressed, their relative abundance, and any modifications that they may undergo. In the CM4AI project, proteome data is obtained through affinity purification coupled with tandem mass spectroscopy (AP-MS/MS).</p> <p>Category: acquisition</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:28 (Proteome)</li> </ul> <p>Enables:</p> <ul> <li>B2AI_USECASE:16 (Link cellular objects to functions through associations between proteins, cell structure proximity, and transcriptomics.)</li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:116</li> </ul> <p>Standards and Tools:</p> <ul> <li>B2AI_STANDARD:764</li> </ul> <p>External References:</p> <ul> <li>EDAM:topic_0121</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/obtain-social-determinants-of-health-data-from-patients/","title":"Obtain social determinants of health data from patients","text":"<p>ID: B2AI_USECASE:9</p> <p>Name: Obtain social determinants of health data from patients.</p> <p>Description: Social determinants of health (SDoH) are the conditions in which people are born, grow, live, work, and age. These conditions are shaped by the distribution of money, power, and resources at global, national, and local levels. SDoH are largely responsible for health inequities - unfair and avoidable differences in health status from person to person. SDoH data may be collected directly from individuals or based on integration with other data, but it generally includes at least one of the following factors poverty and income inequality, education and literacy, employment and working conditions, gender and gender equality, social exclusion and discrimination, housing and living conditions, or access to healthcare.</p> <p>Category: acquisition</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li> <p>B2AI_TOPIC:29 (SDoH)</p> </li> <li> <p>B2AI_TOPIC:31 (Survey)</p> </li> </ul> <p>Enables:</p> <ul> <li> <p>B2AI_USECASE:17 (Standardize clinical record data collected from multiple sites and sources.)</p> </li> <li> <p>B2AI_USECASE:26 (Develop pseudotime patient models of health and salutogenesis.)</p> </li> <li> <p>B2AI_USECASE:28 (Develop cross-sectional AI models of relationships between diabetes severity, cognitive function, and presence of biomarkers.)</p> </li> <li> <p>B2AI_USECASE:29 (Develop predictive models of insulin dependence and salutogenesis.)</p> </li> </ul> <p>Relevant to GCs:</p> <ul> <li> <p>B2AI_ORG:114</p> </li> <li> <p>B2AI_ORG:115</p> </li> </ul> <p>Standards and Tools:</p> <ul> <li>B2AI_STANDARD:243</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/obtain-transcriptome-data-from-human-cell-populations-perturbed-through-crispr-driven-mutagenesis/","title":"Obtain transcriptome data from human cell populations perturbed through CRISPR-driven mutagenesis","text":"<p>ID: B2AI_USECASE:12</p> <p>Name: Obtain transcriptome data from human cell populations perturbed through CRISPR-driven mutagenesis.</p> <p>Description: In the CM4AI project, transcriptome data is collected through single-cell RNA sequencing from cells subjected to CRISPR-driven mutagenesis.</p> <p>Category: acquisition</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:34 (Transcriptome)</li> </ul> <p>Enables:</p> <ul> <li>B2AI_USECASE:16 (Link cellular objects to functions through associations between proteins, cell structure proximity, and transcriptomics.)</li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:116</li> </ul> <p>Standards and Tools:</p> <ul> <li>B2AI_STANDARD:764</li> </ul> <p>External References:</p> <ul> <li>EDAM:topic_3170</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/obtain-voice-data-from-patients/","title":"Obtain voice data from patients","text":"<p>ID: B2AI_USECASE:8</p> <p>Name: Obtain voice data from patients.</p> <p>Description: Perform voice data collection, either in a clinical setting or through a mobile device. Includes a process for patients to consent to voice data collection, voice data sharing and utilization as part of voice AI technology.</p> <p>Category: acquisition</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li> <p>B2AI_TOPIC:31 (Survey)</p> </li> <li> <p>B2AI_TOPIC:36 (Voice)</p> </li> </ul> <p>Enables:</p> <ul> <li> <p>B2AI_USECASE:13 (Integrate clinical record data with voice data.)</p> </li> <li> <p>B2AI_USECASE:22 (Assemble standards for voice data.)</p> </li> <li> <p>B2AI_USECASE:27 (Deploy a Federated Learning System for analysis of voice data.)</p> </li> <li> <p>B2AI_USECASE:31 (Develop software and cloud infrastructure for automated voice data collection through a smartphone application.)</p> </li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:117</li> </ul> <p>Standards and Tools:</p> <ul> <li> <p>B2AI_STANDARD:732</p> </li> <li> <p>B2AI_STANDARD:723</p> </li> <li> <p>B2AI_STANDARD:821</p> </li> <li> <p>B2AI_STANDARD:839</p> </li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/produce-artifacts-that-map-identifiers-between-source-and-standardized-data-representations/","title":"Produce artifacts that map identifiers between source and standardized data representations","text":"<p>ID: B2AI_USECASE:15</p> <p>Name: Produce artifacts that map identifiers between source and standardized data representations.</p> <p>Description: The sets of identifiers shared between two or more data products serve as points of commonality between observations, but in practice, a desired level of interoperability may not be achievable without mapping some identifiers to equivalent terms. This may be necessary for entire namespaces (e.g., mapping all NCBI Gene identifiers to their corresponding UniProtKB protein accessions) or for a subset (e.g., mapping ChEBI entries for drugs to their identifiers in a drug-centric knowledge base). There may also be a need to define inexact matches: an identifier\u2019s best mapping in another resource may be to a more broadly-defined concept.</p> <p>Category: integration</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:115</li> </ul> <p>Standards and Tools:</p> <ul> <li>B2AI_STANDARD:378</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/query-a-graph-database-of-arbitrary-data-types/","title":"Query a graph database of arbitrary data types","text":"<p>ID: B2AI_USECASE:36</p> <p>Name: Query a graph database of arbitrary data types.</p> <p>Description: Querying a graph database covers a variety of actions to retrieve subsets of its contents, often by yielding subsets of the graph (i.e., subgraphs).</p> <p>Category: application</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/query-a-relational-database-of-arbitrary-data-types/","title":"Query a relational database of arbitrary data types","text":"<p>ID: B2AI_USECASE:34</p> <p>Name: Query a relational database of arbitrary data types.</p> <p>Description: Querying a relational database covers a variety of actions to retrieve subsets of its contents.</p> <p>Category: application</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>Alternative Standards and Tools:</p> <ul> <li>B2AI_STANDARD:802</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/standardize-clinical-image-data-collected-from-multiple-sites-and-sources/","title":"Standardize clinical image data collected from multiple sites and sources","text":"<p>ID: B2AI_USECASE:19</p> <p>Name: Standardize clinical image data collected from multiple sites and sources.</p> <p>Description: Standardizing clinical images across sites and sources involves ensuring that images are captured and stored in a consistent manner, so that they can be easily compared and analyzed. This may include following guidelines for image acquisition, e.g., recommended image resolution, contrast, and lighting conditions. It also includes image metadata properties such as consistent labeling and format. Depending on subsequent applications, it may require image processing, such as normalization, to correct for variations in appearance due to differences in equipment or patient positioning.</p> <p>Category: standardization</p> <p>Involved in: Metadata Management, Quality Control</p> <p>Data Topics:</p> <ul> <li> <p>B2AI_TOPIC:15 (Image)</p> </li> <li> <p>B2AI_TOPIC:24 (Ophthalmic Imaging)</p> </li> </ul> <p>Enables:</p> <ul> <li> <p>B2AI_USECASE:25 (Develop models of clinical image data.)</p> </li> <li> <p>B2AI_USECASE:30 (Test and deploy analytical models of clinical image data.)</p> </li> </ul> <p>Enabled by:</p> <ul> <li> <p>B2AI_USECASE:1 (Obtain patient data from records of clinical visits.)</p> </li> <li> <p>B2AI_USECASE:2 (Obtain image data from brain magnetic resonance imaging.)</p> </li> <li> <p>B2AI_USECASE:4 (Obtain image data from retinal and other ophthalmic imaging.)</p> </li> </ul> <p>Relevant to GCs:</p> <ul> <li> <p>B2AI_ORG:114</p> </li> <li> <p>B2AI_ORG:115</p> </li> <li> <p>B2AI_ORG:117</p> </li> </ul> <p>Standards and Tools:</p> <ul> <li> <p>B2AI_STANDARD:71</p> </li> <li> <p>B2AI_STANDARD:98</p> </li> <li> <p>B2AI_STANDARD:788</p> </li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/standardize-clinical-omics-data-collected-from-multiple-sites-and-sources/","title":"Standardize clinical omics data collected from multiple sites and sources","text":"<p>ID: B2AI_USECASE:20</p> <p>Name: Standardize clinical omics data collected from multiple sites and sources.</p> <p>Description: Standardizing clinical omics data involves methods for ensuring consistency and comparability across different sources. This can be achieved through common data formats, controlled vocabularies, and ontologies. It may also involve some degree of quality control, as data from multiple sources may not be subject to identical validation or filtering procedures.</p> <p>Category: standardization</p> <p>Involved in: Metadata Management, Quality Control</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:13 (Genome)</li> </ul> <p>Enabled by:</p> <ul> <li>B2AI_USECASE:7 (Obtain genomics data from patients.)</li> </ul> <p>Relevant to GCs:</p> <ul> <li> <p>B2AI_ORG:114</p> </li> <li> <p>B2AI_ORG:117</p> </li> </ul> <p>Standards and Tools:</p> <ul> <li>B2AI_STANDARD:109</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/standardize-clinical-record-data-collected-from-multiple-sites-and-sources/","title":"Standardize clinical record data collected from multiple sites and sources","text":"<p>ID: B2AI_USECASE:17</p> <p>Name: Standardize clinical record data collected from multiple sites and sources.</p> <p>Description: Standardizing clinical record data across multiple sites and sources involves several steps, all with the goal of rendering it more usable in subsequent analyses. Data is first collected from electronic health records, clinical databases, surveys, and potentially other sources. Next, the data is cleaned and transformed to a consistent format. This may include removing duplicate records, filling in missing data, and standardizing field names and values. The data is then validated to ensure that it is accurate and complete. Standardized data is then integrated into a central repository.</p> <p>Category: standardization</p> <p>Involved in: Metadata Management, Quality Control</p> <p>Data Topics:</p> <ul> <li> <p>Demographic</p> </li> <li> <p>B2AI_TOPIC:4 (Clinical Observations)</p> </li> <li> <p>B2AI_TOPIC:9 (EHR)</p> </li> <li> <p>B2AI_TOPIC:18 (mHealth)</p> </li> <li> <p>B2AI_TOPIC:29 (SDoH)</p> </li> <li> <p>B2AI_TOPIC:31 (Survey)</p> </li> </ul> <p>Enables:</p> <ul> <li> <p>B2AI_USECASE:26 (Develop pseudotime patient models of health and salutogenesis.)</p> </li> <li> <p>B2AI_USECASE:28 (Develop cross-sectional AI models of relationships between diabetes severity, cognitive function, and presence of biomarkers.)</p> </li> <li> <p>B2AI_USECASE:29 (Develop predictive models of insulin dependence and salutogenesis.)</p> </li> </ul> <p>Enabled by:</p> <ul> <li> <p>B2AI_USECASE:1 (Obtain patient data from records of clinical visits.)</p> </li> <li> <p>B2AI_USECASE:5 (Obtain patient data from laboratory analysis, including serological testing and urinalysis.)</p> </li> <li> <p>B2AI_USECASE:6 (Obtain patient data from wearable devices.)</p> </li> <li> <p>B2AI_USECASE:9 (Obtain social determinants of health data from patients.)</p> </li> <li> <p>B2AI_USECASE:13 (Integrate clinical record data with voice data.)</p> </li> </ul> <p>Relevant to GCs:</p> <ul> <li> <p>B2AI_ORG:114</p> </li> <li> <p>B2AI_ORG:115</p> </li> <li> <p>B2AI_ORG:117</p> </li> </ul> <p>Standards and Tools:</p> <ul> <li> <p>B2AI_STANDARD:71</p> </li> <li> <p>B2AI_STANDARD:187</p> </li> <li> <p>B2AI_STANDARD:788</p> </li> <li> <p>B2AI_STANDARD:243</p> </li> <li> <p>B2AI_STANDARD:271</p> </li> <li> <p>B2AI_STANDARD:727</p> </li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/standardize-clinical-waveform-data-collected-from-multiple-sites-and-sources/","title":"Standardize clinical waveform data collected from multiple sites and sources","text":"<p>ID: B2AI_USECASE:18</p> <p>Name: Standardize clinical waveform data collected from multiple sites and sources.</p> <p>Description: As with other clinical observations and records, standardizing waveform data is largely a process of collection, cleaning, transformation, validation, and storage. The features of waveforms, whether audio or cardiac in origin, require specific handling to ensure physiologically-relevant details are retained. Raw waveform data is quite large and therefore consumes more disk space than most database architectures are prepared to operate with. This data may be collected continuously, leading to accumulation of large quantities of incoming observations to store and analyze. standardization must therefore be sensitive to the size and resolution of waveform data.</p> <p>Category: standardization</p> <p>Involved in: Metadata Management, Quality Control</p> <p>Data Topics:</p> <ul> <li> <p>B2AI_TOPIC:9 (EHR)</p> </li> <li> <p>B2AI_TOPIC:10 (EKG)</p> </li> </ul> <p>Enabled by:</p> <ul> <li>B2AI_USECASE:3 (Obtain clinical waveform data from patients.)</li> </ul> <p>Relevant to GCs:</p> <ul> <li> <p>B2AI_ORG:114</p> </li> <li> <p>B2AI_ORG:115</p> </li> </ul> <p>Standards and Tools:</p> <ul> <li> <p>B2AI_STANDARD:788</p> </li> <li> <p>B2AI_STANDARD:202</p> </li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/test-and-deploy-analytical-models-of-clinical-image-data/","title":"Test and deploy analytical models of clinical image data","text":"<p>ID: B2AI_USECASE:30</p> <p>Name: Test and deploy analytical models of clinical image data.</p> <p>Description: Given the availability of a model of clinical image data (as produced by B2AI_USECASE:25), testing and deploying the model generally involves creating a test data set, preprocessing the data by normalizing and converting it into a format that can be used by the model, evaluating the model's performance on the test set, then optimizing the model by re-training under different parameters or input data until the desired level of performance is achieved. There may be a need for converting the model to a format that can be used in a specific runtime environment or monitoring the model's performance in a production environment and making adjustments as needed. Deploying the analytical model may require consideration of validation, regulatory approval, ethics, and compliance with patient privacy laws.</p> <p>Category: application</p> <p>Involved in: Experimental Design, Metadata Management, Quality Control</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:15 (Image)</li> </ul> <p>Enabled by:</p> <ul> <li> <p>B2AI_USECASE:19 (Standardize clinical image data collected from multiple sites and sources.)</p> </li> <li> <p>B2AI_USECASE:25 (Develop models of clinical image data.)</p> </li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:115</li> </ul> <p>Standards and Tools:</p> <ul> <li>B2AI_STANDARD:788</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/train-a-binary-classification-model-on-data-in-one-or-more-bioconductor-objects/","title":"Train a binary classification model on data in one or more Bioconductor objects","text":"<p>ID: B2AI_USECASE:38</p> <p>Name: Train a binary classification model on data in one or more Bioconductor objects.</p> <p>Description: Training a binary classification model on Bioconductor objects can be a convenient way to work with R statistical functions on large quantities of heterogeneous data. After any necessary preprocessing of the data, such as normalizing or filtering, split it into a training and test set. Then select a classification algorithm and use the training data to train a model. Test data may be used to evaluate the performance of the model and adjust any parameters as necessary.</p> <p>Category: modeling</p> <p>Involved in: Experimental Design</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/train-a-linear-regression-model-on-data-in-an-r-tibble/","title":"Train a linear regression model on data in an R tibble","text":"<p>ID: B2AI_USECASE:37</p> <p>Name: Train a linear regression model on data in an R tibble.</p> <p>Description: Training a linear regression model on data in the R tibble data structure generally involves R\u2019s lm() function. To see the summary of the resulting model, use the summary() function on the model object. To make predictions using the model, use the predict() function on the model object and provide new data as the argument.</p> <p>Category: modeling</p> <p>Involved in: Experimental Design, Quality Control</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/train-a-neural-network-model-on-tensor-data/","title":"Train a neural network model on tensor data","text":"<p>ID: B2AI_USECASE:39</p> <p>Name: Train a neural network model on tensor data.</p> <p>Description: Training a neural network model on tensor data is a frequent use case for developing data analysis and prediction methods.</p> <p>Category: modeling</p> <p>Involved in: Experimental Design</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/transform-data-from-omop-to-the-i2b2-standard/","title":"Transform data from OMOP to the i2b2 standard","text":"<p>ID: B2AI_USECASE:14</p> <p>Name: Transform data from OMOP to the i2b2 standard.</p> <p>Description: Transforming data from OMOP to the i2b2 standard involves converting the data from OMOP's schema to the i2b2 schema, which allows for the data to be more easily queried and analyzed using i2b2's tools and platforms. This involves mapping the data to equivalent concepts in the i2b2 schema, and may also involve cleaning and preprocessing the data to ensure that it is in the correct format for use with i2b2.</p> <p>Category: integration</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:4 (Clinical Observations)</li> </ul> <p>Relevant to GCs:</p> <ul> <li>B2AI_ORG:115</li> </ul> <p>Standards and Tools:</p> <ul> <li> <p>B2AI_STANDARD:775</p> </li> <li> <p>B2AI_STANDARD:243</p> </li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"},{"location":"usecases/transform-fhir-data-to-tsv/","title":"Transform FHIR data to TSV","text":"<p>ID: B2AI_USECASE:40</p> <p>Name: Transform FHIR data to TSV.</p> <p>Description: Data described through the HL7 FHIR standard may take a variety of forms, owing to the standard\u2019s intentional flexibility. A highly interpretable, easily parsed format such as TSV may be desirable as part of transformation or subsequent analysis.</p> <p>Category: integration</p> <p>Involved in: Experimental Design, Metadata Management</p> <p>Data Topics:</p> <ul> <li>B2AI_TOPIC:5 (Data)</li> </ul> <p>Standards and Tools:</p> <ul> <li>B2AI_STANDARD:109</li> </ul> <p>Contributor: Harry Caufield  (ORCID:0000-0001-5705-7831)</p>"}]}